{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\"\n",
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\smaller_training_sample\\\\test1\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(fpath + \"/full_data_truncated_survival.dta\")\n",
    "df = df.iloc[:,[-3,-2,-1] + list(range(df.shape[1]-3))]\n",
    "for p in ['num_terms', 'times', 'event']:\n",
    "    df.loc[:,p] = df[p].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298139, 334) (33115, 334)\n"
     ]
    }
   ],
   "source": [
    "train_df_old = df[df.valid == 0].drop(['valid'], axis=1)\n",
    "test_df = df[df.valid == 1].drop(['valid'], axis=1)\n",
    "print(train_df_old.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomly select 10% observations from the original training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, train_df = train_test_split(train_df_old, test_size=0.1, stratify=train_df_old['event'].astype(str)+\"_\"+train_df_old['num_terms'].astype(str), random_state=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    }
   ],
   "source": [
    "predictors = list(df.columns)[4:]\n",
    "print(len(predictors))\n",
    "impute_list_1 = set([\"prop_comp_pre\",\"cum_gpa_pre\"])\n",
    "impute_list_2 = set([t1+\"_\"+t2+str(t3) for t1 in [\"term_gpa\", \"prop_comp\", \"lvl2_prop_comp\", \"dev_prop_comp\"] for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)])\n",
    "impute_list_3 = set([\"cum_gpa\", \"lvl2_prop_comp\", \"dev_prop_comp\", \"prop_comp\", \"prop_comp_sd\", \"withdrawn_prop_comp_sd\"])\n",
    "impute_list_4 = set([\"admrate\", \"gradrate\", \"satvr25\", \"satvr75\", \"satmt25\", \"satmt75\", \"satwr25\", \"satwr75\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train, test):\n",
    "    for p in impute_list_1:\n",
    "        avg_p = np.nanmean(train[train.enrolled_pre == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_\" + suffix] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_4:\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_nsc\"] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%time train_df_new, test_df_new = impute(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = test_df_new.event.copy()\n",
    "test_df_new.loc[:,'event'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 29814 total observations, 19618 right-censored observations>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the CoxPH model\n",
    "cph = CoxPHFitter(penalizer=0.01) # No penalizer will result in LinAlgError (probably due to multicollinearity)\n",
    "%time cph.fit(train_df_new, duration_col='times', event_col='event', strata='num_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33115, 17)\n"
     ]
    }
   ],
   "source": [
    "# Predict graduation probability (derived from survival probability by the end of Year 6)\n",
    "test_pred_raw = cph.predict_survival_function(test_df_new).T.sort_index()\n",
    "print(test_pred_raw.shape)\n",
    "y_test_pred = [1 - test_pred_raw.iloc[i,:].loc[18-e] for i,e in enumerate(test_df_new.num_terms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_pred), open(results_dir + \"/y_test_pred_cox.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox Proportional Hazard Model:\n",
      "AUC = 0.8768\n"
     ]
    }
   ],
   "source": [
    "# C-statistics\n",
    "print(\"Cox Proportional Hazard Model:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test, y_test_pred),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_cox(train):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.event):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        test_part_new = test_part_new.sort_index()\n",
    "        y_2 = test_part_new.event.copy()\n",
    "        test_part_new.loc[:,'event'] = 0\n",
    "        model = CoxPHFitter(penalizer=0.01)\n",
    "        model.fit(train_part_new, duration_col='times', event_col='event', strata='num_terms', step_size=0.1)\n",
    "        y_2_pred_raw = model.predict_survival_function(test_part_new).T.sort_index()\n",
    "        y_2_pred = [1 - y_2_pred_raw.iloc[i,:].loc[18-e] for i,e in enumerate(test_part_new.num_terms)]\n",
    "        p,r,t = precision_recall_curve(y_2, y_2_pred)\n",
    "        auc = roc_auc_score(y_2, y_2_pred)\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(threshold_list)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrolled_nsc_su6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Roaming\\Python\\Python35\\site-packages\\lifelines\\utils\\__init__.py:1086: ConvergenceWarning: Column(s) ['nsc_coll_type_4', 'enrl_intensity_nsc_fa6', 'enrl_intensity_nsc_sp6', 'enrl_intensity_nsc_su6'] have very low variance. This may harm convergence. Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36573440262788026, 0.9999998110637521, 0.37452322342084243, 0.9999993403295645, 0.3674965741569305, 0.3831245466594647, 0.29618604660136516, 0.38987885960821156, 0.357951078368111, 0.39965386489115184]\n",
      "0.8750848589640448 0.008005561486421077\n"
     ]
    }
   ],
   "source": [
    "best_threshold = cross_validation_cox(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44701690212755923"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.447:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  19420.0   2388.0  21808.0\n",
      "Real_1   3587.0   7720.0  11307.0\n",
      "        23007.0  10108.0  33115.0\n",
      "\n",
      "F1 score = 0.721\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "pr_cox = create_confusion_matrix(y_test_pred, best_threshold, \"Cox_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.397:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18765.0   3043.0  21808.0\n",
      "Real_1   3025.0   8282.0  11307.0\n",
      "        21790.0  11325.0  33115.0\n",
      "\n",
      "F1 score = 0.7319\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.event))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "pr2_cox = create_confusion_matrix(y_test_pred_binary, best_threshold, \"Cox_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df = pd.DataFrame([(best_threshold,)+pr_cox,(alternative_threshold,)+pr2_cox]).round(4)\n",
    "precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df.to_csv(results_dir + \"Cox_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with reduced validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomly select 10% observations from the original validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_new.loc[:,'event'] = list(y_test)\n",
    "_, test_df_reduced = train_test_split(test_df_new, test_size=0.1, stratify=test_df_new['event'].astype(str)+\"_\"+test_df_new['num_terms'].astype(str), random_state=54321)\n",
    "test_df_reduced = test_df_reduced.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_reduced = np.array(test_df_reduced.event)\n",
    "test_df_reduced.loc[:,'event'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir_new1 = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\smaller_training_sample\\\\test1\\\\comparison_1\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox Proportional Hazard:\n",
      "(3312, 17)\n",
      "AUC = 0.8866\n"
     ]
    }
   ],
   "source": [
    "print(\"Cox Proportional Hazard:\")\n",
    "test_pred_raw = cph.predict_survival_function(test_df_reduced).T.sort_index()\n",
    "print(test_pred_raw.shape)\n",
    "y_test_pred = [1 - test_pred_raw.iloc[i,:].loc[18-e] for i,e in enumerate(test_df_reduced.num_terms)]\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test_reduced, y_test_pred),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_pred), open(results_dir_new1 + \"y_test_pred_cox.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix_new(y_test, y_test_pred, threshold, fpath, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(np.array(y_test_pred) > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(fpath + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pr(train_df, y_test, y_test_pred, best_threshold, fpath, mn):\n",
    "    print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "    pr_lr = create_confusion_matrix_new(y_test, y_test_pred, best_threshold, fpath, \"{}_cm1\".format(mn))\n",
    "\n",
    "    num_of_0 = int(round((1-np.mean(train_df.event))*len(y_test)))\n",
    "    y_test_pred_binary = np.ones(len(y_test))\n",
    "    y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "    alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "    pr2_lr = create_confusion_matrix_new(y_test, y_test_pred_binary, best_threshold, fpath, \"{}_cm2\".format(mn))\n",
    "\n",
    "    precision_recall_df = pd.DataFrame([(best_threshold,)+pr_lr,(alternative_threshold,)+pr2_lr]).round(4)\n",
    "    precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "    precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "    precision_recall_df.to_csv(fpath + \"{}_precision_recall.csv\".format(mn), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.447:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1934.0   247.0  2181.0\n",
      "Real_1   329.0   802.0  1131.0\n",
      "        2263.0  1049.0  3312.0\n",
      "\n",
      "F1 score = 0.7358\n",
      "\n",
      "\n",
      "\n",
      "Alternative threshold = 0.404:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1894.0   287.0  2181.0\n",
      "Real_1   285.0   846.0  1131.0\n",
      "        2179.0  1133.0  3312.0\n",
      "\n",
      "F1 score = 0.7473\n"
     ]
    }
   ],
   "source": [
    "create_pr(train_df, y_test_reduced, y_test_pred, best_threshold, results_dir_new1, \"Cox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with the base model (trained on the full training data), using the reduced validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_predictors\\\\\"\n",
    "with open(model_dir + 'cox.pickle', 'rb') as f:\n",
    "    cph = pickle.load(f) # saving my trained cph model as my.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_df_old = df[df.valid == 0]\n",
    "test_df_old = df[df.valid == 1]\n",
    "_, test_df_new = train_test_split(test_df_old, test_size=0.1, stratify=test_df_old['event'].astype(str)+\"_\"+test_df_old['num_terms'].astype(str), random_state=54321)\n",
    "_, test_df_reduced = impute(train_df_old, test_df_new)\n",
    "test_df_reduced = test_df_reduced.sort_index()\n",
    "y_test_reduced = np.array(test_df_reduced.event)\n",
    "test_df_reduced.loc[:,'event'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir_new2 = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\smaller_training_sample\\\\test1\\\\comparison_2\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox Proportional Hazard:\n",
      "(3312, 17)\n",
      "AUC = 0.8901\n"
     ]
    }
   ],
   "source": [
    "print(\"Cox Proportional Hazard:\")\n",
    "test_pred_raw = cph.predict_survival_function(test_df_reduced).T.sort_index()\n",
    "print(test_pred_raw.shape)\n",
    "y_test_pred = [1 - test_pred_raw.iloc[i,:].loc[18-e] for i,e in enumerate(test_df_reduced.num_terms)]\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test_reduced, y_test_pred),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_pred), open(results_dir_new2 + \"y_test_pred_cox.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.447:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1934.0   247.0  2181.0\n",
      "Real_1   323.0   808.0  1131.0\n",
      "        2257.0  1055.0  3312.0\n",
      "\n",
      "F1 score = 0.7392\n",
      "\n",
      "\n",
      "\n",
      "Alternative threshold = 0.414:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1893.0   288.0  2181.0\n",
      "Real_1   286.0   845.0  1131.0\n",
      "        2179.0  1133.0  3312.0\n",
      "\n",
      "F1 score = 0.7465\n"
     ]
    }
   ],
   "source": [
    "create_pr(train_df_old, y_test_reduced, y_test_pred, best_threshold, results_dir_new2, \"Cox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
