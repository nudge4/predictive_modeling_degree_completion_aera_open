{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean\n",
    "import sklearn\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod import families\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from numpy.linalg import LinAlgError\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(fpath + \"/full_data_truncated.dta\")\n",
    "df.loc[:,'available_sum'] = 0\n",
    "for p in [p for p in list(df.columns)[10:] if p.startswith(\"available\") and p != \"available_sum\"]:\n",
    "    df.loc[:,'available_sum'] += df[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298139, 342) (33115, 342)\n"
     ]
    }
   ],
   "source": [
    "train_df_old = df[df.valid == 0]\n",
    "test_df = df[df.valid == 1]\n",
    "print(train_df_old.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomly select 10% observations from the original training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, train_df = train_test_split(train_df_old, test_size=0.1, stratify=train_df_old['grad_6years'].astype(str)+\"_\"+train_df_old['available_sum'].astype(str), random_state=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    }
   ],
   "source": [
    "predictors = list(df.columns)[10:-1]\n",
    "print(len(predictors))\n",
    "impute_list_1 = set([\"prop_comp_pre\",\"cum_gpa_pre\"])\n",
    "impute_list_2 = set([t1+\"_\"+t2+str(t3) for t1 in [\"term_gpa\", \"prop_comp\", \"lvl2_prop_comp\", \"dev_prop_comp\"] for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)])\n",
    "impute_list_3 = set([\"cum_gpa\", \"lvl2_prop_comp\", \"dev_prop_comp\", \"prop_comp\", \"prop_comp_sd\", \"withdrawn_prop_comp_sd\"])\n",
    "impute_list_4 = set([\"admrate\", \"gradrate\", \"satvr25\", \"satvr75\", \"satmt25\", \"satmt75\", \"satwr25\", \"satwr75\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34202052726906823"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# degree completion rate of validation sample\n",
    "sum(train_df.grad_6years)/train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34144647440736825"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# degree completion rate of validation sample\n",
    "sum(test_df.grad_6years)/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train, test):\n",
    "    for p in impute_list_1:\n",
    "        avg_p = np.nanmean(train[train.enrolled_pre == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_\" + suffix] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_4:\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_nsc\"] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_df_new, test_df_new = impute(train_df, test_df)\n",
    "X_train = train_df_new.loc[:,predictors]\n",
    "y_train = train_df_new.grad_6years\n",
    "X_test = test_df_new.loc[:,predictors]\n",
    "y_test = test_df_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\smaller_training_sample\\\\test1\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run the basic version of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1724: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lr = sm.Logit(y_train, add_constant(X_train,prepend=True)).fit()\n",
    "except LinAlgError:\n",
    "    lr = LogisticRegression(random_state=1234)\n",
    "    lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "AUC = 0.8805\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "if type(lr) == LogisticRegression:\n",
    "    y_test_pred_lr = list(lr.predict_proba(X_test)[:,1])\n",
    "else:\n",
    "    y_test_pred_lr = list(lr.predict(add_constant(X_test, prepend=True)))\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test, y_test_pred_lr),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model object and predicted scores on the validation sample to local disk\n",
    "# pickle.dump(lr, open(results_dir + \"/lr.p\", \"wb\"))\n",
    "pickle.dump(list(y_test_pred_lr), open(results_dir + \"/y_test_pred_lr.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_lr(train):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grad_6years):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        X_1 = train_part_new.loc[:,predictors]\n",
    "        y_1 = train_part_new.grad_6years\n",
    "        X_2 = test_part_new.loc[:,predictors]\n",
    "        y_2 = test_part_new.grad_6years\n",
    "        model = LogisticRegression(random_state=1234)\n",
    "        model.fit(X_1,y_1)\n",
    "        p,r,t = precision_recall_curve(y_2, model.predict_proba(X_2)[:,1])\n",
    "        auc = roc_auc_score(y_2, model.predict_proba(X_2)[:,1])\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755915092902458 0.005418749221475392\n"
     ]
    }
   ],
   "source": [
    "best_threshold = cross_validation_lr(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38643128923361736"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(np.array(y_test_pred) > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.386:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18189.0   3619.0  21808.0\n",
      "Real_1   2512.0   8795.0  11307.0\n",
      "        20701.0  12414.0  33115.0\n",
      "\n",
      "F1 score = 0.7415\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "pr_lr = create_confusion_matrix(y_test_pred_lr, best_threshold, \"LR1_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.438:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18817.0   2991.0  21808.0\n",
      "Real_1   2972.0   8335.0  11307.0\n",
      "        21789.0  11326.0  33115.0\n",
      "\n",
      "F1 score = 0.7365\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.grad_6years))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred_lr)[:num_of_0]] = 0\n",
    "alternative_threshold = y_test_pred_lr[np.argsort(y_test_pred_lr)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "pr2_lr = create_confusion_matrix(y_test_pred_binary, best_threshold, \"LR1_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df = pd.DataFrame([(best_threshold,)+pr_lr,(alternative_threshold,)+pr2_lr]).round(4)\n",
    "precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df.to_csv(results_dir + \"LR1_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Run the OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ols = sm.OLS(y_train, add_constant(X_train,prepend=True)).fit()\n",
    "except LinAlgError:\n",
    "    ols = LinearRegression()\n",
    "    ols.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS:\n",
      "AUC = 0.8762\n"
     ]
    }
   ],
   "source": [
    "print(\"OLS:\")\n",
    "if type(ols) == LinearRegression:\n",
    "    y_test_pred_ols = list(ols.predict(X_test))\n",
    "else:\n",
    "    y_test_pred_ols = list(ols.predict(add_constant(X_test, prepend=True)))\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test, y_test_pred_ols),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ols, open(results_dir + \"/ols.p\", \"wb\"))\n",
    "pickle.dump(list(y_test_pred_ols), open(results_dir + \"y_test_pred_ols.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_ols(train):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grad_6years):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        X_1 = train_part_new.loc[:,predictors]\n",
    "        y_1 = train_part_new.grad_6years\n",
    "        X_2 = test_part_new.loc[:,predictors]\n",
    "        y_2 = test_part_new.grad_6years\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_2,y_2)\n",
    "        p,r,t = precision_recall_curve(y_2, model.predict(X_2))\n",
    "        auc = roc_auc_score(y_2, model.predict(X_2))\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9034157202934319 0.005268666942512579\n"
     ]
    }
   ],
   "source": [
    "best_threshold_3 = cross_validation_ols(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4250315407143919"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.425:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18232.0   3576.0  21808.0\n",
      "Real_1   2673.0   8634.0  11307.0\n",
      "        20905.0  12210.0  33115.0\n",
      "\n",
      "F1 score = 0.7343\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold_3,3))))\n",
    "pr_ols = create_confusion_matrix(y_test_pred_ols, best_threshold_3, \"OLS_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.454:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18726.0   3082.0  21808.0\n",
      "Real_1   3063.0   8244.0  11307.0\n",
      "        21789.0  11326.0  33115.0\n",
      "\n",
      "F1 score = 0.7285\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.grad_6years))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred_ols)[:num_of_0]] = 0\n",
    "alternative_threshold_3 = y_test_pred_ols[np.argsort(y_test_pred_ols)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold_3,3))))\n",
    "pr2_ols = create_confusion_matrix(y_test_pred_binary, best_threshold_3, \"OLS_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df_3 = pd.DataFrame([(best_threshold_3,)+pr_ols,(alternative_threshold_3,)+pr2_ols]).round(4)\n",
    "precision_recall_df_3.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df_3.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df_3.to_csv(results_dir + \"OLS_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### (3) Comparison with reduced validation sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomly select 10% observations from the original validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_old = df[df.valid == 1]\n",
    "_, test_df_reduced = train_test_split(test_df_old, test_size=0.1, stratify=test_df_old['grad_6years'].astype(str)+\"_\"+test_df_old['available_sum'].astype(str), random_state=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "_, test_df_reduced_new = impute(train_df, test_df_reduced)\n",
    "X_test_reduced = test_df_reduced_new.loc[:,predictors]\n",
    "y_test_reduced = test_df_reduced_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir_new1 = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\smaller_training_sample\\\\test1\\\\comparison_1\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "AUC = 0.8815\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "if type(lr) == LogisticRegression:\n",
    "    y_test_reduced_pred_lr = list(lr.predict_proba(X_test_reduced)[:,1])\n",
    "else:\n",
    "    y_test_reduced_pred_lr = list(lr.predict(add_constant(X_test_reduced, prepend=True)))\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test_reduced, y_test_reduced_pred_lr),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_reduced_pred_lr), open(results_dir_new1 + \"y_test_pred_lr.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix_new(y_test, y_test_pred, threshold, fpath, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(np.array(y_test_pred) > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(fpath + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pr(train_df, y_test, y_test_pred, best_threshold, fpath, mn):\n",
    "    print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "    pr_lr = create_confusion_matrix_new(y_test, y_test_pred, best_threshold, fpath, \"{}_cm1\".format(mn))\n",
    "\n",
    "    num_of_0 = int(round((1-np.mean(train_df.grad_6years))*len(y_test)))\n",
    "    y_test_pred_binary = np.ones(len(y_test))\n",
    "    y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "    alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "    pr2_lr = create_confusion_matrix_new(y_test, y_test_pred_binary, best_threshold, fpath, \"{}_cm2\".format(mn))\n",
    "\n",
    "    precision_recall_df = pd.DataFrame([(best_threshold,)+pr_lr,(alternative_threshold,)+pr2_lr]).round(4)\n",
    "    precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "    precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "    precision_recall_df.to_csv(fpath + \"{}_precision_recall.csv\".format(mn), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.386:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1839.0   342.0  2181.0\n",
      "Real_1   242.0   889.0  1131.0\n",
      "        2081.0  1231.0  3312.0\n",
      "\n",
      "F1 score = 0.7528\n",
      "\n",
      "\n",
      "\n",
      "Alternative threshold = 0.437:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1895.0   286.0  2181.0\n",
      "Real_1   284.0   847.0  1131.0\n",
      "        2179.0  1133.0  3312.0\n",
      "\n",
      "F1 score = 0.7482\n"
     ]
    }
   ],
   "source": [
    "create_pr(train_df, y_test_reduced, y_test_reduced_pred_lr, best_threshold, results_dir_new1, \"LR1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS:\n",
      "AUC = 0.8773\n"
     ]
    }
   ],
   "source": [
    "print(\"OLS:\")\n",
    "if type(ols) == LinearRegression:\n",
    "    y_test_reduced_pred_ols = list(ols.predict(X_test_reduced))\n",
    "else:\n",
    "    y_test_reduced_pred_ols = list(ols.predict(add_constant(X_test_reduced, prepend=True)))\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test_reduced, y_test_reduced_pred_ols),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_reduced_pred_ols), open(results_dir_new1 + \"y_test_pred_ols.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.425:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1838.0   343.0  2181.0\n",
      "Real_1   257.0   874.0  1131.0\n",
      "        2095.0  1217.0  3312.0\n",
      "\n",
      "F1 score = 0.7445\n",
      "\n",
      "\n",
      "\n",
      "Alternative threshold = 0.455:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1877.0   304.0  2181.0\n",
      "Real_1   302.0   829.0  1131.0\n",
      "        2179.0  1133.0  3312.0\n",
      "\n",
      "F1 score = 0.7323\n"
     ]
    }
   ],
   "source": [
    "create_pr(train_df, y_test_reduced, y_test_reduced_pred_ols, best_threshold_3, results_dir_new1, \"OLS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) Comparison with the base model (trained on the full training data), using the reduced validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_predictors\\\\\"\n",
    "base_lr = pickle.load(open(model_dir + \"lr.p\", \"rb\"))\n",
    "base_ols = pickle.load(open(model_dir + \"ols.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_old = df[df.valid == 0]\n",
    "test_df_old = df[df.valid == 1]\n",
    "_, test_df_reduced = train_test_split(test_df_old, test_size=0.1, stratify=test_df_old['grad_6years'].astype(str)+\"_\"+test_df_old['available_sum'].astype(str), random_state=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "_, test_df_reduced_new = impute(train_df_old, test_df_reduced)\n",
    "X_test_reduced = test_df_reduced_new.loc[:,predictors]\n",
    "y_test_reduced = test_df_reduced_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir_new2 = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\smaller_training_sample\\\\test1\\\\comparison_2\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "AUC = 0.8861\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "if type(base_lr) == LogisticRegression:\n",
    "    y_test_reduced_pred_lr = list(base_lr.predict_proba(X_test_reduced)[:,1])\n",
    "else:\n",
    "    y_test_reduced_pred_lr = list(base_lr.predict(add_constant(X_test_reduced, prepend=True)))\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test_reduced, y_test_reduced_pred_lr),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_reduced_pred_lr), open(results_dir_new2 + \"y_test_pred_lr.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.433:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1896.0   285.0  2181.0\n",
      "Real_1   274.0   857.0  1131.0\n",
      "        2170.0  1142.0  3312.0\n",
      "\n",
      "F1 score = 0.7541\n",
      "\n",
      "\n",
      "\n",
      "Alternative threshold = 0.438:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1901.0   280.0  2181.0\n",
      "Real_1   278.0   853.0  1131.0\n",
      "        2179.0  1133.0  3312.0\n",
      "\n",
      "F1 score = 0.7535\n"
     ]
    }
   ],
   "source": [
    "create_pr(train_df_old, y_test_reduced, y_test_reduced_pred_lr, 0.43344163040148626, results_dir_new2, \"LR1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS:\n",
      "AUC = 0.8807\n"
     ]
    }
   ],
   "source": [
    "print(\"OLS:\")\n",
    "if type(ols) == LinearRegression:\n",
    "    y_test_reduced_pred_ols = list(base_ols.predict(X_test_reduced))\n",
    "else:\n",
    "    y_test_reduced_pred_ols = list(base_ols.predict(add_constant(X_test_reduced, prepend=True)))\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test_reduced, y_test_reduced_pred_ols),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(y_test_reduced_pred_ols), open(results_dir_new2 + \"y_test_pred_ols.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.469:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1911.0   270.0  2181.0\n",
      "Real_1   318.0   813.0  1131.0\n",
      "        2229.0  1083.0  3312.0\n",
      "\n",
      "F1 score = 0.7344\n",
      "\n",
      "\n",
      "\n",
      "Alternative threshold = 0.451:\n",
      "\n",
      "        Pred_0  Pred_1        \n",
      "Real_0  1890.0   291.0  2181.0\n",
      "Real_1   289.0   842.0  1131.0\n",
      "        2179.0  1133.0  3312.0\n",
      "\n",
      "F1 score = 0.7438\n"
     ]
    }
   ],
   "source": [
    "create_pr(train_df_old, y_test_reduced, y_test_reduced_pred_ols, 0.46918787407941415, results_dir_new2, \"OLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
