{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "\n",
    "# Other common imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = \"C:/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_part1 = pickle.load(open(\"lstm_data_3/part1_train_X.p\", \"rb\"))\n",
    "X_valid_part1 = pickle.load(open(\"lstm_data_3/part1_valid_X.p\", \"rb\"))\n",
    "X_test_part1 = pickle.load(open(\"lstm_data_3/part1_test_X.p\", \"rb\"))\n",
    "X_train_part2 = np.load(\"lstm_data_3/part2_train_X.npy\")\n",
    "X_valid_part2 = np.load(\"lstm_data_3/part2_valid_X.npy\")\n",
    "X_test_part2 = np.load(\"lstm_data_3/part2_test_X.npy\")\n",
    "y_train = np.load(\"lstm_data_3/train_y.npy\")\n",
    "y_valid = np.load(\"lstm_data_3/valid_y.npy\")\n",
    "y_test = np.load(\"lstm_data_3/test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test_batches(X, X2):\n",
    "    while True:\n",
    "        for i in range(len(X)):\n",
    "            yield [X[i][np.newaxis,:,:], X2[np.newaxis,i,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load models fitted in Rivanna\n",
    "model = keras.models.load_model(fpath + \"output_3/lstm_model_simple.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-65939528298d>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "\n",
      "LSTM Model 1 Simple:\n",
      "C-statistic = 0.8947086838009672\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = np.asarray(model.predict_generator(generate_test_batches(X_valid_part1, X_valid_part2),\n",
    "                          steps=len(X_valid_part1)))\n",
    "valid_auc = \\\n",
    "roc_auc_score(y_valid, y_valid_pred)\n",
    "print(\"\\nLSTM Model 1 Simple:\\nC-statistic = {}\\n\\n\".format(valid_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Model 1 Simple:\n",
      "C-statistic = 0.8955866659386361\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_auc = \\\n",
    "roc_auc_score(y_test, np.asarray(model.predict_generator(generate_test_batches(X_test_part1, X_test_part2),\n",
    "                                                           steps=len(X_test_part1))))\n",
    "print(\"\\nLSTM Model 1 Simple:\\nC-statistic = {}\\n\\n\".format(test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.asarray(model.predict_generator(generate_test_batches(X_test_part1, X_test_part2),\n",
    "                                                 steps=len(X_test_part1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3925025"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,r,t = precision_recall_curve(y_valid, y_valid_pred)\n",
    "best_threshold = find_optimal_threshold(p,r,t)\n",
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 1 = 0.7608\n",
      "F1 score 0 = 0.8717\n"
     ]
    }
   ],
   "source": [
    "cm_arr = confusion_matrix(y_test, np.where(y_test_pred > best_threshold, 1, 0))\n",
    "cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "print(\"F1 score 1 = {}\".format(round(2*p1*r1/(p1+r1),4)))\n",
    "print(\"F1 score 0 = {}\".format(round(2*p0*r0/(p0+r0),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.7445, 0.7778]), array([0.8821, 0.8616]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision/Recall for both graduates and non-graduates\n",
    "np.round(np.array([p1,r1]), 4), np.round(np.array([p0,r0]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(y_test_pred[:,0], open(fpath + \"y_test_pred_rnn_simple.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
