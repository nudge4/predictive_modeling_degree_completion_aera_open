{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "fpath = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\intermediate_files\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random truncation procedure for the training/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_nth = pd.read_stata(fpath+\"enrolled_nth.dta\")\n",
    "truncation_ss = pd.read_stata(fpath+\"truncation_sample_sizes.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ss = {}\n",
    "valid_ss = {}\n",
    "for i in range(truncation_ss.shape[0]):\n",
    "    nth_term = truncation_ss.nth_term.iloc[i]\n",
    "    tss = truncation_ss.train_sample_size.iloc[i]\n",
    "    vss = truncation_ss.valid_sample_size.iloc[i]\n",
    "    train_ss[nth_term] = tss\n",
    "    valid_ss[nth_term] = vss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_ind = pd.read_stata(fpath+\"full_data_enrolled_terms.dta\").loc[:,['vccsid','valid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 300144, 1.0: 33350})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_ind.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 298139\n",
      "Validation sample size: 33115\n"
     ]
    }
   ],
   "source": [
    "enrolled_nth_1 = valid_ind[valid_ind.valid == 0].merge(enrolled_nth, on=['vccsid'], how='inner')\n",
    "print(\"Training sample size:\", len(np.unique(enrolled_nth_1.vccsid)))\n",
    "enrolled_nth_2 = valid_ind[valid_ind.valid == 1].merge(enrolled_nth, on=['vccsid'], how='inner')\n",
    "print(\"Validation sample size:\", len(np.unique(enrolled_nth_2.vccsid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_dict = {}\n",
    "df1 = enrolled_nth.loc[:,['vccsid','first_nonde_strm']].drop_duplicates()\n",
    "for i in range(df1.shape[0]):\n",
    "    vccsid = df1.vccsid.iloc[i]\n",
    "    fns = df1.first_nonde_strm.iloc[i]\n",
    "    initial_dict[vccsid] = fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nth_dict_1 = {i:set() for i in range(1,18)}\n",
    "for i in range(enrolled_nth_1.shape[0]):\n",
    "    vccsid = enrolled_nth_1.vccsid.iloc[i]\n",
    "    nth = enrolled_nth_1.nth.iloc[i]\n",
    "    nth_dict_1[nth].add(vccsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nth_dict_2 = {i:set() for i in range(1,18)}\n",
    "for i in range(enrolled_nth_2.shape[0]):\n",
    "    vccsid = enrolled_nth_2.vccsid.iloc[i]\n",
    "    nth = enrolled_nth_2.nth.iloc[i]\n",
    "    nth_dict_2[nth].add(vccsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nth_dict_1_cp = nth_dict_1.copy()\n",
    "nth_dict_2_cp = nth_dict_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nth == 17 is sampled: 1261 out of 13330\n",
      "nth == 16 is sampled: 6698 out of 16412\n",
      "nth == 15 is sampled: 3183 out of 10709\n",
      "nth == 14 is sampled: 1793 out of 14327\n",
      "nth == 13 is sampled: 10142 out of 19535\n",
      "nth == 12 is sampled: 5285 out of 13502\n",
      "nth == 11 is sampled: 2984 out of 18864\n",
      "nth == 10 is sampled: 17628 out of 27359\n",
      "nth == 9 is sampled: 8879 out of 17669\n",
      "nth == 8 is sampled: 4541 out of 26254\n",
      "nth == 7 is sampled: 29002 out of 40607\n",
      "nth == 6 is sampled: 13590 out of 24067\n",
      "nth == 5 is sampled: 7856 out of 38191\n",
      "nth == 4 is sampled: 50554 out of 57102\n",
      "nth == 3 is sampled: 22554 out of 23998\n",
      "nth == 2 is sampled: 12896 out of 41997\n",
      "nth == 1 is sampled: 99293 out of 99293\n"
     ]
    }
   ],
   "source": [
    "### Random truncation (sampling) for training sample\n",
    "random.seed(12345)\n",
    "sample_1 = {}\n",
    "diff = 0\n",
    "for nth in range(17,0,-1):\n",
    "    tss = int(train_ss[nth]) + diff\n",
    "    pool_size = len(nth_dict_1_cp[nth])\n",
    "    if pool_size < tss:\n",
    "        sample_1[nth] = nth_dict_1_cp[nth]\n",
    "        diff = tss - pool_size\n",
    "    else:\n",
    "        sample_1[nth] = set(random.sample(nth_dict_1_cp[nth], tss))    \n",
    "    for i in range(nth,0,-1):\n",
    "        nth_dict_1_cp[i] = nth_dict_1_cp[i].difference(sample_1[nth])\n",
    "    print(\"nth == {0} is sampled: {1} out of {2}\".format(nth,min(tss, pool_size),pool_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data for Table 1 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_1 = np.array([len(sample_1[i+1]) for i in range(len(sample_1))])\n",
    "prop_1 = prop_1/np.sum(prop_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nth == 17 is sampled: 140 out of 1467\n",
      "nth == 16 is sampled: 744 out of 1836\n",
      "nth == 15 is sampled: 353 out of 1169\n",
      "nth == 14 is sampled: 199 out of 1573\n",
      "nth == 13 is sampled: 1126 out of 2207\n",
      "nth == 12 is sampled: 587 out of 1353\n",
      "nth == 11 is sampled: 331 out of 2072\n",
      "nth == 10 is sampled: 1958 out of 3001\n",
      "nth == 9 is sampled: 986 out of 1947\n",
      "nth == 8 is sampled: 504 out of 2914\n",
      "nth == 7 is sampled: 3221 out of 4495\n",
      "nth == 6 is sampled: 1510 out of 2719\n",
      "nth == 5 is sampled: 873 out of 4308\n",
      "nth == 4 is sampled: 5615 out of 6349\n",
      "nth == 3 is sampled: 2505 out of 2730\n",
      "nth == 2 is sampled: 1432 out of 4591\n",
      "nth == 1 is sampled: 11031 out of 11031\n"
     ]
    }
   ],
   "source": [
    "### Random truncation (sampling) for validation sample\n",
    "random.seed(12345)\n",
    "sample_2 = {}\n",
    "diff = 0\n",
    "for nth in range(17,0,-1):\n",
    "    vss = int(valid_ss[nth]) + diff\n",
    "    pool_size = len(nth_dict_2_cp[nth])\n",
    "    if pool_size < vss:\n",
    "        sample_2[nth] = nth_dict_2_cp[nth]\n",
    "        diff = vss - pool_size\n",
    "    else:\n",
    "        sample_2[nth] = set(random.sample(nth_dict_2_cp[nth], vss))    \n",
    "    for i in range(nth,0,-1):\n",
    "        nth_dict_2_cp[i] = nth_dict_2_cp[i].difference(sample_2[nth])\n",
    "    print(\"nth == {0} is sampled: {1} out of {2}\".format(nth,min(vss, pool_size),pool_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_2 = np.array([len(sample_2[i+1]) for i in range(len(sample_2))])\n",
    "prop_2 = prop_2/np.sum(prop_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nth_term  crnt_cohort  truncated_train  truncated_validation\n",
      "0          1       0.3330           0.3330                0.3331\n",
      "1          2       0.0433           0.0433                0.0432\n",
      "2          3       0.0757           0.0756                0.0756\n",
      "3          4       0.1696           0.1696                0.1696\n",
      "4          5       0.0263           0.0264                0.0264\n",
      "5          6       0.0456           0.0456                0.0456\n",
      "6          7       0.0973           0.0973                0.0973\n",
      "7          8       0.0152           0.0152                0.0152\n",
      "8          9       0.0298           0.0298                0.0298\n",
      "9         10       0.0591           0.0591                0.0591\n",
      "10        11       0.0100           0.0100                0.0100\n",
      "11        12       0.0177           0.0177                0.0177\n",
      "12        13       0.0340           0.0340                0.0340\n",
      "13        14       0.0060           0.0060                0.0060\n",
      "14        15       0.0107           0.0107                0.0107\n",
      "15        16       0.0225           0.0225                0.0225\n",
      "16        17       0.0042           0.0042                0.0042\n"
     ]
    }
   ],
   "source": [
    "prop_df = pd.DataFrame({\"nth_term\": range(1,18),\n",
    "                        \"crnt_cohort\": np.round(truncation_ss.prop,4), \n",
    "                        \"truncated_train\": np.round(prop_1,4),\n",
    "                        \"truncated_validation\": np.round(prop_2,4)})\\\n",
    ".loc[:,['nth_term', 'crnt_cohort', 'truncated_train', 'truncated_validation']]\n",
    "print(prop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_df.to_csv(fpath + \"proportion_after_truncation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the end term of each observation after truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298139 33115\n"
     ]
    }
   ],
   "source": [
    "new_nth_dict = {}\n",
    "s1 = 0\n",
    "for k,v in sample_1.items():\n",
    "    s1 += len(v)\n",
    "    for vccsid in v:\n",
    "        new_nth_dict[vccsid] = k\n",
    "s2 = 0\n",
    "for k,v in sample_2.items():\n",
    "    s2 += len(v)\n",
    "    for vccsid in v:\n",
    "        new_nth_dict[vccsid] = k\n",
    "print(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_nth_df = enrolled_nth.groupby(['vccsid', 'first_nonde_strm']).agg({'nth':'max'}).reset_index()\n",
    "new_nth_df = pd.DataFrame.from_dict(new_nth_dict, orient=\"index\").reset_index().rename(columns={0:\"new_nth\", 'index':'vccsid'})\n",
    "final_nth_df = old_nth_df.merge(new_nth_df, on=['vccsid'], how='inner').merge(valid_ind, on=['vccsid'], how='inner').sort_values(['vccsid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'truncated'] = final_nth_df.apply(lambda r: int(r.loc['nth'] > r.loc['new_nth']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truncated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.419821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.418300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       truncated\n",
       "valid           \n",
       "0.0     0.419821\n",
       "1.0     0.418300"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_nth_df.groupby(['valid']).agg({'truncated':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.83 4.83\n"
     ]
    }
   ],
   "source": [
    "print(np.round(final_nth_df[final_nth_df.valid==0].new_nth.mean(), 2),\n",
    "      np.round(final_nth_df[final_nth_df.valid==1].new_nth.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df = final_nth_df.drop(['nth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'yr'] = (final_nth_df.new_nth-1) // 3\n",
    "final_nth_df.loc[:,'t'] = (final_nth_df.new_nth-1) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'last_term'] = final_nth_df.first_nonde_strm + 10*final_nth_df.yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'last_term'] = final_nth_df.last_term + final_nth_df.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'last_term'] = final_nth_df.last_term.apply(lambda x: x+7 if x % 10 == 5 or x % 10 == 6 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df = final_nth_df.loc[:,['vccsid', 'first_nonde_strm', 'last_term', 'truncated','new_nth']]\\\n",
    ".rename(columns={'new_nth':'nth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.sort_values(['vccsid']).to_stata(fpath + \"truncation_nth_df.dta\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 110324,\n",
       "         2: 14328,\n",
       "         3: 25059,\n",
       "         4: 56169,\n",
       "         5: 8729,\n",
       "         6: 15100,\n",
       "         7: 32223,\n",
       "         8: 5045,\n",
       "         9: 9865,\n",
       "         10: 19586,\n",
       "         11: 3315,\n",
       "         12: 5872,\n",
       "         13: 11268,\n",
       "         14: 1992,\n",
       "         15: 3536,\n",
       "         16: 7442,\n",
       "         17: 1401})"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(final_nth_df.nth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check: dropped students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_terms = pd.read_stata(\"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\dta\\\\student_level_sample_and_outcomes.dta\").loc[:,['vccsid', 'first_nonde_strm', 'first_degree_strm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_nth_1_new = valid_ind[valid_ind.valid == 0].merge(enrolled_nth, on=['vccsid'], how='left')\n",
    "enrolled_nth_1_new = enrolled_nth_1_new[pd.isnull(enrolled_nth_1_new.nth)].loc[:,['vccsid']]\n",
    "enrolled_nth_1_new = enrolled_nth_1_new.merge(enrolled_terms, on=['vccsid'], how='left')\n",
    "assert (enrolled_nth_1_new.first_nonde_strm == enrolled_nth_1_new.first_degree_strm).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_nth_2_new = valid_ind[valid_ind.valid == 1].merge(enrolled_nth, on=['vccsid'], how='left')\n",
    "enrolled_nth_2_new = enrolled_nth_2_new[pd.isnull(enrolled_nth_2_new.nth)].loc[:,['vccsid']]\n",
    "enrolled_nth_2_new = enrolled_nth_2_new.merge(enrolled_terms, on=['vccsid'], how='left')\n",
    "assert (enrolled_nth_2_new.first_nonde_strm == enrolled_nth_2_new.first_degree_strm).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
