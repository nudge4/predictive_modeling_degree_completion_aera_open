{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(fpath + \"/full_data_truncated.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 51\n"
     ]
    }
   ],
   "source": [
    "demo_predictors = [\"age_entry\", \"male\", \"white\", \"afam\", \"hisp\", \"other\", \"pell_0_ind\", \"pell_1_ind\"] + \\\n",
    "[\"pell_0_\" + s1 + str(s2) for s1 in [\"fa\",\"sp\",\"su\"] for s2 in range(1,7)] + \\\n",
    "[\"pell_1_\" + s1 + str(s2) for s1 in [\"fa\",\"sp\",\"su\"] for s2 in range(1,7)] + \\\n",
    "[\"phe_\" + str(i) for i in range(1,8)]\n",
    "demo_predictors = set(demo_predictors)\n",
    "predictors = [p for p in list(df.columns)[10:] if p not in demo_predictors]\n",
    "print(len(predictors), len(demo_predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute_list_1 = set([\"prop_comp_pre\",\"cum_gpa_pre\"])\n",
    "impute_list_2 = set([t1+\"_\"+t2+str(t3) for t1 in [\"term_gpa\", \"prop_comp\", \"lvl2_prop_comp\", \"dev_prop_comp\"] for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)])\n",
    "impute_list_3 = set([\"cum_gpa\", \"lvl2_prop_comp\", \"dev_prop_comp\", \"prop_comp\", \"prop_comp_sd\", \"withdrawn_prop_comp_sd\"])\n",
    "impute_list_4 = set([\"admrate\", \"gradrate\", \"satvr25\", \"satvr75\", \"satmt25\", \"satmt75\", \"satwr25\", \"satwr75\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298139, 341) (33115, 341)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.valid == 0]\n",
    "test_df = df[df.valid == 1]\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train, test):\n",
    "    for p in impute_list_1:\n",
    "        avg_p = np.nanmean(train[train.enrolled_pre == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_\" + suffix] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_4:\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_nsc\"] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_df_new, test_df_new = impute(train_df, test_df)\n",
    "X_train = train_df_new.loc[:,predictors]\n",
    "y_train = train_df_new.grad_6years\n",
    "X_test = test_df_new.loc[:,predictors]\n",
    "y_test = test_df_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "val_indices = np.random.choice(train_df.shape[0], int(np.floor(train_df.shape[0]*0.15)), replace=False)\n",
    "train_val = train_df.iloc[val_indices,:]\n",
    "train_train = train_df.iloc[np.setdiff1d(np.arange(train_df.shape[0]), val_indices),:]\n",
    "train_train_new, train_val_new = impute(train_train, train_val)\n",
    "X_train_train = train_train_new.loc[:,predictors]\n",
    "y_train_train = train_train_new.grad_6years\n",
    "X_train_val = train_val_new.loc[:,predictors]\n",
    "y_train_val = train_val_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_train = xgb.DMatrix(X_train_train, y_train_train)\n",
    "dtrain_val = xgb.DMatrix(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_without_demo\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Grid Search for max_depth and eta (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 4, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.815242\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation-auc:0.846488\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.815242\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.85454\n",
      "[100]\tvalidation-auc:0.863548\n",
      "[150]\tvalidation-auc:0.869789\n",
      "[200]\tvalidation-auc:0.874123\n",
      "[250]\tvalidation-auc:0.87693\n",
      "[300]\tvalidation-auc:0.879151\n",
      "[350]\tvalidation-auc:0.880929\n",
      "[400]\tvalidation-auc:0.882261\n",
      "[450]\tvalidation-auc:0.883446\n",
      "[500]\tvalidation-auc:0.884466\n",
      "[550]\tvalidation-auc:0.885237\n",
      "[600]\tvalidation-auc:0.885961\n",
      "[650]\tvalidation-auc:0.886586\n",
      "[700]\tvalidation-auc:0.887085\n",
      "[750]\tvalidation-auc:0.88755\n",
      "[800]\tvalidation-auc:0.888013\n",
      "[850]\tvalidation-auc:0.888401\n",
      "[900]\tvalidation-auc:0.888756\n",
      "[950]\tvalidation-auc:0.88908\n",
      "[1000]\tvalidation-auc:0.889342\n",
      "[1050]\tvalidation-auc:0.889584\n",
      "[1100]\tvalidation-auc:0.889863\n",
      "[1150]\tvalidation-auc:0.8901\n",
      "[1200]\tvalidation-auc:0.890339\n",
      "[1250]\tvalidation-auc:0.890572\n",
      "[1300]\tvalidation-auc:0.890769\n",
      "[1350]\tvalidation-auc:0.890945\n",
      "[1400]\tvalidation-auc:0.891106\n",
      "[1450]\tvalidation-auc:0.891281\n",
      "[1500]\tvalidation-auc:0.891433\n",
      "[1550]\tvalidation-auc:0.891591\n",
      "[1600]\tvalidation-auc:0.891723\n",
      "[1650]\tvalidation-auc:0.891856\n",
      "[1700]\tvalidation-auc:0.891989\n",
      "[1750]\tvalidation-auc:0.8921\n",
      "[1800]\tvalidation-auc:0.892214\n",
      "[1850]\tvalidation-auc:0.892299\n",
      "[1900]\tvalidation-auc:0.892397\n",
      "[1950]\tvalidation-auc:0.892495\n",
      "[2000]\tvalidation-auc:0.892595\n",
      "[2050]\tvalidation-auc:0.892657\n",
      "[2100]\tvalidation-auc:0.89279\n",
      "[2150]\tvalidation-auc:0.892878\n",
      "[2200]\tvalidation-auc:0.892956\n",
      "[2250]\tvalidation-auc:0.893036\n",
      "[2300]\tvalidation-auc:0.893121\n",
      "[2350]\tvalidation-auc:0.893198\n",
      "[2400]\tvalidation-auc:0.893295\n",
      "[2450]\tvalidation-auc:0.893346\n",
      "[2500]\tvalidation-auc:0.893436\n",
      "[2550]\tvalidation-auc:0.893494\n",
      "[2600]\tvalidation-auc:0.893541\n",
      "[2650]\tvalidation-auc:0.893614\n",
      "[2700]\tvalidation-auc:0.893659\n",
      "Stopping. Best iteration:\n",
      "[2715]\tvalidation-auc:0.893672\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.815242\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.867339\n",
      "[100]\tvalidation-auc:0.877054\n",
      "[150]\tvalidation-auc:0.881465\n",
      "[200]\tvalidation-auc:0.884391\n",
      "[250]\tvalidation-auc:0.886245\n",
      "[300]\tvalidation-auc:0.887789\n",
      "[350]\tvalidation-auc:0.888583\n",
      "[400]\tvalidation-auc:0.889413\n",
      "[450]\tvalidation-auc:0.890109\n",
      "[500]\tvalidation-auc:0.890618\n",
      "[550]\tvalidation-auc:0.89106\n",
      "[600]\tvalidation-auc:0.891481\n",
      "[650]\tvalidation-auc:0.891862\n",
      "[700]\tvalidation-auc:0.892104\n",
      "[750]\tvalidation-auc:0.89237\n",
      "[800]\tvalidation-auc:0.892572\n",
      "[850]\tvalidation-auc:0.892774\n",
      "[900]\tvalidation-auc:0.892977\n",
      "[950]\tvalidation-auc:0.893206\n",
      "[1000]\tvalidation-auc:0.893374\n",
      "Stopping. Best iteration:\n",
      "[1028]\tvalidation-auc:0.893449\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.815242\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.877188\n",
      "[100]\tvalidation-auc:0.884159\n",
      "[150]\tvalidation-auc:0.887447\n",
      "[200]\tvalidation-auc:0.8892\n",
      "[250]\tvalidation-auc:0.890367\n",
      "[300]\tvalidation-auc:0.891173\n",
      "[350]\tvalidation-auc:0.891585\n",
      "[400]\tvalidation-auc:0.892094\n",
      "[450]\tvalidation-auc:0.892461\n",
      "[500]\tvalidation-auc:0.892794\n",
      "Stopping. Best iteration:\n",
      "[502]\tvalidation-auc:0.892803\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.815242\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.884161\n",
      "[100]\tvalidation-auc:0.888871\n",
      "[150]\tvalidation-auc:0.890499\n",
      "[200]\tvalidation-auc:0.891395\n",
      "[250]\tvalidation-auc:0.892217\n",
      "[300]\tvalidation-auc:0.892668\n",
      "[350]\tvalidation-auc:0.892893\n",
      "Stopping. Best iteration:\n",
      "[353]\tvalidation-auc:0.892915\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.858568\n",
      "[100]\tvalidation-auc:0.862864\n",
      "[150]\tvalidation-auc:0.8671\n",
      "[200]\tvalidation-auc:0.870413\n",
      "[250]\tvalidation-auc:0.873177\n",
      "[300]\tvalidation-auc:0.875449\n",
      "[350]\tvalidation-auc:0.877324\n",
      "[400]\tvalidation-auc:0.879012\n",
      "[450]\tvalidation-auc:0.880444\n",
      "[500]\tvalidation-auc:0.881665\n",
      "[550]\tvalidation-auc:0.882672\n",
      "[600]\tvalidation-auc:0.883621\n",
      "[650]\tvalidation-auc:0.884483\n",
      "[700]\tvalidation-auc:0.885263\n",
      "[750]\tvalidation-auc:0.885931\n",
      "[800]\tvalidation-auc:0.886523\n",
      "[850]\tvalidation-auc:0.887029\n",
      "[900]\tvalidation-auc:0.887491\n",
      "[950]\tvalidation-auc:0.887923\n",
      "[1000]\tvalidation-auc:0.888293\n",
      "[1050]\tvalidation-auc:0.888662\n",
      "[1100]\tvalidation-auc:0.888986\n",
      "[1150]\tvalidation-auc:0.889267\n",
      "[1200]\tvalidation-auc:0.889549\n",
      "[1250]\tvalidation-auc:0.889811\n",
      "[1300]\tvalidation-auc:0.89001\n",
      "[1350]\tvalidation-auc:0.890242\n",
      "[1400]\tvalidation-auc:0.890441\n",
      "[1450]\tvalidation-auc:0.890669\n",
      "[1500]\tvalidation-auc:0.890852\n",
      "[1550]\tvalidation-auc:0.891029\n",
      "[1600]\tvalidation-auc:0.891202\n",
      "[1650]\tvalidation-auc:0.891361\n",
      "[1700]\tvalidation-auc:0.891519\n",
      "[1750]\tvalidation-auc:0.891656\n",
      "[1800]\tvalidation-auc:0.891776\n",
      "[1850]\tvalidation-auc:0.891901\n",
      "[1900]\tvalidation-auc:0.892017\n",
      "[1950]\tvalidation-auc:0.892132\n",
      "[2000]\tvalidation-auc:0.892249\n",
      "[2050]\tvalidation-auc:0.892348\n",
      "[2100]\tvalidation-auc:0.892453\n",
      "[2150]\tvalidation-auc:0.89258\n",
      "[2200]\tvalidation-auc:0.892671\n",
      "[2250]\tvalidation-auc:0.892756\n",
      "[2300]\tvalidation-auc:0.892853\n",
      "[2350]\tvalidation-auc:0.892942\n",
      "[2400]\tvalidation-auc:0.893035\n",
      "[2450]\tvalidation-auc:0.893102\n",
      "[2500]\tvalidation-auc:0.893205\n",
      "[2550]\tvalidation-auc:0.893278\n",
      "[2600]\tvalidation-auc:0.89334\n",
      "[2650]\tvalidation-auc:0.893412\n",
      "[2700]\tvalidation-auc:0.893483\n",
      "[2750]\tvalidation-auc:0.893554\n",
      "[2800]\tvalidation-auc:0.893618\n",
      "[2850]\tvalidation-auc:0.893675\n",
      "[2900]\tvalidation-auc:0.893745\n",
      "[2950]\tvalidation-auc:0.893812\n",
      "[3000]\tvalidation-auc:0.893866\n",
      "[3050]\tvalidation-auc:0.893917\n",
      "[3100]\tvalidation-auc:0.893982\n",
      "[3150]\tvalidation-auc:0.894028\n",
      "[3200]\tvalidation-auc:0.894074\n",
      "[3250]\tvalidation-auc:0.894116\n",
      "[3300]\tvalidation-auc:0.894175\n",
      "[3350]\tvalidation-auc:0.894232\n",
      "[3400]\tvalidation-auc:0.894285\n",
      "[3450]\tvalidation-auc:0.894331\n",
      "[3500]\tvalidation-auc:0.894359\n",
      "Stopping. Best iteration:\n",
      "[3529]\tvalidation-auc:0.894389\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.862859\n",
      "[100]\tvalidation-auc:0.870387\n",
      "[150]\tvalidation-auc:0.875352\n",
      "[200]\tvalidation-auc:0.87887\n",
      "[250]\tvalidation-auc:0.88145\n",
      "[300]\tvalidation-auc:0.883524\n",
      "[350]\tvalidation-auc:0.88514\n",
      "[400]\tvalidation-auc:0.886373\n",
      "[450]\tvalidation-auc:0.887342\n",
      "[500]\tvalidation-auc:0.888086\n",
      "[550]\tvalidation-auc:0.888789\n",
      "[600]\tvalidation-auc:0.889323\n",
      "[650]\tvalidation-auc:0.88984\n",
      "[700]\tvalidation-auc:0.890222\n",
      "[750]\tvalidation-auc:0.890627\n",
      "[800]\tvalidation-auc:0.890986\n",
      "[850]\tvalidation-auc:0.891294\n",
      "[900]\tvalidation-auc:0.891573\n",
      "[950]\tvalidation-auc:0.89184\n",
      "[1000]\tvalidation-auc:0.892117\n",
      "[1050]\tvalidation-auc:0.892359\n",
      "[1100]\tvalidation-auc:0.892577\n",
      "[1150]\tvalidation-auc:0.892723\n",
      "[1200]\tvalidation-auc:0.892923\n",
      "[1250]\tvalidation-auc:0.893098\n",
      "[1300]\tvalidation-auc:0.89325\n",
      "[1350]\tvalidation-auc:0.893367\n",
      "[1400]\tvalidation-auc:0.893471\n",
      "[1450]\tvalidation-auc:0.89361\n",
      "[1500]\tvalidation-auc:0.89374\n",
      "[1550]\tvalidation-auc:0.893861\n",
      "[1600]\tvalidation-auc:0.893982\n",
      "[1650]\tvalidation-auc:0.894058\n",
      "[1700]\tvalidation-auc:0.894153\n",
      "[1750]\tvalidation-auc:0.894243\n",
      "[1800]\tvalidation-auc:0.894352\n",
      "[1850]\tvalidation-auc:0.894427\n",
      "Stopping. Best iteration:\n",
      "[1866]\tvalidation-auc:0.894451\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.87332\n",
      "[100]\tvalidation-auc:0.881483\n",
      "[150]\tvalidation-auc:0.8855\n",
      "[200]\tvalidation-auc:0.887942\n",
      "[250]\tvalidation-auc:0.889417\n",
      "[300]\tvalidation-auc:0.890574\n",
      "[350]\tvalidation-auc:0.891339\n",
      "[400]\tvalidation-auc:0.891989\n",
      "[450]\tvalidation-auc:0.892459\n",
      "[500]\tvalidation-auc:0.892891\n",
      "[550]\tvalidation-auc:0.893187\n",
      "[600]\tvalidation-auc:0.893483\n",
      "[650]\tvalidation-auc:0.893711\n",
      "[700]\tvalidation-auc:0.89391\n",
      "[750]\tvalidation-auc:0.894097\n",
      "[800]\tvalidation-auc:0.894271\n",
      "[850]\tvalidation-auc:0.894415\n",
      "[900]\tvalidation-auc:0.894532\n",
      "[950]\tvalidation-auc:0.894704\n",
      "[1000]\tvalidation-auc:0.894824\n",
      "Stopping. Best iteration:\n",
      "[995]\tvalidation-auc:0.894834\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.881601\n",
      "[100]\tvalidation-auc:0.887892\n",
      "[150]\tvalidation-auc:0.890316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation-auc:0.891763\n",
      "[250]\tvalidation-auc:0.892559\n",
      "[300]\tvalidation-auc:0.893075\n",
      "[350]\tvalidation-auc:0.893561\n",
      "[400]\tvalidation-auc:0.894006\n",
      "[450]\tvalidation-auc:0.894192\n",
      "[500]\tvalidation-auc:0.894394\n",
      "Stopping. Best iteration:\n",
      "[505]\tvalidation-auc:0.894425\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.88735\n",
      "[100]\tvalidation-auc:0.890857\n",
      "[150]\tvalidation-auc:0.891927\n",
      "Stopping. Best iteration:\n",
      "[180]\tvalidation-auc:0.892388\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.837279\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.865026\n",
      "[100]\tvalidation-auc:0.869205\n",
      "[150]\tvalidation-auc:0.872482\n",
      "[200]\tvalidation-auc:0.875195\n",
      "[250]\tvalidation-auc:0.877569\n",
      "[300]\tvalidation-auc:0.879518\n",
      "[350]\tvalidation-auc:0.881147\n",
      "[400]\tvalidation-auc:0.882596\n",
      "[450]\tvalidation-auc:0.883853\n",
      "[500]\tvalidation-auc:0.884971\n",
      "[550]\tvalidation-auc:0.885994\n",
      "[600]\tvalidation-auc:0.886807\n",
      "[650]\tvalidation-auc:0.887661\n",
      "[700]\tvalidation-auc:0.888317\n",
      "[750]\tvalidation-auc:0.888864\n",
      "[800]\tvalidation-auc:0.889292\n",
      "[850]\tvalidation-auc:0.889755\n",
      "[900]\tvalidation-auc:0.890109\n",
      "[950]\tvalidation-auc:0.890461\n",
      "[1000]\tvalidation-auc:0.890737\n",
      "[1050]\tvalidation-auc:0.891069\n",
      "[1100]\tvalidation-auc:0.891343\n",
      "[1150]\tvalidation-auc:0.891576\n",
      "[1200]\tvalidation-auc:0.891812\n",
      "[1250]\tvalidation-auc:0.892031\n",
      "[1300]\tvalidation-auc:0.892224\n",
      "[1350]\tvalidation-auc:0.892399\n",
      "[1400]\tvalidation-auc:0.892562\n",
      "[1450]\tvalidation-auc:0.89275\n",
      "[1500]\tvalidation-auc:0.892937\n",
      "[1550]\tvalidation-auc:0.893068\n",
      "[1600]\tvalidation-auc:0.893195\n",
      "[1650]\tvalidation-auc:0.893318\n",
      "[1700]\tvalidation-auc:0.893462\n",
      "[1750]\tvalidation-auc:0.893573\n",
      "[1800]\tvalidation-auc:0.893681\n",
      "[1850]\tvalidation-auc:0.893796\n",
      "[1900]\tvalidation-auc:0.893898\n",
      "[1950]\tvalidation-auc:0.893984\n",
      "[2000]\tvalidation-auc:0.894075\n",
      "[2050]\tvalidation-auc:0.894163\n",
      "[2100]\tvalidation-auc:0.894267\n",
      "[2150]\tvalidation-auc:0.894367\n",
      "[2200]\tvalidation-auc:0.894432\n",
      "[2250]\tvalidation-auc:0.894488\n",
      "[2300]\tvalidation-auc:0.894567\n",
      "[2350]\tvalidation-auc:0.894633\n",
      "[2400]\tvalidation-auc:0.894699\n",
      "[2450]\tvalidation-auc:0.894744\n",
      "[2500]\tvalidation-auc:0.89484\n",
      "[2550]\tvalidation-auc:0.89491\n",
      "[2600]\tvalidation-auc:0.894966\n",
      "[2650]\tvalidation-auc:0.895033\n",
      "[2700]\tvalidation-auc:0.895093\n",
      "[2750]\tvalidation-auc:0.895157\n",
      "[2800]\tvalidation-auc:0.895207\n",
      "[2850]\tvalidation-auc:0.895244\n",
      "[2900]\tvalidation-auc:0.895293\n",
      "[2950]\tvalidation-auc:0.895345\n",
      "[3000]\tvalidation-auc:0.895396\n",
      "[3050]\tvalidation-auc:0.895446\n",
      "[3100]\tvalidation-auc:0.895484\n",
      "Stopping. Best iteration:\n",
      "[3091]\tvalidation-auc:0.895485\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.837279\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.868925\n",
      "[100]\tvalidation-auc:0.875123\n",
      "[150]\tvalidation-auc:0.879239\n",
      "[200]\tvalidation-auc:0.882383\n",
      "[250]\tvalidation-auc:0.884815\n",
      "[300]\tvalidation-auc:0.886763\n",
      "[350]\tvalidation-auc:0.888164\n",
      "[400]\tvalidation-auc:0.889156\n",
      "[450]\tvalidation-auc:0.890044\n",
      "[500]\tvalidation-auc:0.890767\n",
      "[550]\tvalidation-auc:0.891297\n",
      "[600]\tvalidation-auc:0.891759\n",
      "[650]\tvalidation-auc:0.892124\n",
      "[700]\tvalidation-auc:0.892404\n",
      "[750]\tvalidation-auc:0.892708\n",
      "[800]\tvalidation-auc:0.892977\n",
      "[850]\tvalidation-auc:0.893212\n",
      "[900]\tvalidation-auc:0.893439\n",
      "[950]\tvalidation-auc:0.893698\n",
      "[1000]\tvalidation-auc:0.893885\n",
      "[1050]\tvalidation-auc:0.89407\n",
      "[1100]\tvalidation-auc:0.89423\n",
      "[1150]\tvalidation-auc:0.894346\n",
      "[1200]\tvalidation-auc:0.894483\n",
      "[1250]\tvalidation-auc:0.894591\n",
      "[1300]\tvalidation-auc:0.894707\n",
      "[1350]\tvalidation-auc:0.894793\n",
      "[1400]\tvalidation-auc:0.894889\n",
      "[1450]\tvalidation-auc:0.894997\n",
      "[1500]\tvalidation-auc:0.895053\n",
      "Stopping. Best iteration:\n",
      "[1524]\tvalidation-auc:0.895111\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.837279\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.877238\n",
      "[100]\tvalidation-auc:0.884838\n",
      "[150]\tvalidation-auc:0.888476\n",
      "[200]\tvalidation-auc:0.89048\n",
      "[250]\tvalidation-auc:0.891611\n",
      "[300]\tvalidation-auc:0.892418\n",
      "[350]\tvalidation-auc:0.89302\n",
      "[400]\tvalidation-auc:0.893549\n",
      "[450]\tvalidation-auc:0.893979\n",
      "[500]\tvalidation-auc:0.894273\n",
      "[550]\tvalidation-auc:0.894434\n",
      "[600]\tvalidation-auc:0.894628\n",
      "Stopping. Best iteration:\n",
      "[591]\tvalidation-auc:0.89465\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.837279\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.884444\n",
      "[100]\tvalidation-auc:0.889926\n",
      "[150]\tvalidation-auc:0.891882\n",
      "[200]\tvalidation-auc:0.893004\n",
      "[250]\tvalidation-auc:0.8935\n",
      "[300]\tvalidation-auc:0.894106\n",
      "Stopping. Best iteration:\n",
      "[320]\tvalidation-auc:0.894302\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.837279\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.889333\n",
      "[100]\tvalidation-auc:0.892434\n",
      "[150]\tvalidation-auc:0.892945\n",
      "Stopping. Best iteration:\n",
      "[178]\tvalidation-auc:0.893212\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.844291\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870216\n",
      "[100]\tvalidation-auc:0.873717\n",
      "[150]\tvalidation-auc:0.876478\n",
      "[200]\tvalidation-auc:0.87892\n",
      "[250]\tvalidation-auc:0.880958\n",
      "[300]\tvalidation-auc:0.882706\n",
      "[350]\tvalidation-auc:0.884141\n",
      "[400]\tvalidation-auc:0.885463\n",
      "[450]\tvalidation-auc:0.886636\n",
      "[500]\tvalidation-auc:0.887659\n",
      "[550]\tvalidation-auc:0.888535\n",
      "[600]\tvalidation-auc:0.88935\n",
      "[650]\tvalidation-auc:0.890008\n",
      "[700]\tvalidation-auc:0.890558\n",
      "[750]\tvalidation-auc:0.891018\n",
      "[800]\tvalidation-auc:0.891398\n",
      "[850]\tvalidation-auc:0.891753\n",
      "[900]\tvalidation-auc:0.892069\n",
      "[950]\tvalidation-auc:0.892369\n",
      "[1000]\tvalidation-auc:0.892636\n",
      "[1050]\tvalidation-auc:0.892909\n",
      "[1100]\tvalidation-auc:0.893123\n",
      "[1150]\tvalidation-auc:0.893309\n",
      "[1200]\tvalidation-auc:0.89354\n",
      "[1250]\tvalidation-auc:0.893711\n",
      "[1300]\tvalidation-auc:0.893862\n",
      "[1350]\tvalidation-auc:0.894027\n",
      "[1400]\tvalidation-auc:0.894153\n",
      "[1450]\tvalidation-auc:0.89429\n",
      "[1500]\tvalidation-auc:0.894419\n",
      "[1550]\tvalidation-auc:0.894541\n",
      "[1600]\tvalidation-auc:0.894655\n",
      "[1650]\tvalidation-auc:0.894774\n",
      "[1700]\tvalidation-auc:0.894882\n",
      "[1750]\tvalidation-auc:0.894964\n",
      "[1800]\tvalidation-auc:0.895053\n",
      "[1850]\tvalidation-auc:0.895131\n",
      "[1900]\tvalidation-auc:0.895223\n",
      "[1950]\tvalidation-auc:0.895296\n",
      "[2000]\tvalidation-auc:0.895363\n",
      "[2050]\tvalidation-auc:0.89542\n",
      "[2100]\tvalidation-auc:0.895512\n",
      "[2150]\tvalidation-auc:0.895565\n",
      "[2200]\tvalidation-auc:0.895618\n",
      "[2250]\tvalidation-auc:0.895681\n",
      "[2300]\tvalidation-auc:0.89576\n",
      "[2350]\tvalidation-auc:0.895815\n",
      "[2400]\tvalidation-auc:0.895876\n",
      "[2450]\tvalidation-auc:0.895914\n",
      "[2500]\tvalidation-auc:0.895985\n",
      "[2550]\tvalidation-auc:0.896028\n",
      "Stopping. Best iteration:\n",
      "[2540]\tvalidation-auc:0.896028\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.844291\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.873472\n",
      "[100]\tvalidation-auc:0.878803\n",
      "[150]\tvalidation-auc:0.882375\n",
      "[200]\tvalidation-auc:0.88532\n",
      "[250]\tvalidation-auc:0.88746\n",
      "[300]\tvalidation-auc:0.889208\n",
      "[350]\tvalidation-auc:0.890417\n",
      "[400]\tvalidation-auc:0.8912\n",
      "[450]\tvalidation-auc:0.891853\n",
      "[500]\tvalidation-auc:0.892462\n",
      "[550]\tvalidation-auc:0.892883\n",
      "[600]\tvalidation-auc:0.893295\n",
      "[650]\tvalidation-auc:0.893621\n",
      "[700]\tvalidation-auc:0.893881\n",
      "[750]\tvalidation-auc:0.89416\n",
      "[800]\tvalidation-auc:0.894387\n",
      "[850]\tvalidation-auc:0.894552\n",
      "[900]\tvalidation-auc:0.894746\n",
      "[950]\tvalidation-auc:0.894934\n",
      "[1000]\tvalidation-auc:0.895094\n",
      "[1050]\tvalidation-auc:0.895229\n",
      "[1100]\tvalidation-auc:0.895349\n",
      "[1150]\tvalidation-auc:0.895463\n",
      "[1200]\tvalidation-auc:0.895557\n",
      "Stopping. Best iteration:\n",
      "[1221]\tvalidation-auc:0.895622\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.844291\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.880482\n",
      "[100]\tvalidation-auc:0.887344\n",
      "[150]\tvalidation-auc:0.890469\n",
      "[200]\tvalidation-auc:0.892076\n",
      "[250]\tvalidation-auc:0.892974\n",
      "[300]\tvalidation-auc:0.893777\n",
      "[350]\tvalidation-auc:0.894275\n",
      "[400]\tvalidation-auc:0.894716\n",
      "[450]\tvalidation-auc:0.89493\n",
      "Stopping. Best iteration:\n",
      "[441]\tvalidation-auc:0.894952\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.844291\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.887113\n",
      "[100]\tvalidation-auc:0.891578\n",
      "[150]\tvalidation-auc:0.892844\n",
      "[200]\tvalidation-auc:0.893762\n",
      "[250]\tvalidation-auc:0.894183\n",
      "[300]\tvalidation-auc:0.894465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\tvalidation-auc:0.894651\n",
      "[400]\tvalidation-auc:0.894904\n",
      "Stopping. Best iteration:\n",
      "[398]\tvalidation-auc:0.894925\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.844291\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.890773\n",
      "[100]\tvalidation-auc:0.892542\n",
      "[150]\tvalidation-auc:0.893\n",
      "Stopping. Best iteration:\n",
      "[161]\tvalidation-auc:0.893087\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_1 = [(md,e) for md in range(4,8) for e in [0.01, 0.02, 0.05, 0.1, 0.2]]\n",
    "validation_auc_1 = Counter()\n",
    "for md,e in grid_1:\n",
    "    print(\"max_depth = {0}, eta = {1}:\".format(md,e))\n",
    "    params = {'max_depth': md, 'eta': e, 'min_child_weight': 1, 'colsample_bytree': 0.8, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_1[(md,e)] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 0.01), 0.896028)\n",
      "((7, 0.02), 0.895622)\n",
      "((6, 0.01), 0.895485)\n",
      "((6, 0.02), 0.895111)\n",
      "((7, 0.05), 0.894952)\n",
      "((7, 0.1), 0.894925)\n",
      "((5, 0.05), 0.894834)\n",
      "((6, 0.05), 0.89465)\n",
      "((5, 0.02), 0.894451)\n",
      "((5, 0.1), 0.894425)\n",
      "((5, 0.01), 0.894389)\n",
      "((6, 0.1), 0.894302)\n",
      "((4, 0.02), 0.893672)\n",
      "((4, 0.05), 0.893449)\n",
      "((6, 0.2), 0.893212)\n",
      "((7, 0.2), 0.893087)\n",
      "((4, 0.2), 0.892915)\n",
      "((4, 0.1), 0.892803)\n",
      "((5, 0.2), 0.892388)\n",
      "((4, 0.01), 0.846488)\n"
     ]
    }
   ],
   "source": [
    "for t in validation_auc_1.most_common():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Grid Search for min_child_weight (along with max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 5, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.862859\n",
      "[100]\tvalidation-auc:0.87039\n",
      "[150]\tvalidation-auc:0.875349\n",
      "[200]\tvalidation-auc:0.878916\n",
      "[250]\tvalidation-auc:0.881495\n",
      "[300]\tvalidation-auc:0.883579\n",
      "[350]\tvalidation-auc:0.885224\n",
      "[400]\tvalidation-auc:0.88646\n",
      "[450]\tvalidation-auc:0.88739\n",
      "[500]\tvalidation-auc:0.888131\n",
      "[550]\tvalidation-auc:0.888819\n",
      "[600]\tvalidation-auc:0.889407\n",
      "[650]\tvalidation-auc:0.889967\n",
      "[700]\tvalidation-auc:0.890323\n",
      "[750]\tvalidation-auc:0.890761\n",
      "[800]\tvalidation-auc:0.891115\n",
      "[850]\tvalidation-auc:0.891396\n",
      "[900]\tvalidation-auc:0.891655\n",
      "[950]\tvalidation-auc:0.891912\n",
      "[1000]\tvalidation-auc:0.892159\n",
      "[1050]\tvalidation-auc:0.892382\n",
      "[1100]\tvalidation-auc:0.892583\n",
      "[1150]\tvalidation-auc:0.892746\n",
      "[1200]\tvalidation-auc:0.89294\n",
      "[1250]\tvalidation-auc:0.893115\n",
      "[1300]\tvalidation-auc:0.893283\n",
      "[1350]\tvalidation-auc:0.893399\n",
      "[1400]\tvalidation-auc:0.893521\n",
      "[1450]\tvalidation-auc:0.893646\n",
      "[1500]\tvalidation-auc:0.893761\n",
      "[1550]\tvalidation-auc:0.893898\n",
      "[1600]\tvalidation-auc:0.894018\n",
      "[1650]\tvalidation-auc:0.894114\n",
      "[1700]\tvalidation-auc:0.894212\n",
      "[1750]\tvalidation-auc:0.894298\n",
      "[1800]\tvalidation-auc:0.894416\n",
      "[1850]\tvalidation-auc:0.894498\n",
      "[1900]\tvalidation-auc:0.894584\n",
      "[1950]\tvalidation-auc:0.894667\n",
      "[2000]\tvalidation-auc:0.894721\n",
      "[2050]\tvalidation-auc:0.894795\n",
      "Stopping. Best iteration:\n",
      "[2042]\tvalidation-auc:0.894795\n",
      "\n",
      "\n",
      "max_depth = 5, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.828533\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.862861\n",
      "[100]\tvalidation-auc:0.870398\n",
      "[150]\tvalidation-auc:0.875355\n",
      "[200]\tvalidation-auc:0.878892\n",
      "[250]\tvalidation-auc:0.88141\n",
      "[300]\tvalidation-auc:0.883447\n",
      "[350]\tvalidation-auc:0.885103\n",
      "[400]\tvalidation-auc:0.886324\n",
      "[450]\tvalidation-auc:0.887226\n",
      "[500]\tvalidation-auc:0.88804\n",
      "[550]\tvalidation-auc:0.888742\n",
      "[600]\tvalidation-auc:0.889317\n",
      "[650]\tvalidation-auc:0.889849\n",
      "[700]\tvalidation-auc:0.890294\n",
      "[750]\tvalidation-auc:0.890716\n",
      "[800]\tvalidation-auc:0.891062\n",
      "[850]\tvalidation-auc:0.89139\n",
      "[900]\tvalidation-auc:0.891658\n",
      "[950]\tvalidation-auc:0.891896\n",
      "[1000]\tvalidation-auc:0.892165\n",
      "[1050]\tvalidation-auc:0.892374\n",
      "[1100]\tvalidation-auc:0.89256\n",
      "[1150]\tvalidation-auc:0.892707\n",
      "[1200]\tvalidation-auc:0.892927\n",
      "[1250]\tvalidation-auc:0.893084\n",
      "[1300]\tvalidation-auc:0.893236\n",
      "[1350]\tvalidation-auc:0.893387\n",
      "[1400]\tvalidation-auc:0.893514\n",
      "[1450]\tvalidation-auc:0.893644\n",
      "[1500]\tvalidation-auc:0.893748\n",
      "[1550]\tvalidation-auc:0.893856\n",
      "[1600]\tvalidation-auc:0.89396\n",
      "[1650]\tvalidation-auc:0.894063\n",
      "[1700]\tvalidation-auc:0.894161\n",
      "[1750]\tvalidation-auc:0.894233\n",
      "[1800]\tvalidation-auc:0.894327\n",
      "Stopping. Best iteration:\n",
      "[1829]\tvalidation-auc:0.894385\n",
      "\n",
      "\n",
      "max_depth = 6, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.837321\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.868957\n",
      "[100]\tvalidation-auc:0.875189\n",
      "[150]\tvalidation-auc:0.879368\n",
      "[200]\tvalidation-auc:0.88249\n",
      "[250]\tvalidation-auc:0.884897\n",
      "[300]\tvalidation-auc:0.886911\n",
      "[350]\tvalidation-auc:0.888283\n",
      "[400]\tvalidation-auc:0.889284\n",
      "[450]\tvalidation-auc:0.890085\n",
      "[500]\tvalidation-auc:0.890728\n",
      "[550]\tvalidation-auc:0.891277\n",
      "[600]\tvalidation-auc:0.891819\n",
      "[650]\tvalidation-auc:0.892186\n",
      "[700]\tvalidation-auc:0.892454\n",
      "[750]\tvalidation-auc:0.892764\n",
      "[800]\tvalidation-auc:0.893025\n",
      "[850]\tvalidation-auc:0.893294\n",
      "[900]\tvalidation-auc:0.893509\n",
      "[950]\tvalidation-auc:0.893749\n",
      "[1000]\tvalidation-auc:0.893962\n",
      "[1050]\tvalidation-auc:0.894128\n",
      "[1100]\tvalidation-auc:0.894294\n",
      "[1150]\tvalidation-auc:0.894407\n",
      "[1200]\tvalidation-auc:0.894556\n",
      "[1250]\tvalidation-auc:0.894681\n",
      "[1300]\tvalidation-auc:0.894777\n",
      "[1350]\tvalidation-auc:0.894898\n",
      "[1400]\tvalidation-auc:0.895005\n",
      "[1450]\tvalidation-auc:0.895096\n",
      "[1500]\tvalidation-auc:0.895175\n",
      "[1550]\tvalidation-auc:0.895273\n",
      "Stopping. Best iteration:\n",
      "[1550]\tvalidation-auc:0.895273\n",
      "\n",
      "\n",
      "max_depth = 6, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.837321\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.86888\n",
      "[100]\tvalidation-auc:0.875122\n",
      "[150]\tvalidation-auc:0.879298\n",
      "[200]\tvalidation-auc:0.882384\n",
      "[250]\tvalidation-auc:0.8848\n",
      "[300]\tvalidation-auc:0.886768\n",
      "[350]\tvalidation-auc:0.888141\n",
      "[400]\tvalidation-auc:0.889128\n",
      "[450]\tvalidation-auc:0.889991\n",
      "[500]\tvalidation-auc:0.890668\n",
      "[550]\tvalidation-auc:0.891246\n",
      "[600]\tvalidation-auc:0.891745\n",
      "[650]\tvalidation-auc:0.89209\n",
      "[700]\tvalidation-auc:0.892393\n",
      "[750]\tvalidation-auc:0.892709\n",
      "[800]\tvalidation-auc:0.892984\n",
      "[850]\tvalidation-auc:0.893215\n",
      "[900]\tvalidation-auc:0.893423\n",
      "[950]\tvalidation-auc:0.893656\n",
      "[1000]\tvalidation-auc:0.893853\n",
      "[1050]\tvalidation-auc:0.894016\n",
      "[1100]\tvalidation-auc:0.894165\n",
      "[1150]\tvalidation-auc:0.894292\n",
      "[1200]\tvalidation-auc:0.894424\n",
      "[1250]\tvalidation-auc:0.894534\n",
      "[1300]\tvalidation-auc:0.894659\n",
      "[1350]\tvalidation-auc:0.894761\n",
      "[1400]\tvalidation-auc:0.894869\n",
      "Stopping. Best iteration:\n",
      "[1418]\tvalidation-auc:0.894907\n",
      "\n",
      "\n",
      "max_depth = 7, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.844246\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.87346\n",
      "[100]\tvalidation-auc:0.878817\n",
      "[150]\tvalidation-auc:0.882394\n",
      "[200]\tvalidation-auc:0.885233\n",
      "[250]\tvalidation-auc:0.887382\n",
      "[300]\tvalidation-auc:0.889148\n",
      "[350]\tvalidation-auc:0.890377\n",
      "[400]\tvalidation-auc:0.891158\n",
      "[450]\tvalidation-auc:0.891877\n",
      "[500]\tvalidation-auc:0.892443\n",
      "[550]\tvalidation-auc:0.89287\n",
      "[600]\tvalidation-auc:0.89324\n",
      "[650]\tvalidation-auc:0.893547\n",
      "[700]\tvalidation-auc:0.893826\n",
      "[750]\tvalidation-auc:0.894092\n",
      "[800]\tvalidation-auc:0.89432\n",
      "[850]\tvalidation-auc:0.894532\n",
      "[900]\tvalidation-auc:0.894675\n",
      "[950]\tvalidation-auc:0.894858\n",
      "[1000]\tvalidation-auc:0.895003\n",
      "[1050]\tvalidation-auc:0.895146\n",
      "[1100]\tvalidation-auc:0.895278\n",
      "[1150]\tvalidation-auc:0.895398\n",
      "[1200]\tvalidation-auc:0.895492\n",
      "[1250]\tvalidation-auc:0.895593\n",
      "[1300]\tvalidation-auc:0.895672\n",
      "[1350]\tvalidation-auc:0.895755\n",
      "[1400]\tvalidation-auc:0.89585\n",
      "Stopping. Best iteration:\n",
      "[1435]\tvalidation-auc:0.895906\n",
      "\n",
      "\n",
      "max_depth = 7, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.844308\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.873473\n",
      "[100]\tvalidation-auc:0.878849\n",
      "[150]\tvalidation-auc:0.882353\n",
      "[200]\tvalidation-auc:0.885233\n",
      "[250]\tvalidation-auc:0.887435\n",
      "[300]\tvalidation-auc:0.889119\n",
      "[350]\tvalidation-auc:0.890312\n",
      "[400]\tvalidation-auc:0.891105\n",
      "[450]\tvalidation-auc:0.891795\n",
      "[500]\tvalidation-auc:0.892384\n",
      "[550]\tvalidation-auc:0.892778\n",
      "[600]\tvalidation-auc:0.893199\n",
      "[650]\tvalidation-auc:0.893537\n",
      "[700]\tvalidation-auc:0.893797\n",
      "[750]\tvalidation-auc:0.894053\n",
      "[800]\tvalidation-auc:0.894279\n",
      "[850]\tvalidation-auc:0.894494\n",
      "[900]\tvalidation-auc:0.894696\n",
      "[950]\tvalidation-auc:0.894888\n",
      "[1000]\tvalidation-auc:0.895042\n",
      "[1050]\tvalidation-auc:0.895179\n",
      "[1100]\tvalidation-auc:0.895299\n",
      "[1150]\tvalidation-auc:0.895415\n",
      "[1200]\tvalidation-auc:0.895516\n",
      "Stopping. Best iteration:\n",
      "[1238]\tvalidation-auc:0.895615\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md1 = 6\n",
    "grid_2 = [(md1+i,mcw) for i in [-1,0,1] for mcw in [3,5]]\n",
    "validation_auc_2 = Counter()\n",
    "for md,mcw in grid_2:\n",
    "    print(\"max_depth = {0}, min_child_weight = {1}:\".format(md,mcw))\n",
    "    params = {'max_depth': md, 'eta': 0.02, 'min_child_weight': mcw, 'colsample_bytree': 0.8, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_2[(md,mcw)] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 3), 0.895906)\n",
      "((7, 5), 0.895615)\n",
      "((6, 3), 0.895273)\n",
      "((6, 5), 0.894907)\n",
      "((5, 3), 0.894795)\n",
      "((5, 5), 0.894385)\n"
     ]
    }
   ],
   "source": [
    "for t in validation_auc_2.most_common():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Grid Search for colsample_by_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_by_tree = 0.5:\n",
      "[0]\tvalidation-auc:0.827185\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.87571\n",
      "[100]\tvalidation-auc:0.879822\n",
      "[150]\tvalidation-auc:0.882896\n",
      "[200]\tvalidation-auc:0.885254\n",
      "[250]\tvalidation-auc:0.887411\n",
      "[300]\tvalidation-auc:0.889192\n",
      "[350]\tvalidation-auc:0.890438\n",
      "[400]\tvalidation-auc:0.891354\n",
      "[450]\tvalidation-auc:0.892116\n",
      "[500]\tvalidation-auc:0.892683\n",
      "[550]\tvalidation-auc:0.893115\n",
      "[600]\tvalidation-auc:0.893454\n",
      "[650]\tvalidation-auc:0.893788\n",
      "[700]\tvalidation-auc:0.894022\n",
      "[750]\tvalidation-auc:0.894279\n",
      "[800]\tvalidation-auc:0.894511\n",
      "[850]\tvalidation-auc:0.894689\n",
      "[900]\tvalidation-auc:0.894884\n",
      "[950]\tvalidation-auc:0.895\n",
      "[1000]\tvalidation-auc:0.895165\n",
      "[1050]\tvalidation-auc:0.895303\n",
      "[1100]\tvalidation-auc:0.89545\n",
      "[1150]\tvalidation-auc:0.895562\n",
      "[1200]\tvalidation-auc:0.895677\n",
      "[1250]\tvalidation-auc:0.895749\n",
      "[1300]\tvalidation-auc:0.895848\n",
      "[1350]\tvalidation-auc:0.895973\n",
      "[1400]\tvalidation-auc:0.896073\n",
      "[1450]\tvalidation-auc:0.896178\n",
      "[1500]\tvalidation-auc:0.896259\n",
      "Stopping. Best iteration:\n",
      "[1525]\tvalidation-auc:0.896312\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.55:\n",
      "[0]\tvalidation-auc:0.840372\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.875447\n",
      "[100]\tvalidation-auc:0.879787\n",
      "[150]\tvalidation-auc:0.882871\n",
      "[200]\tvalidation-auc:0.885247\n",
      "[250]\tvalidation-auc:0.887444\n",
      "[300]\tvalidation-auc:0.88916\n",
      "[350]\tvalidation-auc:0.89037\n",
      "[400]\tvalidation-auc:0.891205\n",
      "[450]\tvalidation-auc:0.891899\n",
      "[500]\tvalidation-auc:0.892476\n",
      "[550]\tvalidation-auc:0.892894\n",
      "[600]\tvalidation-auc:0.893217\n",
      "[650]\tvalidation-auc:0.893595\n",
      "[700]\tvalidation-auc:0.893822\n",
      "[750]\tvalidation-auc:0.894086\n",
      "[800]\tvalidation-auc:0.894337\n",
      "[850]\tvalidation-auc:0.894527\n",
      "[900]\tvalidation-auc:0.894717\n",
      "[950]\tvalidation-auc:0.89489\n",
      "[1000]\tvalidation-auc:0.895039\n",
      "[1050]\tvalidation-auc:0.895199\n",
      "[1100]\tvalidation-auc:0.895333\n",
      "[1150]\tvalidation-auc:0.895442\n",
      "[1200]\tvalidation-auc:0.895551\n",
      "[1250]\tvalidation-auc:0.89566\n",
      "[1300]\tvalidation-auc:0.895767\n",
      "[1350]\tvalidation-auc:0.895881\n",
      "Stopping. Best iteration:\n",
      "[1388]\tvalidation-auc:0.895956\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.6:\n",
      "[0]\tvalidation-auc:0.842672\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.875023\n",
      "[100]\tvalidation-auc:0.879497\n",
      "[150]\tvalidation-auc:0.882893\n",
      "[200]\tvalidation-auc:0.885372\n",
      "[250]\tvalidation-auc:0.887572\n",
      "[300]\tvalidation-auc:0.889306\n",
      "[350]\tvalidation-auc:0.890534\n",
      "[400]\tvalidation-auc:0.891395\n",
      "[450]\tvalidation-auc:0.892063\n",
      "[500]\tvalidation-auc:0.892662\n",
      "[550]\tvalidation-auc:0.893058\n",
      "[600]\tvalidation-auc:0.893397\n",
      "[650]\tvalidation-auc:0.893712\n",
      "[700]\tvalidation-auc:0.893971\n",
      "[750]\tvalidation-auc:0.894259\n",
      "[800]\tvalidation-auc:0.894505\n",
      "[850]\tvalidation-auc:0.894702\n",
      "[900]\tvalidation-auc:0.894847\n",
      "[950]\tvalidation-auc:0.895033\n",
      "[1000]\tvalidation-auc:0.895185\n",
      "[1050]\tvalidation-auc:0.895334\n",
      "[1100]\tvalidation-auc:0.895492\n",
      "[1150]\tvalidation-auc:0.895587\n",
      "[1200]\tvalidation-auc:0.895688\n",
      "[1250]\tvalidation-auc:0.895786\n",
      "[1300]\tvalidation-auc:0.895866\n",
      "[1350]\tvalidation-auc:0.895951\n",
      "[1400]\tvalidation-auc:0.896037\n",
      "[1450]\tvalidation-auc:0.896122\n",
      "[1500]\tvalidation-auc:0.89619\n",
      "Stopping. Best iteration:\n",
      "[1522]\tvalidation-auc:0.896228\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.65:\n",
      "[0]\tvalidation-auc:0.842699\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.874772\n",
      "[100]\tvalidation-auc:0.879361\n",
      "[150]\tvalidation-auc:0.882745\n",
      "[200]\tvalidation-auc:0.885349\n",
      "[250]\tvalidation-auc:0.887552\n",
      "[300]\tvalidation-auc:0.889292\n",
      "[350]\tvalidation-auc:0.890556\n",
      "[400]\tvalidation-auc:0.891432\n",
      "[450]\tvalidation-auc:0.892108\n",
      "[500]\tvalidation-auc:0.892709\n",
      "[550]\tvalidation-auc:0.893143\n",
      "[600]\tvalidation-auc:0.893464\n",
      "[650]\tvalidation-auc:0.893819\n",
      "[700]\tvalidation-auc:0.894091\n",
      "[750]\tvalidation-auc:0.894314\n",
      "[800]\tvalidation-auc:0.894542\n",
      "[850]\tvalidation-auc:0.894759\n",
      "[900]\tvalidation-auc:0.894914\n",
      "[950]\tvalidation-auc:0.895051\n",
      "[1000]\tvalidation-auc:0.895252\n",
      "[1050]\tvalidation-auc:0.895376\n",
      "[1100]\tvalidation-auc:0.895514\n",
      "[1150]\tvalidation-auc:0.895605\n",
      "[1200]\tvalidation-auc:0.895734\n",
      "[1250]\tvalidation-auc:0.895811\n",
      "[1300]\tvalidation-auc:0.895924\n",
      "[1350]\tvalidation-auc:0.896023\n",
      "[1400]\tvalidation-auc:0.896125\n",
      "[1450]\tvalidation-auc:0.896205\n",
      "[1500]\tvalidation-auc:0.896263\n",
      "[1550]\tvalidation-auc:0.896323\n",
      "Stopping. Best iteration:\n",
      "[1582]\tvalidation-auc:0.896359\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.7:\n",
      "[0]\tvalidation-auc:0.8444\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.874151\n",
      "[100]\tvalidation-auc:0.879028\n",
      "[150]\tvalidation-auc:0.882495\n",
      "[200]\tvalidation-auc:0.88524\n",
      "[250]\tvalidation-auc:0.887516\n",
      "[300]\tvalidation-auc:0.889265\n",
      "[350]\tvalidation-auc:0.890443\n",
      "[400]\tvalidation-auc:0.891269\n",
      "[450]\tvalidation-auc:0.891949\n",
      "[500]\tvalidation-auc:0.892554\n",
      "[550]\tvalidation-auc:0.892996\n",
      "[600]\tvalidation-auc:0.893351\n",
      "[650]\tvalidation-auc:0.893723\n",
      "[700]\tvalidation-auc:0.893984\n",
      "[750]\tvalidation-auc:0.894255\n",
      "[800]\tvalidation-auc:0.894447\n",
      "[850]\tvalidation-auc:0.894651\n",
      "[900]\tvalidation-auc:0.894829\n",
      "[950]\tvalidation-auc:0.894976\n",
      "[1000]\tvalidation-auc:0.895113\n",
      "[1050]\tvalidation-auc:0.895252\n",
      "[1100]\tvalidation-auc:0.895366\n",
      "[1150]\tvalidation-auc:0.895474\n",
      "[1200]\tvalidation-auc:0.895622\n",
      "[1250]\tvalidation-auc:0.895735\n",
      "[1300]\tvalidation-auc:0.89583\n",
      "[1350]\tvalidation-auc:0.895917\n",
      "[1400]\tvalidation-auc:0.896001\n",
      "[1450]\tvalidation-auc:0.896094\n",
      "[1500]\tvalidation-auc:0.896152\n",
      "Stopping. Best iteration:\n",
      "[1536]\tvalidation-auc:0.89622\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.75:\n",
      "[0]\tvalidation-auc:0.844387\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.873618\n",
      "[100]\tvalidation-auc:0.878787\n",
      "[150]\tvalidation-auc:0.882482\n",
      "[200]\tvalidation-auc:0.885362\n",
      "[250]\tvalidation-auc:0.887578\n",
      "[300]\tvalidation-auc:0.889247\n",
      "[350]\tvalidation-auc:0.89049\n",
      "[400]\tvalidation-auc:0.89131\n",
      "[450]\tvalidation-auc:0.891993\n",
      "[500]\tvalidation-auc:0.892573\n",
      "[550]\tvalidation-auc:0.892985\n",
      "[600]\tvalidation-auc:0.893366\n",
      "[650]\tvalidation-auc:0.893696\n",
      "[700]\tvalidation-auc:0.893992\n",
      "[750]\tvalidation-auc:0.894243\n",
      "[800]\tvalidation-auc:0.894479\n",
      "[850]\tvalidation-auc:0.894665\n",
      "[900]\tvalidation-auc:0.894869\n",
      "[950]\tvalidation-auc:0.895049\n",
      "[1000]\tvalidation-auc:0.895188\n",
      "[1050]\tvalidation-auc:0.895337\n",
      "[1100]\tvalidation-auc:0.895452\n",
      "[1150]\tvalidation-auc:0.89555\n",
      "[1200]\tvalidation-auc:0.895628\n",
      "[1250]\tvalidation-auc:0.895739\n",
      "[1300]\tvalidation-auc:0.895847\n",
      "[1350]\tvalidation-auc:0.895949\n",
      "[1400]\tvalidation-auc:0.896042\n",
      "[1450]\tvalidation-auc:0.89617\n",
      "Stopping. Best iteration:\n",
      "[1459]\tvalidation-auc:0.896186\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.8:\n",
      "[0]\tvalidation-auc:0.844246\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.87346\n",
      "[100]\tvalidation-auc:0.878817\n",
      "[150]\tvalidation-auc:0.882394\n",
      "[200]\tvalidation-auc:0.885233\n",
      "[250]\tvalidation-auc:0.887382\n",
      "[300]\tvalidation-auc:0.889148\n",
      "[350]\tvalidation-auc:0.890377\n",
      "[400]\tvalidation-auc:0.891158\n",
      "[450]\tvalidation-auc:0.891877\n",
      "[500]\tvalidation-auc:0.892443\n",
      "[550]\tvalidation-auc:0.89287\n",
      "[600]\tvalidation-auc:0.89324\n",
      "[650]\tvalidation-auc:0.893547\n",
      "[700]\tvalidation-auc:0.893826\n",
      "[750]\tvalidation-auc:0.894092\n",
      "[800]\tvalidation-auc:0.89432\n",
      "[850]\tvalidation-auc:0.894532\n",
      "[900]\tvalidation-auc:0.894675\n",
      "[950]\tvalidation-auc:0.894858\n",
      "[1000]\tvalidation-auc:0.895003\n",
      "[1050]\tvalidation-auc:0.895146\n",
      "[1100]\tvalidation-auc:0.895278\n",
      "[1150]\tvalidation-auc:0.895398\n",
      "[1200]\tvalidation-auc:0.895492\n",
      "[1250]\tvalidation-auc:0.895593\n",
      "[1300]\tvalidation-auc:0.895672\n",
      "[1350]\tvalidation-auc:0.895755\n",
      "[1400]\tvalidation-auc:0.89585\n",
      "Stopping. Best iteration:\n",
      "[1435]\tvalidation-auc:0.895906\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.85:\n",
      "[0]\tvalidation-auc:0.849439\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.872971\n",
      "[100]\tvalidation-auc:0.878654\n",
      "[150]\tvalidation-auc:0.882358\n",
      "[200]\tvalidation-auc:0.885308\n",
      "[250]\tvalidation-auc:0.887506\n",
      "[300]\tvalidation-auc:0.889196\n",
      "[350]\tvalidation-auc:0.890355\n",
      "[400]\tvalidation-auc:0.891158\n",
      "[450]\tvalidation-auc:0.89188\n",
      "[500]\tvalidation-auc:0.892472\n",
      "[550]\tvalidation-auc:0.892833\n",
      "[600]\tvalidation-auc:0.89323\n",
      "[650]\tvalidation-auc:0.893543\n",
      "[700]\tvalidation-auc:0.893779\n",
      "[750]\tvalidation-auc:0.894076\n",
      "[800]\tvalidation-auc:0.894303\n",
      "[850]\tvalidation-auc:0.894502\n",
      "[900]\tvalidation-auc:0.894697\n",
      "[950]\tvalidation-auc:0.894908\n",
      "[1000]\tvalidation-auc:0.895082\n",
      "[1050]\tvalidation-auc:0.895231\n",
      "[1100]\tvalidation-auc:0.895375\n",
      "[1150]\tvalidation-auc:0.895498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\tvalidation-auc:0.895578\n",
      "Stopping. Best iteration:\n",
      "[1221]\tvalidation-auc:0.89564\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.9:\n",
      "[0]\tvalidation-auc:0.849439\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.873004\n",
      "[100]\tvalidation-auc:0.878592\n",
      "[150]\tvalidation-auc:0.882377\n",
      "[200]\tvalidation-auc:0.885222\n",
      "[250]\tvalidation-auc:0.887517\n",
      "[300]\tvalidation-auc:0.889163\n",
      "[350]\tvalidation-auc:0.890383\n",
      "[400]\tvalidation-auc:0.891224\n",
      "[450]\tvalidation-auc:0.891942\n",
      "[500]\tvalidation-auc:0.892492\n",
      "[550]\tvalidation-auc:0.892863\n",
      "[600]\tvalidation-auc:0.893267\n",
      "[650]\tvalidation-auc:0.893589\n",
      "[700]\tvalidation-auc:0.893844\n",
      "[750]\tvalidation-auc:0.894117\n",
      "[800]\tvalidation-auc:0.894353\n",
      "[850]\tvalidation-auc:0.894582\n",
      "[900]\tvalidation-auc:0.894769\n",
      "[950]\tvalidation-auc:0.894969\n",
      "[1000]\tvalidation-auc:0.89512\n",
      "[1050]\tvalidation-auc:0.895253\n",
      "[1100]\tvalidation-auc:0.895379\n",
      "[1150]\tvalidation-auc:0.895475\n",
      "[1200]\tvalidation-auc:0.89561\n",
      "[1250]\tvalidation-auc:0.895702\n",
      "[1300]\tvalidation-auc:0.895791\n",
      "[1350]\tvalidation-auc:0.895875\n",
      "[1400]\tvalidation-auc:0.895975\n",
      "Stopping. Best iteration:\n",
      "[1407]\tvalidation-auc:0.895988\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_3 = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "validation_auc_3 = Counter()\n",
    "for cbt in grid_3:\n",
    "    print(\"colsample_by_tree = {}:\".format(cbt))\n",
    "    params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 3, 'colsample_bytree': cbt, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_3[cbt] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.65, 0.896359),\n",
       " (0.5, 0.896312),\n",
       " (0.6, 0.896228),\n",
       " (0.7, 0.89622),\n",
       " (0.75, 0.896186),\n",
       " (0.9, 0.895988),\n",
       " (0.55, 0.895956),\n",
       " (0.8, 0.895906),\n",
       " (0.85, 0.89564)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_auc_3.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Finally select the opitmal num_boost_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.842699\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.874772\n",
      "[100]\tvalidation-auc:0.879361\n",
      "[150]\tvalidation-auc:0.882745\n",
      "[200]\tvalidation-auc:0.885349\n",
      "[250]\tvalidation-auc:0.887552\n",
      "[300]\tvalidation-auc:0.889292\n",
      "[350]\tvalidation-auc:0.890556\n",
      "[400]\tvalidation-auc:0.891432\n",
      "[450]\tvalidation-auc:0.892108\n",
      "[500]\tvalidation-auc:0.892709\n",
      "[550]\tvalidation-auc:0.893143\n",
      "[600]\tvalidation-auc:0.893464\n",
      "[650]\tvalidation-auc:0.893819\n",
      "[700]\tvalidation-auc:0.894091\n",
      "[750]\tvalidation-auc:0.894314\n",
      "[800]\tvalidation-auc:0.894542\n",
      "[850]\tvalidation-auc:0.894759\n",
      "[900]\tvalidation-auc:0.894914\n",
      "[950]\tvalidation-auc:0.895051\n",
      "[1000]\tvalidation-auc:0.895252\n",
      "[1050]\tvalidation-auc:0.895376\n",
      "[1100]\tvalidation-auc:0.895514\n",
      "[1150]\tvalidation-auc:0.895605\n",
      "[1200]\tvalidation-auc:0.895734\n",
      "[1250]\tvalidation-auc:0.895811\n",
      "[1300]\tvalidation-auc:0.895924\n",
      "[1350]\tvalidation-auc:0.896023\n",
      "[1400]\tvalidation-auc:0.896125\n",
      "[1450]\tvalidation-auc:0.896205\n",
      "[1500]\tvalidation-auc:0.896263\n",
      "[1550]\tvalidation-auc:0.896323\n",
      "Stopping. Best iteration:\n",
      "[1582]\tvalidation-auc:0.896359\n",
      "\n",
      "\n",
      "1582\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 3, 'colsample_bytree': 0.65, \n",
    "          'subsample': 0.8, \n",
    "          'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "          'seed': 12345}\n",
    "evals_result = {}\n",
    "xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                      early_stopping_rounds = 10,\n",
    "                      evals_result = evals_result,\n",
    "                      verbose_eval = 50)\n",
    "optimal_num_boost_round = np.argmax(evals_result['validation']['auc'])\n",
    "print(\"\")\n",
    "print(optimal_num_boost_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Train the final xgb model and make predictions for observations in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 3, 'colsample_bytree': 0.65, \n",
    "          'subsample': 0.8, \n",
    "          'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "          'seed': 12345}\n",
    "final_xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = optimal_num_boost_round)\n",
    "# make prediction for observations in the test set\n",
    "y_test_pred = final_xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "AUC = 0.9001\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(dtest.get_label(), y_test_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model object and predicted scores on the validation sample to local disk\n",
    "# pickle.dump(final_xgb_model, open(results_dir + \"/xgb.p\", \"wb\"))\n",
    "pickle.dump(list(y_test_pred), open(results_dir + \"/y_test_pred_xgb.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(list(final_xgb_model.get_fscore().items()), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "feature_importance.loc[:, 'importance'] = feature_importance.loc[:, 'importance'] / sum(feature_importance.loc[:, 'importance'])\n",
    "yy = feature_importance.loc[:, 'importance'].iloc[:20]\n",
    "xx = feature_importance.loc[:, 'feature'].iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_summary = feature_importance.rename(columns = {'feature':'predictor_name',\n",
    "                                                   'importance':'feature_importance'})\\\n",
    ".loc[:,['predictor_name', 'feature_importance']]\n",
    "xgb_summary = xgb_summary.merge(pd.DataFrame({'predictor_name': predictors}), on=['predictor_name'], how='right')\\\n",
    ".sort_values(['feature_importance', 'predictor_name'], ascending=[False, True]).fillna(0)\n",
    "xgb_summary.to_csv(results_dir + \"xgb_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAK0CAYAAABRFsgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npwgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x198a3748358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.bar(list(range(20)), yy, width=0.75, color = \"orange\")\n",
    "plt.xticks(list(range(20)), xx, rotation = 'vertical', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Predictor\", fontsize=16, color=\"gray\")\n",
    "plt.ylabel(\"Feature Importance\", fontsize=16, color=\"gray\")\n",
    "plt.savefig(results_dir + \"XGBoost_variable_importance.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t\n",
    "\n",
    "def cross_validation(train, xgb_params, nbr):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grad_6years):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        X_1 = train_part_new.loc[:,predictors]\n",
    "        y_1 = train_part_new.grad_6years\n",
    "        X_2 = test_part_new.loc[:,predictors]\n",
    "        y_2 = test_part_new.grad_6years\n",
    "        dtrain_cv = xgb.DMatrix(X_1,y_1)\n",
    "        dtest_cv = xgb.DMatrix(X_2,y_2)\n",
    "        xgb_cv_model = xgb.train(params=xgb_params, dtrain=dtrain_cv, num_boost_round = nbr)\n",
    "        y_2_pred = xgb_cv_model.predict(dtest_cv)\n",
    "        p,r,t = precision_recall_curve(y_2, y_2_pred)\n",
    "        auc = roc_auc_score(y_2, y_2_pred)\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979687984063963 0.0018765117140369715\n"
     ]
    }
   ],
   "source": [
    "final_params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 3, 'colsample_bytree': 0.65, \n",
    "                'subsample': 0.8, \n",
    "                'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "                'seed': 12345}\n",
    "best_threshold = cross_validation(train_df, final_params, optimal_num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37799257"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.378:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18625.0   3183.0  21808.0\n",
      "Real_1   2251.0   9056.0  11307.0\n",
      "        20876.0  12239.0  33115.0\n",
      "\n",
      "F1 score = 0.7692\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "pr_xgb = create_confusion_matrix(y_test_pred, best_threshold, \"XGBoost_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.43:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  19156.0   2652.0  21808.0\n",
      "Real_1   2633.0   8674.0  11307.0\n",
      "        21789.0  11326.0  33115.0\n",
      "\n",
      "F1 score = 0.7665\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.grad_6years))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "pr2_xgb = create_confusion_matrix(y_test_pred_binary, best_threshold, \"XGBoost_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df = pd.DataFrame([(best_threshold,)+pr_xgb,(alternative_threshold,)+pr2_xgb]).round(4)\n",
    "precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df.to_csv(results_dir + \"XGBoost_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Reorganize files of key evaluation metrics for the five models: OLS, Logit, RF, XGBoost and CoxPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract all of the key evaluation metrics of the five models that exclude demographic predictors,\n",
    "# which will be used to create Figure 10 of paper\n",
    "cstat = [0.8817,0.8773,0.8792,0.8866,0.9001]\n",
    "m_dict = {'Logit': 'LR1', 'OLS': 'OLS',\n",
    "          'RF': 'RF', 'XGBoost': 'XGBoost',\n",
    "          'CoxPH': 'Cox'}\n",
    "m_list = ['Logit', 'OLS', 'CoxPH', 'RF', 'XGBoost']\n",
    "summary = []\n",
    "for c,m in zip(cstat,m_list):\n",
    "    summary.append((m,c)+tuple(pd.read_csv(results_dir + \"\\\\{}_precision_recall.csv\".format(m_dict[m])).iloc[0,1:]))\n",
    "summary_df = pd.DataFrame(summary, columns=['model','c-statistic','threshold','precision_1','recall_1',\n",
    "                                            'precision_0','recall_0','f1_score_1'])\n",
    "summary_df.loc[:,'f1_score_0'] = 2*summary_df.precision_0*summary_df.recall_0/(summary_df.precision_0+summary_df.recall_0)\n",
    "summary_df.round(4).to_csv(results_dir + \"cleaned_results\\\\main_eval_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_without_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "m2_dict = {'lr':'Logit','xgb':'XGBoost','ols':'OLS','rf':'RF'}\n",
    "for f in [e + \".csv\" for e in ['lr_feature_ranking','ols_feature_ranking','rf_summary','xgb_summary']]:\n",
    "    m = f.split(\"_\")[0]\n",
    "    try:\n",
    "        shutil.copy(f, \"cleaned_results\\\\feature_ranking\\\\\"+m2_dict[m]+\"_feature_ranking.csv\")\n",
    "    except KeyError:\n",
    "        shutil.copy(f, \"cleaned_results\\\\feature_ranking\\\\\"+m+\"_feature_ranking.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the race and age differences in the 20 most important predictors (according to XGBoost model without demographic predictors) -- used to generate Table 2 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import CompareMeans,DescrStatsW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recover the real values of certain predictors (because we applied log transformation to rescale before \n",
    "# feeding them into predictive models)\n",
    "df = pd.read_stata(fpath + \"/full_data_truncated.dta\")\n",
    "test_df = df[df.valid == 1]\n",
    "for p in predictors:\n",
    "    if p.split(\"_\")[0] in ['grants', 'sub_loans', 'unsub_loans', 'others']:\n",
    "        test_df.loc[:,p] = test_df.loc[:,p].apply(lambda x: np.exp(x) - 1)\n",
    "    elif p == \"coll_lvl_cred_earn\":\n",
    "        test_df.loc[:,p] = test_df.loc[:,p] * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top20_predictors_xgboost = pd.read_csv(\"cleaned_results\\\\feature_ranking\\\\XGBoost_feature_ranking.csv\").predictor_name.iloc[:20]\n",
    "xgboost_fi = pd.read_csv(\"cleaned_results\\\\feature_ranking\\\\XGBoost_feature_ranking.csv\").iloc[:20,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "afam_indices = np.where(test_df.afam == 1)[0]\n",
    "nonafam_indices = np.where(test_df.afam == 0)[0]\n",
    "\n",
    "rows_2 = []\n",
    "for i,p in enumerate(top20_predictors_xgboost):\n",
    "    if p in impute_list_1:\n",
    "        new_indices = np.where(test_df.enrolled_pre == 1)[0]\n",
    "    elif p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        new_indices = np.where(test_df['enrolled_'+suffix] == 1)[0]\n",
    "    elif p in impute_list_4:\n",
    "        suffix = p[-3:]\n",
    "        new_indices = np.where(test_df['enrolled_nsc_'+suffix] == 1)[0]\n",
    "    else:\n",
    "        new_indices = np.array(range(test_df.shape[0]))\n",
    "    new_indices = np.intersect1d(new_indices, np.where(pd.isnull(test_df[p]) == False)[0])\n",
    "    afam_indices = np.intersect1d(afam_indices, new_indices)\n",
    "    nonafam_indices = np.intersect1d(nonafam_indices, new_indices)\n",
    "    x = np.array(test_df.loc[:,p])\n",
    "    x_1 = x[afam_indices]\n",
    "    x_2 = x[nonafam_indices]\n",
    "    test_result = CompareMeans(DescrStatsW(x_1), DescrStatsW(x_2)).ztest_ind(alternative='two-sided', usevar='unequal')\n",
    "    p_vals = str(test_result[1]).split(\"e\")\n",
    "    if len(p_vals) == 1:\n",
    "        new_p_val = str(round(float(p_vals[0]),4))\n",
    "    else:\n",
    "        new_p_val = str(round(float(p_vals[0]),4)) + \"e\" + p_vals[1]\n",
    "    diff_in_mean = round(np.mean(x_1) - np.mean(x_2),4)\n",
    "    rows_2.append((p,xgboost_fi.iloc[i],np.round(np.mean(x_1),4), np.round(np.mean(x_2),4), diff_in_mean,new_p_val))\n",
    "afam_test_df_2 = pd.DataFrame(rows_2, columns = ['predictor', 'feature_importance', 'afam_mean', 'nonafam_mean', 'diff_in_mean', 'p_val'])\n",
    "afam_test_df_2.to_csv(\"cleaned_results\\\\subgroups\\\\new_comparisons\\\\XGBoost_afam_ztest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age25_indices = np.where(test_df.age_entry >= 25)[0]\n",
    "nonage25_indices = np.where(test_df.age_entry < 25)[0]\n",
    "\n",
    "rows_2 = []\n",
    "for i,p in enumerate(top20_predictors_xgboost):\n",
    "    if p in impute_list_1:\n",
    "        new_indices = np.where(test_df.enrolled_pre == 1)[0]\n",
    "    elif p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        new_indices = np.where(test_df['enrolled_'+suffix] == 1)[0]\n",
    "    elif p in impute_list_4:\n",
    "        suffix = p[-3:]\n",
    "        new_indices = np.where(test_df['enrolled_nsc_'+suffix] == 1)[0]\n",
    "    else:\n",
    "        new_indices = np.array(range(test_df.shape[0]))\n",
    "    new_indices = np.intersect1d(new_indices, np.where(pd.isnull(test_df[p]) == False)[0])\n",
    "    age25_indices = np.intersect1d(age25_indices, new_indices)\n",
    "    nonage25_indices = np.intersect1d(nonage25_indices, new_indices)\n",
    "    x = np.array(test_df.loc[:,p])\n",
    "    x_1 = x[age25_indices]\n",
    "    x_2 = x[nonage25_indices]\n",
    "    test_result = CompareMeans(DescrStatsW(x_1), DescrStatsW(x_2)).ztest_ind(alternative='two-sided', usevar='unequal')\n",
    "    p_vals = str(test_result[1]).split(\"e\")\n",
    "    if len(p_vals) == 1:\n",
    "        new_p_val = str(round(float(p_vals[0]),4))\n",
    "    else:\n",
    "        new_p_val = str(round(float(p_vals[0]),4)) + \"e\" + p_vals[1]\n",
    "    diff_in_mean = round(np.mean(x_1) - np.mean(x_2),4)\n",
    "    rows_2.append((p,xgboost_fi.iloc[i],np.round(np.mean(x_1),4), np.round(np.mean(x_2),4), diff_in_mean,new_p_val))\n",
    "age25_test_df_2 = pd.DataFrame(rows_2, columns = ['predictor', 'feature_importance', 'age>=25_mean', 'age<25_mean', 'diff_in_mean', 'p_val'])\n",
    "age25_test_df_2.to_csv(\"cleaned_results\\\\subgroups\\\\new_comparisons\\\\XGBoost_age25_ztest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
