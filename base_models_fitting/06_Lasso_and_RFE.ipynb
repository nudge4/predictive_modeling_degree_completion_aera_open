{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\"\n",
    "results_dir = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/evaluation_results/truncated_predictors/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(fpath + \"/full_data_truncated.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    }
   ],
   "source": [
    "predictors = list(df.columns.values[10:])\n",
    "print(len(predictors))\n",
    "impute_list_1 = set([\"prop_comp_pre\",\"cum_gpa_pre\"])\n",
    "impute_list_2 = set([t1+\"_\"+t2+str(t3) for t1 in [\"term_gpa\", \"prop_comp\", \"lvl2_prop_comp\", \"dev_prop_comp\"] for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)])\n",
    "impute_list_3 = set([\"cum_gpa\", \"lvl2_prop_comp\", \"dev_prop_comp\", \"prop_comp\", \"prop_comp_sd\", \"withdrawn_prop_comp_sd\"])\n",
    "impute_list_4 = set([\"admrate\", \"gradrate\", \"satvr25\", \"satvr75\", \"satmt25\", \"satmt75\", \"satwr25\", \"satwr75\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298139, 341) (33115, 341)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.valid == 0]\n",
    "test_df = df[df.valid == 1]\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train_original, test_original):\n",
    "    train = train_original.copy()\n",
    "    test = test_original.copy()\n",
    "    for p in impute_list_1:\n",
    "        avg_p = np.nanmean(train[train.enrolled_pre == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_\" + suffix] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_4:\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_nsc\"] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_new, test_df_new = impute(train_df, test_df)\n",
    "X_train = train_df_new.loc[:,predictors]\n",
    "y_train = train_df_new.grad_6years\n",
    "X_test = test_df_new.loc[:,predictors]\n",
    "y_test = test_df_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cv_folds(n_folds, rs, train_df):\n",
    "    k_fold = StratifiedKFold(n_splits = n_folds, shuffle=True, random_state = rs)\n",
    "    data_folds = []\n",
    "    for train_indices, test_indices in k_fold.split(train_df, train_df.grad_6years):\n",
    "        train_part = train_df.iloc[train_indices, :]\n",
    "        test_part = train_df.iloc[test_indices, :]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        X1 = train_part_new.loc[:,predictors]\n",
    "        y1 = train_part_new.grad_6years\n",
    "        X2 = test_part_new.loc[:,predictors]\n",
    "        y2 = test_part_new.grad_6years\n",
    "        scaler = MinMaxScaler()\n",
    "        X1_new = scaler.fit_transform(X1)\n",
    "        X2_new = scaler.transform(X2)\n",
    "        data_folds.append((X1_new,y1,X2_new,y2))\n",
    "    return data_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "cv_folds = create_cv_folds(10, 12345, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,f in enumerate(cv_folds):\n",
    "    pickle.dump(f, open(fpath + \"/fold_{}.p\".format(i+1), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following part after executing the script \"Lasso_Classifier_CV.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) The optimal set of predictors (a total of 147) identified by Lasso feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0.8769782028442551 0.0022235769382606225\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-646719f5f42e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mbest_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": [
    "auc_list = []\n",
    "threshold_list = []\n",
    "for indx,(X_1,y_1,X_2,y_2) in enumerate(cv_folds):\n",
    "    print(indx)\n",
    "    lasso_cv = LogisticRegression(penalty='l1', C=0.01153, solver=\"saga\", max_iter=10000)\n",
    "    lasso_cv.fit(X_1,y_1)\n",
    "    p,r,t = precision_recall_curve(y_2, lasso_cv.predict_proba(X_2)[:,1])\n",
    "    auc = roc_auc_score(y_2, lasso_cv.predict_proba(X_2)[:,1])\n",
    "    threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "    auc_list.append(auc)\n",
    "print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "best_threshold = gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43858621973241146\n"
     ]
    }
   ],
   "source": [
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selected_predictors(lasso_m):\n",
    "    zero_predictors = set(np.array(predictors)[lasso_m.coef_[0] == 0])\n",
    "    nonzero_predictors = set(np.array(predictors)[lasso_m.coef_[0] != 0])\n",
    "    to_keep = []\n",
    "    for p in zero_predictors:\n",
    "        if p == 'enrolled_pre':\n",
    "            if sum([int(e in nonzero_predictors) for e in ['cum_gpa_pre', 'prop_com_pre']]) > 0:\n",
    "                to_keep.append(p)\n",
    "        elif p.startswith(\"enrolled_nsc_\"):\n",
    "            suffix = p[-4:]\n",
    "            if ('enrl_intensity_nsc' + suffix) in nonzero_predictors:\n",
    "                to_keep.append(p)\n",
    "        elif p.startswith(\"enrolled_\") or p.startswith(\"available_\"):\n",
    "            suffix = p[-4:]\n",
    "            if sum(int(e+suffix in nonzero_predictors) for e in ['withdrawn_prop_comp', 'repeat', 'pell_0', 'pell_1', 'degree_seeking', 'term_cred_att', 'term_gpa', 'prop_comp', 'lvl2_prop_comp', 'dev_prop_comp']):\n",
    "                to_keep.append(p)\n",
    "    return list(nonzero_predictors) + to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_selected_predictors = selected_predictors(lasso_1)\n",
    "pickle.dump(lasso_selected_predictors, \n",
    "            open(\"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\intermediate_files\\\\lasso_selected_predictors.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lasso_selected_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Find how the model performance changes over num of predictors: Use to generate Figure A18 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_predictors_dict_0 = {0.0001: 14, 0.001: 50, 0.01: 139, 0.1: 235, 1: 306, 100: 330}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C parameter value = 0.02:\n",
      "161\n",
      "C parameter value = 0.03:\n",
      "179\n",
      "C parameter value = 0.04:\n",
      "194\n",
      "C parameter value = 0.05:\n",
      "202\n",
      "C parameter value = 0.06:\n",
      "214\n",
      "C parameter value = 0.07:\n",
      "218\n",
      "C parameter value = 0.08:\n",
      "223\n",
      "C parameter value = 0.09:\n",
      "231\n",
      "C parameter value = 0.011:\n",
      "146\n",
      "C parameter value = 0.012:\n",
      "147\n",
      "C parameter value = 0.013:\n",
      "150\n",
      "C parameter value = 0.014:\n",
      "151\n",
      "C parameter value = 0.015:\n",
      "151\n",
      "C parameter value = 0.016:\n",
      "153\n",
      "C parameter value = 0.017:\n",
      "154\n",
      "C parameter value = 0.018:\n",
      "156\n",
      "C parameter value = 0.019:\n",
      "160\n",
      "C parameter value = 0.0111:\n",
      "146\n",
      "C parameter value = 0.0112:\n",
      "146\n",
      "C parameter value = 0.0113:\n",
      "147\n",
      "C parameter value = 0.0114:\n",
      "147\n",
      "C parameter value = 0.0115:\n",
      "147\n",
      "C parameter value = 0.0116:\n",
      "147\n",
      "C parameter value = 0.0117:\n",
      "147\n",
      "C parameter value = 0.0118:\n",
      "147\n",
      "C parameter value = 0.0119:\n",
      "147\n",
      "C parameter value = 0.01153:\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "num_of_predictors_dict_1 = {}\n",
    "grid_val =\\\n",
    "[0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09] +\\\n",
    "[0.011,0.012,0.013,0.014,0.015,0.016,0.017,0.018,0.019] +\\\n",
    "[0.0111,0.0112,0.0113,0.0114,0.0115,0.0116,0.0117,0.0118,0.0119] +\\\n",
    "[0.01153]\n",
    "for C_val in grid_val:\n",
    "    print(\"C parameter value = {}:\".format(C_val))\n",
    "    lasso_test = LogisticRegression(penalty='l1', C=C_val, solver=\"saga\", max_iter=10000)\n",
    "    lasso_test.fit(X_train_new, y_train)\n",
    "    selected = selected_predictors(lasso_test)\n",
    "    print(len(selected))\n",
    "    num_of_predictors_dict_1[C_val] = len(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C parameter value = 2.5e-05:\n",
      "0\n",
      "C parameter value = 5e-05:\n",
      "0\n",
      "C parameter value = 7.5e-05:\n",
      "10\n",
      "C parameter value = 0.00015:\n",
      "14\n",
      "C parameter value = 0.0002:\n",
      "22\n",
      "C parameter value = 0.0003:\n",
      "26\n",
      "C parameter value = 0.0005:\n",
      "36\n",
      "C parameter value = 0.00075:\n",
      "45\n",
      "C parameter value = 0.0015:\n",
      "67\n",
      "C parameter value = 0.002:\n",
      "68\n",
      "C parameter value = 0.0025:\n",
      "76\n",
      "C parameter value = 0.003:\n",
      "86\n",
      "C parameter value = 0.0035:\n",
      "90\n",
      "C parameter value = 0.004:\n",
      "95\n",
      "C parameter value = 0.0045:\n",
      "105\n",
      "C parameter value = 0.005:\n",
      "108\n",
      "C parameter value = 0.006:\n",
      "113\n",
      "C parameter value = 0.007:\n",
      "122\n",
      "C parameter value = 0.008:\n",
      "128\n",
      "C parameter value = 0.009:\n",
      "134\n",
      "C parameter value = 0.023:\n",
      "168\n",
      "C parameter value = 0.026:\n",
      "175\n",
      "C parameter value = 0.035:\n",
      "186\n",
      "C parameter value = 0.055:\n",
      "209\n",
      "C parameter value = 0.15:\n",
      "254\n",
      "C parameter value = 0.2:\n",
      "266\n",
      "C parameter value = 0.25:\n",
      "272\n",
      "C parameter value = 0.3:\n",
      "277\n",
      "C parameter value = 0.4:\n",
      "285\n",
      "C parameter value = 0.5:\n",
      "296\n",
      "C parameter value = 0.6:\n",
      "298\n",
      "C parameter value = 0.7:\n",
      "300\n",
      "C parameter value = 0.8:\n",
      "301\n",
      "C parameter value = 0.9:\n"
     ]
    }
   ],
   "source": [
    "num_of_predictors_dict_2 = {}\n",
    "for C_val in [2, 4]:\n",
    "    print(\"C parameter value = {}:\".format(C_val))\n",
    "    lasso_test = LogisticRegression(penalty='l1', C=C_val, solver=\"saga\", max_iter=10000)\n",
    "    lasso_test.fit(X_train_new, y_train)\n",
    "    selected = selected_predictors(lasso_test)\n",
    "    print(len(selected))\n",
    "    num_of_predictors_dict_2[C_val] = len(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C parameter value = 0.9:\n",
      "303\n",
      "C parameter value = 2:\n",
      "321\n",
      "C parameter value = 4:\n",
      "328\n",
      "C parameter value = 5.5e-05:\n",
      "3\n",
      "C parameter value = 6e-05:\n",
      "6\n",
      "C parameter value = 6.5e-05:\n",
      "9\n",
      "C parameter value = 7e-05:\n",
      "9\n",
      "C parameter value = 0.000175:\n",
      "19\n",
      "C parameter value = 0.0004:\n",
      "31\n",
      "C parameter value = 0.0006:\n",
      "42\n",
      "C parameter value = 0.0011:\n",
      "54\n",
      "C parameter value = 0.0012:\n",
      "62\n",
      "C parameter value = 0.0013:\n",
      "59\n",
      "C parameter value = 0.00275:\n",
      "82\n",
      "C parameter value = 0.00425:\n",
      "99\n",
      "C parameter value = 0.12:\n",
      "248\n",
      "C parameter value = 0.135:\n",
      "253\n",
      "C parameter value = 0.17:\n",
      "259\n"
     ]
    }
   ],
   "source": [
    "num_of_predictors_dict_3 = {}\n",
    "for C_val in [0.9,2,4,5.5e-5, 6e-5, 6.5e-5, 7e-5, 0.000175, 0.0004, 0.0006, 0.0011, 0.0012, 0.0013, 0.00275, 0.00425, 0.12, 0.135, 0.17]:\n",
    "    print(\"C parameter value = {}:\".format(C_val))\n",
    "    lasso_test = LogisticRegression(penalty='l1', C=C_val, solver=\"saga\", max_iter=10000)\n",
    "    lasso_test.fit(X_train_new, y_train)\n",
    "    selected = selected_predictors(lasso_test)\n",
    "    print(len(selected))\n",
    "    num_of_predictors_dict_3[C_val] = len(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C parameter value = 1.2:\n",
      "311\n",
      "C parameter value = 1.5:\n",
      "317\n",
      "C parameter value = 0.45:\n",
      "286\n",
      "C parameter value = 0.11:\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "num_of_predictors_dict_4 = {}\n",
    "for C_val in [1.2, 1.5, 0.45, 0.11]:\n",
    "    print(\"C parameter value = {}:\".format(C_val))\n",
    "    lasso_test = LogisticRegression(penalty='l1', C=C_val, solver=\"saga\", max_iter=10000)\n",
    "    lasso_test.fit(X_train_new, y_train)\n",
    "    selected = selected_predictors(lasso_test)\n",
    "    print(len(selected))\n",
    "    num_of_predictors_dict_4[C_val] = len(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C parameter value = 0.475:\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "num_of_predictors_dict_5 = {}\n",
    "for C_val in [0.475]:\n",
    "    print(\"C parameter value = {}:\".format(C_val))\n",
    "    lasso_test = LogisticRegression(penalty='l1', C=C_val, solver=\"saga\", max_iter=10000)\n",
    "    lasso_test.fit(X_train_new, y_train)\n",
    "    selected = selected_predictors(lasso_test)\n",
    "    print(len(selected))\n",
    "    num_of_predictors_dict_5[C_val] = len(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Feature ranking using RFE, for logit and OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_predictors\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 22:17:13.637940\n",
      "2020-03-17 22:38:34.030930\n"
     ]
    }
   ],
   "source": [
    "lr_estimator = LogisticRegression(solver=\"saga\", max_iter=10000)\n",
    "selector = RFE(lr_estimator, n_features_to_select=1, step=1)\n",
    "print(dt.datetime.now())\n",
    "selector.fit(X_train_new, y_train)\n",
    "print(dt.datetime.now())\n",
    "df1 = pd.DataFrame({'predictor_name':predictors, 'ranking':selector.ranking_}).sort_values(['ranking'])\n",
    "df1.to_csv(results_dir + \"reduced_lr_feature_ranking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 22:38:34.049918\n",
      "2020-03-17 22:40:58.618356\n"
     ]
    }
   ],
   "source": [
    "ols_estimator = LinearRegression()\n",
    "selector_3 = RFE(ols_estimator, n_features_to_select=1, step=1)\n",
    "print(dt.datetime.now())\n",
    "selector_3.fit(X_train_new, y_train)\n",
    "print(dt.datetime.now())\n",
    "df3 = pd.DataFrame({'predictor_name':predictors, 'ranking':selector_3.ranking_}).sort_values(['ranking'])\n",
    "df3.to_csv(results_dir + \"reduced_ols_feature_ranking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 22:40:58.637346\n",
      "2020-03-17 23:02:22.586946\n"
     ]
    }
   ],
   "source": [
    "lr2_estimator = LogisticRegression(solver=\"saga\", max_iter=10000, class_weight=\"balanced\")\n",
    "selector_2 = RFE(lr2_estimator, n_features_to_select=1, step=1)\n",
    "print(dt.datetime.now())\n",
    "selector_2.fit(X_train_new, y_train)\n",
    "print(dt.datetime.now())\n",
    "df2 = pd.DataFrame({'predictor_name':predictors, 'ranking':selector_2.ranking_}).sort_values(['ranking'])\n",
    "df2.to_csv(results_dir + \"reduced_lr2_feature_ranking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_estimator = LogisticRegression(solver=\"saga\", max_iter=10000)\n",
    "selector = RFE(lr_estimator, n_features_to_select=1, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-15 09:16:27.172666\n",
      "2020-03-16 02:46:04.836714\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now())\n",
    "selector.fit(X_train_new, y_train)\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'predictor_name':predictors, 'ranking':selector.ranking_}).sort_values(['ranking'])\n",
    "df1.to_csv(results_dir + \"lr_feature_ranking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ols_estimator = LinearRegression()\n",
    "selector_3 = RFE(ols_estimator, n_features_to_select=1, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-16 02:46:05.226761\n",
      "2020-03-16 02:59:37.192593\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now())\n",
    "selector_3.fit(X_train_new, y_train)\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'predictor_name':predictors, 'ranking':selector_3.ranking_}).sort_values(['ranking'])\n",
    "df3.to_csv(results_dir + \"ols_feature_ranking.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
