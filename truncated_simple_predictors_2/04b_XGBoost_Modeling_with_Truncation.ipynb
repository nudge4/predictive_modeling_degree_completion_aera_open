{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.stats.mstats import gmean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(fpath + \"/full_data_truncated.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'first_gen_0'] = df.phe_1 + df.phe_2 + df.phe_3\n",
    "df.loc[:,'first_gen_1'] = df.phe_4 + df.phe_5 + df.phe_6 + df.phe_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in ['term_cred_att_', 'enrolled_', 'available_']:\n",
    "    df.loc[:,v+\"sum\"] = 0\n",
    "    for t1 in ['sp','su','fa']:\n",
    "        for t2 in range(1,7):\n",
    "            t = t1+str(t2)\n",
    "            df.loc[:,v+\"sum\"] = df.loc[:,v+\"sum\"] + df.loc[:,v+t]\n",
    "df.loc[:,'avg_cred_att'] = df.term_cred_att_sum / df.enrolled_sum\n",
    "df.loc[:,'pct_enrolled'] = df.enrolled_sum / df.available_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Note: This model variant only includes 14 predictors, which are all simple non-term-specific predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "predictors = ['male', 'afam', 'white', 'hisp', 'other', 'first_gen_0', 'first_gen_1', 'cum_gpa', 'pct_enrolled', 'avg_cred_att', 'available_sum', 'prop_comp', 'pell_0_ind', 'pell_1_ind']\n",
    "print(len(predictors))\n",
    "impute_list_3 = set([\"cum_gpa\", \"prop_comp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298139, 348) (33115, 348)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.valid == 0]\n",
    "test_df = df[df.valid == 1]\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train, test):\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_df_new, test_df_new = impute(train_df, test_df)\n",
    "X_train = train_df_new.loc[:,predictors]\n",
    "y_train = train_df_new.grad_6years\n",
    "X_test = test_df_new.loc[:,predictors]\n",
    "y_test = test_df_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "val_indices = np.random.choice(train_df.shape[0], int(np.floor(train_df.shape[0]*0.15)), replace=False)\n",
    "train_val = train_df.iloc[val_indices,:]\n",
    "train_train = train_df.iloc[np.setdiff1d(np.arange(train_df.shape[0]), val_indices),:]\n",
    "train_train_new, train_val_new = impute(train_train, train_val)\n",
    "X_train_train = train_train_new.loc[:,predictors]\n",
    "y_train_train = train_train_new.grad_6years\n",
    "X_train_val = train_val_new.loc[:,predictors]\n",
    "y_train_val = train_val_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_train = xgb.DMatrix(X_train_train, y_train_train)\n",
    "dtrain_val = xgb.DMatrix(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_simple_predictors_2\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Grid Search for max_depth and eta (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 4, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.7989\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\tvalidation-auc:0.826419\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.7989\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.82868\n",
      "[100]\tvalidation-auc:0.833961\n",
      "[150]\tvalidation-auc:0.837466\n",
      "[200]\tvalidation-auc:0.840389\n",
      "[250]\tvalidation-auc:0.84226\n",
      "[300]\tvalidation-auc:0.843518\n",
      "[350]\tvalidation-auc:0.844444\n",
      "[400]\tvalidation-auc:0.845196\n",
      "[450]\tvalidation-auc:0.845798\n",
      "[500]\tvalidation-auc:0.846274\n",
      "[550]\tvalidation-auc:0.846678\n",
      "[600]\tvalidation-auc:0.847041\n",
      "[650]\tvalidation-auc:0.847316\n",
      "[700]\tvalidation-auc:0.847583\n",
      "[750]\tvalidation-auc:0.847785\n",
      "[800]\tvalidation-auc:0.847968\n",
      "[850]\tvalidation-auc:0.848143\n",
      "[900]\tvalidation-auc:0.848295\n",
      "[950]\tvalidation-auc:0.848429\n",
      "[1000]\tvalidation-auc:0.848581\n",
      "[1050]\tvalidation-auc:0.848718\n",
      "[1100]\tvalidation-auc:0.848847\n",
      "[1150]\tvalidation-auc:0.848955\n",
      "[1200]\tvalidation-auc:0.849051\n",
      "[1250]\tvalidation-auc:0.849142\n",
      "[1300]\tvalidation-auc:0.84923\n",
      "[1350]\tvalidation-auc:0.849287\n",
      "[1400]\tvalidation-auc:0.849341\n",
      "[1450]\tvalidation-auc:0.849407\n",
      "[1500]\tvalidation-auc:0.849444\n",
      "[1550]\tvalidation-auc:0.849497\n",
      "[1600]\tvalidation-auc:0.849541\n",
      "[1650]\tvalidation-auc:0.849606\n",
      "[1700]\tvalidation-auc:0.849668\n",
      "Stopping. Best iteration:\n",
      "[1736]\tvalidation-auc:0.84971\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.7989\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.835949\n",
      "[100]\tvalidation-auc:0.842345\n",
      "[150]\tvalidation-auc:0.844746\n",
      "[200]\tvalidation-auc:0.846259\n",
      "[250]\tvalidation-auc:0.847208\n",
      "[300]\tvalidation-auc:0.847851\n",
      "[350]\tvalidation-auc:0.848211\n",
      "[400]\tvalidation-auc:0.848514\n",
      "[450]\tvalidation-auc:0.848822\n",
      "[500]\tvalidation-auc:0.849076\n",
      "[550]\tvalidation-auc:0.849206\n",
      "[600]\tvalidation-auc:0.849356\n",
      "[650]\tvalidation-auc:0.849502\n",
      "[700]\tvalidation-auc:0.849624\n",
      "Stopping. Best iteration:\n",
      "[721]\tvalidation-auc:0.849678\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.7989\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.842418\n",
      "[100]\tvalidation-auc:0.84662\n",
      "[150]\tvalidation-auc:0.848066\n",
      "[200]\tvalidation-auc:0.848744\n",
      "[250]\tvalidation-auc:0.849152\n",
      "[300]\tvalidation-auc:0.849414\n",
      "[350]\tvalidation-auc:0.849617\n",
      "Stopping. Best iteration:\n",
      "[363]\tvalidation-auc:0.849677\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.7989\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.846559\n",
      "[100]\tvalidation-auc:0.848494\n",
      "[150]\tvalidation-auc:0.849051\n",
      "[200]\tvalidation-auc:0.849436\n",
      "Stopping. Best iteration:\n",
      "[216]\tvalidation-auc:0.849526\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[15]\tvalidation-auc:0.831223\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.834014\n",
      "[100]\tvalidation-auc:0.838423\n",
      "[150]\tvalidation-auc:0.841498\n",
      "[200]\tvalidation-auc:0.843579\n",
      "[250]\tvalidation-auc:0.845086\n",
      "[300]\tvalidation-auc:0.846021\n",
      "[350]\tvalidation-auc:0.846736\n",
      "[400]\tvalidation-auc:0.84735\n",
      "[450]\tvalidation-auc:0.847786\n",
      "[500]\tvalidation-auc:0.848185\n",
      "[550]\tvalidation-auc:0.848492\n",
      "[600]\tvalidation-auc:0.848738\n",
      "[650]\tvalidation-auc:0.848964\n",
      "[700]\tvalidation-auc:0.849156\n",
      "[750]\tvalidation-auc:0.849309\n",
      "[800]\tvalidation-auc:0.849442\n",
      "[850]\tvalidation-auc:0.849559\n",
      "[900]\tvalidation-auc:0.849669\n",
      "[950]\tvalidation-auc:0.849739\n",
      "[1000]\tvalidation-auc:0.849808\n",
      "[1050]\tvalidation-auc:0.84989\n",
      "[1100]\tvalidation-auc:0.849959\n",
      "[1150]\tvalidation-auc:0.850036\n",
      "[1200]\tvalidation-auc:0.850098\n",
      "[1250]\tvalidation-auc:0.850151\n",
      "[1300]\tvalidation-auc:0.850206\n",
      "Stopping. Best iteration:\n",
      "[1309]\tvalidation-auc:0.850215\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.839908\n",
      "[100]\tvalidation-auc:0.844959\n",
      "[150]\tvalidation-auc:0.846994\n",
      "[200]\tvalidation-auc:0.848107\n",
      "[250]\tvalidation-auc:0.848843\n",
      "[300]\tvalidation-auc:0.849274\n",
      "[350]\tvalidation-auc:0.849518\n",
      "[400]\tvalidation-auc:0.849698\n",
      "[450]\tvalidation-auc:0.849869\n",
      "Stopping. Best iteration:\n",
      "[465]\tvalidation-auc:0.849914\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.844977\n",
      "[100]\tvalidation-auc:0.848257\n",
      "[150]\tvalidation-auc:0.849034\n",
      "[200]\tvalidation-auc:0.849496\n",
      "[250]\tvalidation-auc:0.849812\n",
      "Stopping. Best iteration:\n",
      "[245]\tvalidation-auc:0.849834\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.847988\n",
      "[100]\tvalidation-auc:0.849444\n",
      "Stopping. Best iteration:\n",
      "[106]\tvalidation-auc:0.849565\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.814079\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.836367\n",
      "[100]\tvalidation-auc:0.838453\n",
      "[150]\tvalidation-auc:0.840182\n",
      "[200]\tvalidation-auc:0.841567\n",
      "[250]\tvalidation-auc:0.843027\n",
      "[300]\tvalidation-auc:0.844238\n",
      "[350]\tvalidation-auc:0.845162\n",
      "[400]\tvalidation-auc:0.845929\n",
      "[450]\tvalidation-auc:0.84655\n",
      "[500]\tvalidation-auc:0.847059\n",
      "[550]\tvalidation-auc:0.847486\n",
      "[600]\tvalidation-auc:0.84787\n",
      "[650]\tvalidation-auc:0.848166\n",
      "[700]\tvalidation-auc:0.848457\n",
      "[750]\tvalidation-auc:0.848677\n",
      "[800]\tvalidation-auc:0.848892\n",
      "[850]\tvalidation-auc:0.849115\n",
      "[900]\tvalidation-auc:0.849263\n",
      "[950]\tvalidation-auc:0.849408\n",
      "[1000]\tvalidation-auc:0.84953\n",
      "[1050]\tvalidation-auc:0.849644\n",
      "[1100]\tvalidation-auc:0.84976\n",
      "[1150]\tvalidation-auc:0.849858\n",
      "[1200]\tvalidation-auc:0.849943\n",
      "[1250]\tvalidation-auc:0.85002\n",
      "[1300]\tvalidation-auc:0.850081\n",
      "[1350]\tvalidation-auc:0.850121\n",
      "[1400]\tvalidation-auc:0.850168\n",
      "[1450]\tvalidation-auc:0.850221\n",
      "[1500]\tvalidation-auc:0.850256\n",
      "[1550]\tvalidation-auc:0.850287\n",
      "Stopping. Best iteration:\n",
      "[1559]\tvalidation-auc:0.850296\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.814079\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.838211\n",
      "[100]\tvalidation-auc:0.84167\n",
      "[150]\tvalidation-auc:0.844206\n",
      "[200]\tvalidation-auc:0.845909\n",
      "[250]\tvalidation-auc:0.847086\n",
      "[300]\tvalidation-auc:0.847861\n",
      "[350]\tvalidation-auc:0.848429\n",
      "[400]\tvalidation-auc:0.848871\n",
      "[450]\tvalidation-auc:0.849267\n",
      "[500]\tvalidation-auc:0.849515\n",
      "[550]\tvalidation-auc:0.84968\n",
      "[600]\tvalidation-auc:0.849847\n",
      "[650]\tvalidation-auc:0.849966\n",
      "[700]\tvalidation-auc:0.850087\n",
      "[750]\tvalidation-auc:0.850184\n",
      "[800]\tvalidation-auc:0.850265\n",
      "[850]\tvalidation-auc:0.85035\n",
      "[900]\tvalidation-auc:0.850433\n",
      "[950]\tvalidation-auc:0.850496\n",
      "Stopping. Best iteration:\n",
      "[958]\tvalidation-auc:0.850519\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.814079\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.842921\n",
      "[100]\tvalidation-auc:0.846999\n",
      "[150]\tvalidation-auc:0.848635\n",
      "[200]\tvalidation-auc:0.849387\n",
      "[250]\tvalidation-auc:0.8498\n",
      "[300]\tvalidation-auc:0.850036\n",
      "Stopping. Best iteration:\n",
      "[309]\tvalidation-auc:0.850059\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.814079\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.846672\n",
      "[100]\tvalidation-auc:0.849112\n",
      "Stopping. Best iteration:\n",
      "[134]\tvalidation-auc:0.849663\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.814079\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.848879\n",
      "[100]\tvalidation-auc:0.849907\n",
      "Stopping. Best iteration:\n",
      "[126]\tvalidation-auc:0.850014\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.817\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[13]\tvalidation-auc:0.83908\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.817\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841417\n",
      "[100]\tvalidation-auc:0.84426\n",
      "[150]\tvalidation-auc:0.846306\n",
      "[200]\tvalidation-auc:0.847672\n",
      "[250]\tvalidation-auc:0.848572\n",
      "[300]\tvalidation-auc:0.849195\n",
      "[350]\tvalidation-auc:0.849617\n",
      "[400]\tvalidation-auc:0.84993\n",
      "[450]\tvalidation-auc:0.850173\n",
      "[500]\tvalidation-auc:0.850326\n",
      "[550]\tvalidation-auc:0.850459\n",
      "[600]\tvalidation-auc:0.850557\n",
      "Stopping. Best iteration:\n",
      "[630]\tvalidation-auc:0.850594\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.845023\n",
      "[100]\tvalidation-auc:0.848321\n",
      "[150]\tvalidation-auc:0.849661\n",
      "[200]\tvalidation-auc:0.850203\n",
      "[250]\tvalidation-auc:0.850498\n",
      "[300]\tvalidation-auc:0.850603\n",
      "Stopping. Best iteration:\n",
      "[291]\tvalidation-auc:0.85061\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.817\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.848356\n",
      "[100]\tvalidation-auc:0.850107\n",
      "Stopping. Best iteration:\n",
      "[132]\tvalidation-auc:0.850332\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.817\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.849052\n",
      "Stopping. Best iteration:\n",
      "[58]\tvalidation-auc:0.849311\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_1 = [(md,e) for md in range(4,8) for e in [0.01, 0.02, 0.05, 0.1, 0.2]]\n",
    "validation_auc_1 = Counter()\n",
    "for md,e in grid_1:\n",
    "    print(\"max_depth = {0}, eta = {1}:\".format(md,e))\n",
    "    params = {'max_depth': md, 'eta': e, 'min_child_weight': 1, 'colsample_bytree': 0.8, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_1[(md,e)] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 0.05), 0.85061)\n",
      "((7, 0.02), 0.850594)\n",
      "((6, 0.02), 0.850519)\n",
      "((7, 0.1), 0.850332)\n",
      "((6, 0.01), 0.850296)\n",
      "((5, 0.02), 0.850215)\n",
      "((6, 0.05), 0.850059)\n",
      "((6, 0.2), 0.850014)\n",
      "((5, 0.05), 0.849914)\n",
      "((5, 0.1), 0.849834)\n",
      "((4, 0.02), 0.84971)\n",
      "((4, 0.05), 0.849678)\n",
      "((4, 0.1), 0.849677)\n",
      "((6, 0.1), 0.849663)\n",
      "((5, 0.2), 0.849565)\n",
      "((4, 0.2), 0.849526)\n",
      "((7, 0.2), 0.849311)\n",
      "((7, 0.01), 0.83908)\n",
      "((5, 0.01), 0.831223)\n",
      "((4, 0.01), 0.826419)\n"
     ]
    }
   ],
   "source": [
    "for t in validation_auc_1.most_common():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Grid Search for min_child_weight (along with max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 5, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.834017\n",
      "[100]\tvalidation-auc:0.838419\n",
      "[150]\tvalidation-auc:0.841474\n",
      "[200]\tvalidation-auc:0.843564\n",
      "[250]\tvalidation-auc:0.845046\n",
      "[300]\tvalidation-auc:0.845979\n",
      "[350]\tvalidation-auc:0.846674\n",
      "[400]\tvalidation-auc:0.847295\n",
      "[450]\tvalidation-auc:0.847786\n",
      "[500]\tvalidation-auc:0.848159\n",
      "[550]\tvalidation-auc:0.848454\n",
      "[600]\tvalidation-auc:0.848724\n",
      "[650]\tvalidation-auc:0.848941\n",
      "[700]\tvalidation-auc:0.84914\n",
      "[750]\tvalidation-auc:0.849297\n",
      "[800]\tvalidation-auc:0.849445\n",
      "[850]\tvalidation-auc:0.849594\n",
      "[900]\tvalidation-auc:0.849692\n",
      "[950]\tvalidation-auc:0.849777\n",
      "[1000]\tvalidation-auc:0.849856\n",
      "[1050]\tvalidation-auc:0.849944\n",
      "Stopping. Best iteration:\n",
      "[1057]\tvalidation-auc:0.849962\n",
      "\n",
      "\n",
      "max_depth = 5, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.806552\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.834019\n",
      "[100]\tvalidation-auc:0.838418\n",
      "[150]\tvalidation-auc:0.841495\n",
      "[200]\tvalidation-auc:0.843568\n",
      "[250]\tvalidation-auc:0.845084\n",
      "[300]\tvalidation-auc:0.846036\n",
      "[350]\tvalidation-auc:0.846721\n",
      "[400]\tvalidation-auc:0.847325\n",
      "[450]\tvalidation-auc:0.847801\n",
      "[500]\tvalidation-auc:0.848196\n",
      "[550]\tvalidation-auc:0.848513\n",
      "[600]\tvalidation-auc:0.848765\n",
      "[650]\tvalidation-auc:0.848957\n",
      "[700]\tvalidation-auc:0.849149\n",
      "[750]\tvalidation-auc:0.849306\n",
      "[800]\tvalidation-auc:0.849441\n",
      "[850]\tvalidation-auc:0.849578\n",
      "[900]\tvalidation-auc:0.849677\n",
      "[950]\tvalidation-auc:0.849785\n",
      "[1000]\tvalidation-auc:0.849866\n",
      "[1050]\tvalidation-auc:0.849945\n",
      "Stopping. Best iteration:\n",
      "[1057]\tvalidation-auc:0.849959\n",
      "\n",
      "\n",
      "max_depth = 6, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.81411\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.838214\n",
      "[100]\tvalidation-auc:0.841681\n",
      "[150]\tvalidation-auc:0.844285\n",
      "[200]\tvalidation-auc:0.84592\n",
      "[250]\tvalidation-auc:0.84711\n",
      "[300]\tvalidation-auc:0.847897\n",
      "[350]\tvalidation-auc:0.848443\n",
      "[400]\tvalidation-auc:0.848853\n",
      "[450]\tvalidation-auc:0.849212\n",
      "[500]\tvalidation-auc:0.849474\n",
      "[550]\tvalidation-auc:0.849648\n",
      "[600]\tvalidation-auc:0.849853\n",
      "[650]\tvalidation-auc:0.850006\n",
      "[700]\tvalidation-auc:0.850121\n",
      "[750]\tvalidation-auc:0.850192\n",
      "[800]\tvalidation-auc:0.850268\n",
      "[850]\tvalidation-auc:0.850353\n",
      "Stopping. Best iteration:\n",
      "[888]\tvalidation-auc:0.850432\n",
      "\n",
      "\n",
      "max_depth = 6, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.81411\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.838218\n",
      "[100]\tvalidation-auc:0.841685\n",
      "[150]\tvalidation-auc:0.844225\n",
      "[200]\tvalidation-auc:0.845902\n",
      "[250]\tvalidation-auc:0.847099\n",
      "[300]\tvalidation-auc:0.847849\n",
      "[350]\tvalidation-auc:0.848431\n",
      "[400]\tvalidation-auc:0.848879\n",
      "[450]\tvalidation-auc:0.849238\n",
      "[500]\tvalidation-auc:0.849509\n",
      "[550]\tvalidation-auc:0.849688\n",
      "[600]\tvalidation-auc:0.849872\n",
      "[650]\tvalidation-auc:0.850002\n",
      "[700]\tvalidation-auc:0.850121\n",
      "[750]\tvalidation-auc:0.8502\n",
      "[800]\tvalidation-auc:0.850299\n",
      "[850]\tvalidation-auc:0.850373\n",
      "[900]\tvalidation-auc:0.850465\n",
      "Stopping. Best iteration:\n",
      "[902]\tvalidation-auc:0.850472\n",
      "\n",
      "\n",
      "max_depth = 7, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.817055\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841441\n",
      "[100]\tvalidation-auc:0.844243\n",
      "[150]\tvalidation-auc:0.846289\n",
      "[200]\tvalidation-auc:0.847654\n",
      "[250]\tvalidation-auc:0.848589\n",
      "[300]\tvalidation-auc:0.849188\n",
      "[350]\tvalidation-auc:0.84962\n",
      "[400]\tvalidation-auc:0.849914\n",
      "[450]\tvalidation-auc:0.850146\n",
      "[500]\tvalidation-auc:0.850296\n",
      "[550]\tvalidation-auc:0.85042\n",
      "[600]\tvalidation-auc:0.850553\n",
      "Stopping. Best iteration:\n",
      "[623]\tvalidation-auc:0.850599\n",
      "\n",
      "\n",
      "max_depth = 7, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.817056\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841454\n",
      "[100]\tvalidation-auc:0.844249\n",
      "[150]\tvalidation-auc:0.846313\n",
      "[200]\tvalidation-auc:0.847646\n",
      "[250]\tvalidation-auc:0.848577\n",
      "[300]\tvalidation-auc:0.849185\n",
      "[350]\tvalidation-auc:0.849654\n",
      "[400]\tvalidation-auc:0.849941\n",
      "[450]\tvalidation-auc:0.850167\n",
      "[500]\tvalidation-auc:0.850332\n",
      "[550]\tvalidation-auc:0.850437\n",
      "[600]\tvalidation-auc:0.850549\n",
      "[650]\tvalidation-auc:0.85062\n",
      "[700]\tvalidation-auc:0.850693\n",
      "Stopping. Best iteration:\n",
      "[702]\tvalidation-auc:0.850697\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md1 = 6\n",
    "grid_2 = [(md1+i,mcw) for i in [-1,0,1] for mcw in [3,5]]\n",
    "validation_auc_2 = Counter()\n",
    "for md,mcw in grid_2:\n",
    "    print(\"max_depth = {0}, min_child_weight = {1}:\".format(md,mcw))\n",
    "    params = {'max_depth': md, 'eta': 0.02, 'min_child_weight': mcw, 'colsample_bytree': 0.8, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_2[(md,mcw)] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 5), 0.850697)\n",
      "((7, 3), 0.850599)\n",
      "((6, 5), 0.850472)\n",
      "((6, 3), 0.850432)\n",
      "((5, 3), 0.849962)\n",
      "((5, 5), 0.849959)\n"
     ]
    }
   ],
   "source": [
    "for t in validation_auc_2.most_common():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Grid Search for colsample_by_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_by_tree = 0.5:\n",
      "[0]\tvalidation-auc:0.669135\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation-auc:0.83465\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.55:\n",
      "[0]\tvalidation-auc:0.669135\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation-auc:0.83465\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.6:\n",
      "[0]\tvalidation-auc:0.806231\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation-auc:0.840852\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.65:\n",
      "[0]\tvalidation-auc:0.806231\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841683\n",
      "[100]\tvalidation-auc:0.843626\n",
      "[150]\tvalidation-auc:0.845728\n",
      "[200]\tvalidation-auc:0.84703\n",
      "[250]\tvalidation-auc:0.848265\n",
      "[300]\tvalidation-auc:0.849077\n",
      "[350]\tvalidation-auc:0.849593\n",
      "[400]\tvalidation-auc:0.8499\n",
      "[450]\tvalidation-auc:0.850143\n",
      "[500]\tvalidation-auc:0.850333\n",
      "[550]\tvalidation-auc:0.850465\n",
      "[600]\tvalidation-auc:0.850556\n",
      "[650]\tvalidation-auc:0.850621\n",
      "[700]\tvalidation-auc:0.850707\n",
      "Stopping. Best iteration:\n",
      "[737]\tvalidation-auc:0.850754\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.7:\n",
      "[0]\tvalidation-auc:0.806231\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841683\n",
      "[100]\tvalidation-auc:0.843626\n",
      "[150]\tvalidation-auc:0.845728\n",
      "[200]\tvalidation-auc:0.84703\n",
      "[250]\tvalidation-auc:0.848265\n",
      "[300]\tvalidation-auc:0.849077\n",
      "[350]\tvalidation-auc:0.849593\n",
      "[400]\tvalidation-auc:0.8499\n",
      "[450]\tvalidation-auc:0.850143\n",
      "[500]\tvalidation-auc:0.850333\n",
      "[550]\tvalidation-auc:0.850465\n",
      "[600]\tvalidation-auc:0.850556\n",
      "[650]\tvalidation-auc:0.850621\n",
      "[700]\tvalidation-auc:0.850707\n",
      "Stopping. Best iteration:\n",
      "[737]\tvalidation-auc:0.850754\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.75:\n",
      "[0]\tvalidation-auc:0.817056\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.84191\n",
      "[100]\tvalidation-auc:0.844178\n",
      "[150]\tvalidation-auc:0.846095\n",
      "[200]\tvalidation-auc:0.847385\n",
      "[250]\tvalidation-auc:0.84846\n",
      "[300]\tvalidation-auc:0.849172\n",
      "[350]\tvalidation-auc:0.849562\n",
      "[400]\tvalidation-auc:0.849879\n",
      "[450]\tvalidation-auc:0.850112\n",
      "[500]\tvalidation-auc:0.850292\n",
      "[550]\tvalidation-auc:0.850423\n",
      "[600]\tvalidation-auc:0.850512\n",
      "Stopping. Best iteration:\n",
      "[615]\tvalidation-auc:0.850555\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.8:\n",
      "[0]\tvalidation-auc:0.817056\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841454\n",
      "[100]\tvalidation-auc:0.844249\n",
      "[150]\tvalidation-auc:0.846313\n",
      "[200]\tvalidation-auc:0.847646\n",
      "[250]\tvalidation-auc:0.848577\n",
      "[300]\tvalidation-auc:0.849185\n",
      "[350]\tvalidation-auc:0.849654\n",
      "[400]\tvalidation-auc:0.849941\n",
      "[450]\tvalidation-auc:0.850167\n",
      "[500]\tvalidation-auc:0.850332\n",
      "[550]\tvalidation-auc:0.850437\n",
      "[600]\tvalidation-auc:0.850549\n",
      "[650]\tvalidation-auc:0.85062\n",
      "[700]\tvalidation-auc:0.850693\n",
      "Stopping. Best iteration:\n",
      "[702]\tvalidation-auc:0.850697\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.85:\n",
      "[0]\tvalidation-auc:0.817056\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841454\n",
      "[100]\tvalidation-auc:0.844249\n",
      "[150]\tvalidation-auc:0.846313\n",
      "[200]\tvalidation-auc:0.847646\n",
      "[250]\tvalidation-auc:0.848577\n",
      "[300]\tvalidation-auc:0.849185\n",
      "[350]\tvalidation-auc:0.849654\n",
      "[400]\tvalidation-auc:0.849941\n",
      "[450]\tvalidation-auc:0.850167\n",
      "[500]\tvalidation-auc:0.850332\n",
      "[550]\tvalidation-auc:0.850437\n",
      "[600]\tvalidation-auc:0.850549\n",
      "[650]\tvalidation-auc:0.85062\n",
      "[700]\tvalidation-auc:0.850693\n",
      "Stopping. Best iteration:\n",
      "[702]\tvalidation-auc:0.850697\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.9:\n",
      "[0]\tvalidation-auc:0.825378\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.840816\n",
      "[100]\tvalidation-auc:0.843998\n",
      "[150]\tvalidation-auc:0.846063\n",
      "[200]\tvalidation-auc:0.847447\n",
      "[250]\tvalidation-auc:0.848467\n",
      "[300]\tvalidation-auc:0.849077\n",
      "[350]\tvalidation-auc:0.849515\n",
      "[400]\tvalidation-auc:0.849812\n",
      "[450]\tvalidation-auc:0.850055\n",
      "[500]\tvalidation-auc:0.850202\n",
      "[550]\tvalidation-auc:0.850301\n",
      "[600]\tvalidation-auc:0.850416\n",
      "[650]\tvalidation-auc:0.850506\n",
      "[700]\tvalidation-auc:0.850602\n",
      "Stopping. Best iteration:\n",
      "[739]\tvalidation-auc:0.850653\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_3 = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "validation_auc_3 = Counter()\n",
    "for cbt in grid_3:\n",
    "    print(\"colsample_by_tree = {}:\".format(cbt))\n",
    "    params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 5, 'colsample_bytree': cbt, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_3[cbt] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7, 0.850754),\n",
       " (0.65, 0.850754),\n",
       " (0.85, 0.850697),\n",
       " (0.8, 0.850697),\n",
       " (0.9, 0.850653),\n",
       " (0.75, 0.850555),\n",
       " (0.6, 0.840852),\n",
       " (0.5, 0.83465),\n",
       " (0.55, 0.83465)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_auc_3.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Finally select the opitmal num_boost_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.806231\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.841683\n",
      "[100]\tvalidation-auc:0.843626\n",
      "[150]\tvalidation-auc:0.845728\n",
      "[200]\tvalidation-auc:0.84703\n",
      "[250]\tvalidation-auc:0.848265\n",
      "[300]\tvalidation-auc:0.849077\n",
      "[350]\tvalidation-auc:0.849593\n",
      "[400]\tvalidation-auc:0.8499\n",
      "[450]\tvalidation-auc:0.850143\n",
      "[500]\tvalidation-auc:0.850333\n",
      "[550]\tvalidation-auc:0.850465\n",
      "[600]\tvalidation-auc:0.850556\n",
      "[650]\tvalidation-auc:0.850621\n",
      "[700]\tvalidation-auc:0.850707\n",
      "Stopping. Best iteration:\n",
      "[737]\tvalidation-auc:0.850754\n",
      "\n",
      "\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 5, 'colsample_bytree': 0.7, \n",
    "          'subsample': 0.8, \n",
    "          'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "          'seed': 12345}\n",
    "evals_result = {}\n",
    "xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                      early_stopping_rounds = 10,\n",
    "                      evals_result = evals_result,\n",
    "                      verbose_eval = 50)\n",
    "optimal_num_boost_round = np.argmax(evals_result['validation']['auc'])\n",
    "print(\"\")\n",
    "print(optimal_num_boost_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Train the final xgb model and make predictions for observations in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_num_boost_round = 737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 5, 'colsample_bytree': 0.7, \n",
    "          'subsample': 0.8, \n",
    "          'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "          'seed': 12345}\n",
    "final_xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = optimal_num_boost_round)\n",
    "# make prediction for observations in the test set\n",
    "y_test_pred = final_xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "AUC = 0.855\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(dtest.get_label(), y_test_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model object and predicted scores on the validation sample to local disk\n",
    "# pickle.dump(final_xgb_model, open(results_dir + \"/xgb.p\", \"wb\"))\n",
    "pickle.dump(list(y_test_pred), open(results_dir + \"/y_test_pred_xgb.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(list(final_xgb_model.get_fscore().items()), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "feature_importance.loc[:, 'importance'] = feature_importance.loc[:, 'importance'] / sum(feature_importance.loc[:, 'importance'])\n",
    "yy = feature_importance.loc[:, 'importance'].iloc[:20]\n",
    "xx = feature_importance.loc[:, 'feature'].iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_summary = feature_importance.rename(columns = {'feature':'predictor_name',\n",
    "                                                   'importance':'feature_importance'})\\\n",
    ".loc[:,['predictor_name', 'feature_importance']]\n",
    "xgb_summary = xgb_summary.merge(pd.DataFrame({'predictor_name': predictors}), on=['predictor_name'], how='right')\\\n",
    ".sort_values(['feature_importance', 'predictor_name'], ascending=[False, True]).fillna(0)\n",
    "xgb_summary.to_csv(results_dir + \"xgb_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAJ5CAYAAAD8YMV2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzAriBN3MzMzMrCBO0M3MzMzMCvL/Adh76KGDgw3rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.bar(list(range(14)), yy, width=0.75, color = \"orange\")\n",
    "plt.xticks(list(range(14)), xx, rotation = 'vertical', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Predictor\", fontsize=16, color=\"gray\")\n",
    "plt.ylabel(\"Feature Importance\", fontsize=16, color=\"gray\")\n",
    "plt.savefig(results_dir + \"XGBoost_variable_importance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t\n",
    "\n",
    "def cross_validation(train, xgb_params, nbr):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grad_6years):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        X_1 = train_part_new.loc[:,predictors]\n",
    "        y_1 = train_part_new.grad_6years\n",
    "        X_2 = test_part_new.loc[:,predictors]\n",
    "        y_2 = test_part_new.grad_6years\n",
    "        dtrain_cv = xgb.DMatrix(X_1,y_1)\n",
    "        dtest_cv = xgb.DMatrix(X_2,y_2)\n",
    "        xgb_cv_model = xgb.train(params=xgb_params, dtrain=dtrain_cv, num_boost_round = nbr)\n",
    "        y_2_pred = xgb_cv_model.predict(dtest_cv)\n",
    "        p,r,t = precision_recall_curve(y_2, y_2_pred)\n",
    "        auc = roc_auc_score(y_2, y_2_pred)\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8523419272699062 0.002535903987580834\n"
     ]
    }
   ],
   "source": [
    "final_params = {'max_depth': 7, 'eta': 0.02, 'min_child_weight': 5, 'colsample_bytree': 0.7, \n",
    "                'subsample': 0.8, \n",
    "                'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "                'seed': 12345}\n",
    "best_threshold = cross_validation(train_df, final_params, optimal_num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34333235"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.343:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  16963.0   4845.0  21808.0\n",
      "Real_1   2592.0   8715.0  11307.0\n",
      "        19555.0  13560.0  33115.0\n",
      "\n",
      "F1 score = 0.7009\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "pr_xgb = create_confusion_matrix(y_test_pred, best_threshold, \"XGBoost_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.416:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18348.0   3460.0  21808.0\n",
      "Real_1   3441.0   7866.0  11307.0\n",
      "        21789.0  11326.0  33115.0\n",
      "\n",
      "F1 score = 0.6951\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.grad_6years))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "pr2_xgb = create_confusion_matrix(y_test_pred_binary, best_threshold, \"XGBoost_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df = pd.DataFrame([(best_threshold,)+pr_xgb,(alternative_threshold,)+pr2_xgb]).round(4)\n",
    "precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df.to_csv(results_dir + \"XGBoost_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Reorganize files of key evaluation metrics for the five truncated models: OLS, Logit, RF, XGBoost, CoxPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract all of the key evaluation metrics of the five truncated models that only include simple non-term-specific predictors,\n",
    "# which will be used to populate column (2) within the Appendix Table A1 of the paper, as well as to generate Figure 1 and\n",
    "# Figure A14\n",
    "cstat = [0.8183,0.8105,0.8368,0.8516,0.855]\n",
    "m_dict = {'Logit': 'LR1', 'OLS': 'OLS',\n",
    "          'RF': 'RF', 'XGBoost': 'XGBoost',\n",
    "          'CoxPH': 'Cox'}\n",
    "m_list = ['Logit', 'OLS', 'CoxPH', 'RF', 'XGBoost']\n",
    "summary = []\n",
    "for c,m in zip(cstat,m_list):\n",
    "    summary.append((m,c)+tuple(pd.read_csv(results_dir + \"\\\\{}_precision_recall.csv\".format(m_dict[m])).iloc[0,1:]))\n",
    "summary_df = pd.DataFrame(summary, columns=['model','c-statistic','threshold','precision_1','recall_1',\n",
    "                                            'precision_0','recall_0','f1_score_1'])\n",
    "summary_df.loc[:,'f1_score_0'] = 2*summary_df.precision_0*summary_df.recall_0/(summary_df.precision_0+summary_df.recall_0)\n",
    "summary_df.loc[:,'f1_score_0'] = summary_df.loc[:,'f1_score_0'].apply(lambda x: round(x,4))\n",
    "summary_df.to_csv(results_dir + \"cleaned_results\\\\main_eval_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
