{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.stats.mstats import gmean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats.mstats import gmean\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_stata(fpath + \"/full_data_6yr.dta\")\n",
    "df1 = df1[df1.valid == 0]\n",
    "df1.loc[:,'first_gen_0'] = df1.phe_1 + df1.phe_2 + df1.phe_3\n",
    "df1.loc[:,'first_gen_1'] = df1.phe_4 + df1.phe_5 + df1.phe_6 + df1.phe_7\n",
    "for v in ['term_cred_att_', 'enrolled_']:\n",
    "    df1.loc[:,v+\"sum\"] = 0\n",
    "    for t1 in ['sp','su','fa']:\n",
    "        for t2 in range(1,7):\n",
    "            t = t1+str(t2)\n",
    "            df1.loc[:,v+\"sum\"] = df1.loc[:,v+\"sum\"] + df1.loc[:,v+t]\n",
    "df1.loc[:,'avg_cred_att'] = df1.term_cred_att_sum / df1.enrolled_sum\n",
    "df1.loc[:,'pct_enrolled'] = df1.enrolled_sum / 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_stata(fpath + \"/full_data_truncated.dta\")\n",
    "df2 = df2[df2.valid == 1]\n",
    "df2.loc[:,'first_gen_0'] = df2.phe_1 + df2.phe_2 + df2.phe_3\n",
    "df2.loc[:,'first_gen_1'] = df2.phe_4 + df2.phe_5 + df2.phe_6 + df2.phe_7\n",
    "for v in ['term_cred_att_', 'enrolled_', 'available_']:\n",
    "    df2.loc[:,v+\"sum\"] = 0\n",
    "    for t1 in ['sp','su','fa']:\n",
    "        for t2 in range(1,7):\n",
    "            t = t1+str(t2)\n",
    "            df2.loc[:,v+\"sum\"] = df2.loc[:,v+\"sum\"] + df2.loc[:,v+t]\n",
    "df2.loc[:,'avg_cred_att'] = df2.term_cred_att_sum / df2.enrolled_sum\n",
    "df2.loc[:,'pct_enrolled'] = df2.enrolled_sum / df2.available_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2], join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Note: This model variant only includes 14 predictors, which are all simple non-term-specific predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "predictors = ['male', 'afam', 'white', 'hisp', 'other', 'first_gen_0', 'first_gen_1', 'cum_gpa', 'pct_enrolled', 'avg_cred_att', 'prop_comp', 'pell_0_ind', 'pell_1_ind']\n",
    "print(len(predictors))\n",
    "impute_list_3 = set([\"cum_gpa\", \"prop_comp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300144, 329) (33115, 329)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.valid == 0]\n",
    "test_df = df[df.valid == 1]\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train, test):\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_df_new, test_df_new = impute(train_df, test_df)\n",
    "X_train = train_df_new.loc[:,predictors]\n",
    "y_train = train_df_new.grad_6years\n",
    "X_test = test_df_new.loc[:,predictors]\n",
    "y_test = test_df_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "val_indices = np.random.choice(train_df.shape[0], int(np.floor(train_df.shape[0]*0.15)), replace=False)\n",
    "train_val = train_df.iloc[val_indices,:]\n",
    "train_train = train_df.iloc[np.setdiff1d(np.arange(train_df.shape[0]), val_indices),:]\n",
    "train_train_new, train_val_new = impute(train_train, train_val)\n",
    "X_train_train = train_train_new.loc[:,predictors]\n",
    "y_train_train = train_train_new.grad_6years\n",
    "X_train_val = train_val_new.loc[:,predictors]\n",
    "y_train_val = train_val_new.grad_6years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_train = xgb.DMatrix(X_train_train, y_train_train)\n",
    "dtrain_val = xgb.DMatrix(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_simple_predictors_2\\\\no_truncation\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Grid Search for max_depth and eta (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 4, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.838963\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.85669\n",
      "[100]\tvalidation-auc:0.859617\n",
      "[150]\tvalidation-auc:0.861582\n",
      "[200]\tvalidation-auc:0.863102\n",
      "[250]\tvalidation-auc:0.864313\n",
      "[300]\tvalidation-auc:0.865424\n",
      "[350]\tvalidation-auc:0.866462\n",
      "[400]\tvalidation-auc:0.867331\n",
      "[450]\tvalidation-auc:0.868076\n",
      "[500]\tvalidation-auc:0.868642\n",
      "[550]\tvalidation-auc:0.869071\n",
      "[600]\tvalidation-auc:0.869403\n",
      "[650]\tvalidation-auc:0.869689\n",
      "[700]\tvalidation-auc:0.869956\n",
      "[750]\tvalidation-auc:0.870178\n",
      "[800]\tvalidation-auc:0.870373\n",
      "[850]\tvalidation-auc:0.870558\n",
      "[900]\tvalidation-auc:0.870713\n",
      "[950]\tvalidation-auc:0.870888\n",
      "[1000]\tvalidation-auc:0.871023\n",
      "[1050]\tvalidation-auc:0.87117\n",
      "[1100]\tvalidation-auc:0.871289\n",
      "[1150]\tvalidation-auc:0.871398\n",
      "[1200]\tvalidation-auc:0.8715\n",
      "[1250]\tvalidation-auc:0.871579\n",
      "[1300]\tvalidation-auc:0.871682\n",
      "[1350]\tvalidation-auc:0.871756\n",
      "[1400]\tvalidation-auc:0.871846\n",
      "[1450]\tvalidation-auc:0.871904\n",
      "[1500]\tvalidation-auc:0.871987\n",
      "[1550]\tvalidation-auc:0.872065\n",
      "[1600]\tvalidation-auc:0.872121\n",
      "[1650]\tvalidation-auc:0.872188\n",
      "[1700]\tvalidation-auc:0.872245\n",
      "[1750]\tvalidation-auc:0.872292\n",
      "[1800]\tvalidation-auc:0.872342\n",
      "[1850]\tvalidation-auc:0.872377\n",
      "[1900]\tvalidation-auc:0.872424\n",
      "[1950]\tvalidation-auc:0.872458\n",
      "[2000]\tvalidation-auc:0.872499\n",
      "[2050]\tvalidation-auc:0.872531\n",
      "[2100]\tvalidation-auc:0.872561\n",
      "[2150]\tvalidation-auc:0.872593\n",
      "[2200]\tvalidation-auc:0.872618\n",
      "[2250]\tvalidation-auc:0.872645\n",
      "[2300]\tvalidation-auc:0.872675\n",
      "[2350]\tvalidation-auc:0.872706\n",
      "[2400]\tvalidation-auc:0.872726\n",
      "[2450]\tvalidation-auc:0.872751\n",
      "[2500]\tvalidation-auc:0.872776\n",
      "[2550]\tvalidation-auc:0.8728\n",
      "Stopping. Best iteration:\n",
      "[2556]\tvalidation-auc:0.872805\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.838963\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.85977\n",
      "[100]\tvalidation-auc:0.863076\n",
      "[150]\tvalidation-auc:0.865534\n",
      "[200]\tvalidation-auc:0.867431\n",
      "[250]\tvalidation-auc:0.868743\n",
      "[300]\tvalidation-auc:0.869517\n",
      "[350]\tvalidation-auc:0.870088\n",
      "[400]\tvalidation-auc:0.870489\n",
      "[450]\tvalidation-auc:0.870869\n",
      "[500]\tvalidation-auc:0.871156\n",
      "[550]\tvalidation-auc:0.871392\n",
      "[600]\tvalidation-auc:0.871598\n",
      "[650]\tvalidation-auc:0.871779\n",
      "[700]\tvalidation-auc:0.871904\n",
      "[750]\tvalidation-auc:0.872035\n",
      "[800]\tvalidation-auc:0.872167\n",
      "[850]\tvalidation-auc:0.872288\n",
      "[900]\tvalidation-auc:0.872392\n",
      "[950]\tvalidation-auc:0.872476\n",
      "[1000]\tvalidation-auc:0.872529\n",
      "[1050]\tvalidation-auc:0.872586\n",
      "[1100]\tvalidation-auc:0.872642\n",
      "[1150]\tvalidation-auc:0.872715\n",
      "Stopping. Best iteration:\n",
      "[1177]\tvalidation-auc:0.872751\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.838963\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.864539\n",
      "[100]\tvalidation-auc:0.868477\n",
      "[150]\tvalidation-auc:0.87005\n",
      "[200]\tvalidation-auc:0.870869\n",
      "[250]\tvalidation-auc:0.871521\n",
      "[300]\tvalidation-auc:0.871932\n",
      "[350]\tvalidation-auc:0.872171\n",
      "[400]\tvalidation-auc:0.872363\n",
      "[450]\tvalidation-auc:0.872507\n",
      "[500]\tvalidation-auc:0.872626\n",
      "[550]\tvalidation-auc:0.872743\n",
      "[600]\tvalidation-auc:0.872825\n",
      "[650]\tvalidation-auc:0.872904\n",
      "Stopping. Best iteration:\n",
      "[669]\tvalidation-auc:0.872932\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.838963\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.868624\n",
      "[100]\tvalidation-auc:0.870963\n",
      "[150]\tvalidation-auc:0.871986\n",
      "[200]\tvalidation-auc:0.872354\n",
      "[250]\tvalidation-auc:0.872572\n",
      "[300]\tvalidation-auc:0.872716\n",
      "Stopping. Best iteration:\n",
      "[292]\tvalidation-auc:0.872726\n",
      "\n",
      "\n",
      "max_depth = 4, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.838963\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870667\n",
      "[100]\tvalidation-auc:0.87199\n",
      "Stopping. Best iteration:\n",
      "[135]\tvalidation-auc:0.872238\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.860701\n",
      "[100]\tvalidation-auc:0.862913\n",
      "[150]\tvalidation-auc:0.864817\n",
      "[200]\tvalidation-auc:0.866146\n",
      "[250]\tvalidation-auc:0.86729\n",
      "[300]\tvalidation-auc:0.868267\n",
      "[350]\tvalidation-auc:0.869049\n",
      "[400]\tvalidation-auc:0.869584\n",
      "[450]\tvalidation-auc:0.870093\n",
      "[500]\tvalidation-auc:0.870521\n",
      "[550]\tvalidation-auc:0.870848\n",
      "[600]\tvalidation-auc:0.871106\n",
      "[650]\tvalidation-auc:0.871345\n",
      "[700]\tvalidation-auc:0.87156\n",
      "[750]\tvalidation-auc:0.87174\n",
      "[800]\tvalidation-auc:0.871899\n",
      "[850]\tvalidation-auc:0.872038\n",
      "[900]\tvalidation-auc:0.872161\n",
      "[950]\tvalidation-auc:0.872285\n",
      "[1000]\tvalidation-auc:0.87237\n",
      "[1050]\tvalidation-auc:0.872457\n",
      "[1100]\tvalidation-auc:0.872532\n",
      "[1150]\tvalidation-auc:0.872603\n",
      "[1200]\tvalidation-auc:0.872685\n",
      "[1250]\tvalidation-auc:0.872733\n",
      "[1300]\tvalidation-auc:0.872782\n",
      "[1350]\tvalidation-auc:0.872821\n",
      "[1400]\tvalidation-auc:0.872883\n",
      "[1450]\tvalidation-auc:0.872911\n",
      "[1500]\tvalidation-auc:0.872959\n",
      "[1550]\tvalidation-auc:0.872981\n",
      "[1600]\tvalidation-auc:0.873018\n",
      "[1650]\tvalidation-auc:0.873048\n",
      "[1700]\tvalidation-auc:0.873081\n",
      "Stopping. Best iteration:\n",
      "[1703]\tvalidation-auc:0.873082\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.863025\n",
      "[100]\tvalidation-auc:0.865969\n",
      "[150]\tvalidation-auc:0.868262\n",
      "[200]\tvalidation-auc:0.869493\n",
      "[250]\tvalidation-auc:0.87041\n",
      "[300]\tvalidation-auc:0.871032\n",
      "[350]\tvalidation-auc:0.871462\n",
      "[400]\tvalidation-auc:0.871753\n",
      "[450]\tvalidation-auc:0.872028\n",
      "[500]\tvalidation-auc:0.872229\n",
      "[550]\tvalidation-auc:0.872382\n",
      "[600]\tvalidation-auc:0.872534\n",
      "[650]\tvalidation-auc:0.87265\n",
      "[700]\tvalidation-auc:0.872739\n",
      "[750]\tvalidation-auc:0.872848\n",
      "Stopping. Best iteration:\n",
      "[786]\tvalidation-auc:0.87291\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.867524\n",
      "[100]\tvalidation-auc:0.870506\n",
      "[150]\tvalidation-auc:0.871705\n",
      "[200]\tvalidation-auc:0.872238\n",
      "[250]\tvalidation-auc:0.872563\n",
      "[300]\tvalidation-auc:0.872847\n",
      "[350]\tvalidation-auc:0.873014\n",
      "Stopping. Best iteration:\n",
      "[377]\tvalidation-auc:0.873088\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870551\n",
      "[100]\tvalidation-auc:0.872179\n",
      "[150]\tvalidation-auc:0.872801\n",
      "Stopping. Best iteration:\n",
      "[183]\tvalidation-auc:0.872918\n",
      "\n",
      "\n",
      "max_depth = 5, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.871888\n",
      "[100]\tvalidation-auc:0.872465\n",
      "Stopping. Best iteration:\n",
      "[103]\tvalidation-auc:0.872495\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.854912\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.864916\n",
      "[100]\tvalidation-auc:0.866103\n",
      "[150]\tvalidation-auc:0.867366\n",
      "[200]\tvalidation-auc:0.868379\n",
      "[250]\tvalidation-auc:0.869182\n",
      "[300]\tvalidation-auc:0.869945\n",
      "[350]\tvalidation-auc:0.870576\n",
      "[400]\tvalidation-auc:0.87098\n",
      "[450]\tvalidation-auc:0.871374\n",
      "[500]\tvalidation-auc:0.871709\n",
      "[550]\tvalidation-auc:0.871963\n",
      "[600]\tvalidation-auc:0.872161\n",
      "[650]\tvalidation-auc:0.872332\n",
      "[700]\tvalidation-auc:0.87249\n",
      "[750]\tvalidation-auc:0.872613\n",
      "[800]\tvalidation-auc:0.87271\n",
      "[850]\tvalidation-auc:0.872807\n",
      "[900]\tvalidation-auc:0.872908\n",
      "[950]\tvalidation-auc:0.87298\n",
      "[1000]\tvalidation-auc:0.873023\n",
      "[1050]\tvalidation-auc:0.873075\n",
      "[1100]\tvalidation-auc:0.873111\n",
      "[1150]\tvalidation-auc:0.873151\n",
      "[1200]\tvalidation-auc:0.873198\n",
      "[1250]\tvalidation-auc:0.873235\n",
      "[1300]\tvalidation-auc:0.873273\n",
      "Stopping. Best iteration:\n",
      "[1335]\tvalidation-auc:0.87329\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.854912\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.866166\n",
      "[100]\tvalidation-auc:0.868203\n",
      "[150]\tvalidation-auc:0.869947\n",
      "[200]\tvalidation-auc:0.870977\n",
      "[250]\tvalidation-auc:0.871679\n",
      "[300]\tvalidation-auc:0.872145\n",
      "[350]\tvalidation-auc:0.872461\n",
      "[400]\tvalidation-auc:0.872682\n",
      "[450]\tvalidation-auc:0.872852\n",
      "[500]\tvalidation-auc:0.872981\n",
      "[550]\tvalidation-auc:0.873057\n",
      "[600]\tvalidation-auc:0.873145\n",
      "[650]\tvalidation-auc:0.873211\n",
      "[700]\tvalidation-auc:0.87326\n",
      "[750]\tvalidation-auc:0.873301\n",
      "Stopping. Best iteration:\n",
      "[781]\tvalidation-auc:0.873342\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.854912\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.869344\n",
      "[100]\tvalidation-auc:0.871664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalidation-auc:0.87253\n",
      "[200]\tvalidation-auc:0.872826\n",
      "[250]\tvalidation-auc:0.873081\n",
      "[300]\tvalidation-auc:0.873221\n",
      "[350]\tvalidation-auc:0.873365\n",
      "Stopping. Best iteration:\n",
      "[376]\tvalidation-auc:0.873423\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.854912\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.871833\n",
      "[100]\tvalidation-auc:0.872795\n",
      "[150]\tvalidation-auc:0.873191\n",
      "Stopping. Best iteration:\n",
      "[157]\tvalidation-auc:0.87323\n",
      "\n",
      "\n",
      "max_depth = 6, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.854912\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.872317\n",
      "Stopping. Best iteration:\n",
      "[85]\tvalidation-auc:0.872624\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.01:\n",
      "[0]\tvalidation-auc:0.859433\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.867418\n",
      "[100]\tvalidation-auc:0.868145\n",
      "[150]\tvalidation-auc:0.869155\n",
      "[200]\tvalidation-auc:0.869896\n",
      "[250]\tvalidation-auc:0.870506\n",
      "[300]\tvalidation-auc:0.871095\n",
      "[350]\tvalidation-auc:0.871615\n",
      "[400]\tvalidation-auc:0.871927\n",
      "[450]\tvalidation-auc:0.872199\n",
      "[500]\tvalidation-auc:0.872425\n",
      "[550]\tvalidation-auc:0.872608\n",
      "[600]\tvalidation-auc:0.872749\n",
      "[650]\tvalidation-auc:0.87287\n",
      "[700]\tvalidation-auc:0.872977\n",
      "[750]\tvalidation-auc:0.873054\n",
      "[800]\tvalidation-auc:0.873117\n",
      "[850]\tvalidation-auc:0.873178\n",
      "[900]\tvalidation-auc:0.873234\n",
      "[950]\tvalidation-auc:0.87327\n",
      "Stopping. Best iteration:\n",
      "[954]\tvalidation-auc:0.873281\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.02:\n",
      "[0]\tvalidation-auc:0.859433\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.868395\n",
      "[100]\tvalidation-auc:0.869863\n",
      "[150]\tvalidation-auc:0.87115\n",
      "[200]\tvalidation-auc:0.871941\n",
      "[250]\tvalidation-auc:0.872438\n",
      "[300]\tvalidation-auc:0.872764\n",
      "[350]\tvalidation-auc:0.872995\n",
      "[400]\tvalidation-auc:0.873113\n",
      "[450]\tvalidation-auc:0.873219\n",
      "Stopping. Best iteration:\n",
      "[472]\tvalidation-auc:0.873245\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.05:\n",
      "[0]\tvalidation-auc:0.859433\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870593\n",
      "[100]\tvalidation-auc:0.872245\n",
      "[150]\tvalidation-auc:0.872959\n",
      "Stopping. Best iteration:\n",
      "[183]\tvalidation-auc:0.873109\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.1:\n",
      "[0]\tvalidation-auc:0.859433\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.872343\n",
      "[100]\tvalidation-auc:0.873035\n",
      "Stopping. Best iteration:\n",
      "[135]\tvalidation-auc:0.873168\n",
      "\n",
      "\n",
      "max_depth = 7, eta = 0.2:\n",
      "[0]\tvalidation-auc:0.859433\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.872889\n",
      "Stopping. Best iteration:\n",
      "[69]\tvalidation-auc:0.873084\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_1 = [(md,e) for md in range(4,8) for e in [0.01, 0.02, 0.05, 0.1, 0.2]]\n",
    "validation_auc_1 = Counter()\n",
    "for md,e in grid_1:\n",
    "    print(\"max_depth = {0}, eta = {1}:\".format(md,e))\n",
    "    params = {'max_depth': md, 'eta': e, 'min_child_weight': 1, 'colsample_bytree': 0.8, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_1[(md,e)] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6, 0.05), 0.873423)\n",
      "((6, 0.02), 0.873342)\n",
      "((6, 0.01), 0.87329)\n",
      "((7, 0.01), 0.873281)\n",
      "((7, 0.02), 0.873245)\n",
      "((6, 0.1), 0.87323)\n",
      "((7, 0.1), 0.873168)\n",
      "((7, 0.05), 0.873109)\n",
      "((5, 0.05), 0.873088)\n",
      "((7, 0.2), 0.873084)\n",
      "((5, 0.01), 0.873082)\n",
      "((4, 0.05), 0.872932)\n",
      "((5, 0.1), 0.872918)\n",
      "((5, 0.02), 0.87291)\n",
      "((4, 0.01), 0.872805)\n",
      "((4, 0.02), 0.872751)\n",
      "((4, 0.1), 0.872726)\n",
      "((6, 0.2), 0.872624)\n",
      "((5, 0.2), 0.872495)\n",
      "((4, 0.2), 0.872238)\n"
     ]
    }
   ],
   "source": [
    "for t in validation_auc_1.most_common():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Grid Search for min_child_weight (along with max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 5, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.867519\n",
      "[100]\tvalidation-auc:0.870473\n",
      "[150]\tvalidation-auc:0.871732\n",
      "[200]\tvalidation-auc:0.872251\n",
      "[250]\tvalidation-auc:0.872634\n",
      "[300]\tvalidation-auc:0.872912\n",
      "[350]\tvalidation-auc:0.873051\n",
      "Stopping. Best iteration:\n",
      "[376]\tvalidation-auc:0.873115\n",
      "\n",
      "\n",
      "max_depth = 5, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.848008\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.867521\n",
      "[100]\tvalidation-auc:0.870473\n",
      "[150]\tvalidation-auc:0.871718\n",
      "[200]\tvalidation-auc:0.872265\n",
      "[250]\tvalidation-auc:0.872599\n",
      "[300]\tvalidation-auc:0.872881\n",
      "[350]\tvalidation-auc:0.873061\n",
      "Stopping. Best iteration:\n",
      "[354]\tvalidation-auc:0.873084\n",
      "\n",
      "\n",
      "max_depth = 6, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.854919\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.869308\n",
      "[100]\tvalidation-auc:0.871585\n",
      "[150]\tvalidation-auc:0.87251\n",
      "[200]\tvalidation-auc:0.872843\n",
      "[250]\tvalidation-auc:0.873066\n",
      "[300]\tvalidation-auc:0.873204\n",
      "Stopping. Best iteration:\n",
      "[291]\tvalidation-auc:0.873215\n",
      "\n",
      "\n",
      "max_depth = 6, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.854924\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.869319\n",
      "[100]\tvalidation-auc:0.871657\n",
      "[150]\tvalidation-auc:0.87257\n",
      "[200]\tvalidation-auc:0.872875\n",
      "[250]\tvalidation-auc:0.87307\n",
      "[300]\tvalidation-auc:0.873206\n",
      "Stopping. Best iteration:\n",
      "[292]\tvalidation-auc:0.873216\n",
      "\n",
      "\n",
      "max_depth = 7, min_child_weight = 3:\n",
      "[0]\tvalidation-auc:0.859421\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870557\n",
      "[100]\tvalidation-auc:0.872199\n",
      "[150]\tvalidation-auc:0.87287\n",
      "[200]\tvalidation-auc:0.873019\n",
      "Stopping. Best iteration:\n",
      "[220]\tvalidation-auc:0.873096\n",
      "\n",
      "\n",
      "max_depth = 7, min_child_weight = 5:\n",
      "[0]\tvalidation-auc:0.859435\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870589\n",
      "[100]\tvalidation-auc:0.872356\n",
      "[150]\tvalidation-auc:0.873062\n",
      "[200]\tvalidation-auc:0.873237\n",
      "Stopping. Best iteration:\n",
      "[221]\tvalidation-auc:0.873294\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md1 = 6\n",
    "grid_2 = [(md1+i,mcw) for i in [-1,0,1] for mcw in [3,5]]\n",
    "validation_auc_2 = Counter()\n",
    "for md,mcw in grid_2:\n",
    "    print(\"max_depth = {0}, min_child_weight = {1}:\".format(md,mcw))\n",
    "    params = {'max_depth': md, 'eta': 0.05, 'min_child_weight': mcw, 'colsample_bytree': 0.8, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_2[(md,mcw)] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 5), 0.873294)\n",
      "((6, 5), 0.873216)\n",
      "((6, 3), 0.873215)\n",
      "((5, 3), 0.873115)\n",
      "((7, 3), 0.873096)\n",
      "((5, 5), 0.873084)\n"
     ]
    }
   ],
   "source": [
    "for t in validation_auc_2.most_common():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Grid Search for colsample_by_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_by_tree = 0.5:\n",
      "[0]\tvalidation-auc:0.849506\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation-auc:0.862087\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.55:\n",
      "[0]\tvalidation-auc:0.849647\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.869539\n",
      "[100]\tvalidation-auc:0.871734\n",
      "[150]\tvalidation-auc:0.872811\n",
      "Stopping. Best iteration:\n",
      "[174]\tvalidation-auc:0.872993\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.6:\n",
      "[0]\tvalidation-auc:0.849647\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.869539\n",
      "[100]\tvalidation-auc:0.871734\n",
      "[150]\tvalidation-auc:0.872811\n",
      "Stopping. Best iteration:\n",
      "[174]\tvalidation-auc:0.872993\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.65:\n",
      "[0]\tvalidation-auc:0.849647\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870221\n",
      "[100]\tvalidation-auc:0.872069\n",
      "[150]\tvalidation-auc:0.872928\n",
      "[200]\tvalidation-auc:0.873203\n",
      "[250]\tvalidation-auc:0.873358\n",
      "Stopping. Best iteration:\n",
      "[262]\tvalidation-auc:0.873397\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.7:\n",
      "[0]\tvalidation-auc:0.849647\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870647\n",
      "[100]\tvalidation-auc:0.87227\n",
      "[150]\tvalidation-auc:0.873006\n",
      "[200]\tvalidation-auc:0.873199\n",
      "Stopping. Best iteration:\n",
      "[212]\tvalidation-auc:0.87324\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.75:\n",
      "[0]\tvalidation-auc:0.849647\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870647\n",
      "[100]\tvalidation-auc:0.87227\n",
      "[150]\tvalidation-auc:0.873006\n",
      "[200]\tvalidation-auc:0.873199\n",
      "Stopping. Best iteration:\n",
      "[212]\tvalidation-auc:0.87324\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.8:\n",
      "[0]\tvalidation-auc:0.859435\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870589\n",
      "[100]\tvalidation-auc:0.872356\n",
      "[150]\tvalidation-auc:0.873062\n",
      "[200]\tvalidation-auc:0.873237\n",
      "Stopping. Best iteration:\n",
      "[221]\tvalidation-auc:0.873294\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.85:\n",
      "[0]\tvalidation-auc:0.859613\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870753\n",
      "[100]\tvalidation-auc:0.872465\n",
      "[150]\tvalidation-auc:0.872978\n",
      "Stopping. Best iteration:\n",
      "[180]\tvalidation-auc:0.873113\n",
      "\n",
      "\n",
      "colsample_by_tree = 0.9:\n",
      "[0]\tvalidation-auc:0.859613\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870753\n",
      "[100]\tvalidation-auc:0.872465\n",
      "[150]\tvalidation-auc:0.872978\n",
      "Stopping. Best iteration:\n",
      "[180]\tvalidation-auc:0.873113\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_3 = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "validation_auc_3 = Counter()\n",
    "for cbt in grid_3:\n",
    "    print(\"colsample_by_tree = {}:\".format(cbt))\n",
    "    params = {'max_depth': 7, 'eta': 0.05, 'min_child_weight': 5, 'colsample_bytree': cbt, \n",
    "              'subsample': 0.8, \n",
    "              'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "              'seed': 12345}\n",
    "    evals_result = {}\n",
    "    xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                          early_stopping_rounds = 10,\n",
    "                          evals_result = evals_result,\n",
    "                          verbose_eval = 50)\n",
    "    validation_auc_3[cbt] = np.max(evals_result['validation']['auc'])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7, 0.850754),\n",
       " (0.65, 0.850754),\n",
       " (0.85, 0.850697),\n",
       " (0.8, 0.850697),\n",
       " (0.9, 0.850653),\n",
       " (0.75, 0.850555),\n",
       " (0.6, 0.840852),\n",
       " (0.5, 0.83465),\n",
       " (0.55, 0.83465)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_auc_3.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Finally select the opitmal num_boost_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.849647\n",
      "Will train until validation-auc hasn't improved in 10 rounds.\n",
      "[50]\tvalidation-auc:0.870647\n",
      "[100]\tvalidation-auc:0.87227\n",
      "[150]\tvalidation-auc:0.873006\n",
      "[200]\tvalidation-auc:0.873199\n",
      "Stopping. Best iteration:\n",
      "[212]\tvalidation-auc:0.87324\n",
      "\n",
      "\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 7, 'eta': 0.05, 'min_child_weight': 5, 'colsample_bytree': 0.7, \n",
    "          'subsample': 0.8, \n",
    "          'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "          'seed': 12345}\n",
    "evals_result = {}\n",
    "xgb_model = xgb.train(params = params, dtrain = dtrain_train, num_boost_round = int(5e3), evals = [(dtrain_val, 'validation')],\n",
    "                      early_stopping_rounds = 10,\n",
    "                      evals_result = evals_result,\n",
    "                      verbose_eval = 50)\n",
    "optimal_num_boost_round = np.argmax(evals_result['validation']['auc'])\n",
    "print(\"\")\n",
    "print(optimal_num_boost_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Train the final xgb model and make predictions for observations in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_num_boost_round = 212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "params = {'max_depth': 7, 'eta': 0.05, 'min_child_weight': 5, 'colsample_bytree': 0.7, \n",
    "          'subsample': 0.8, \n",
    "          'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "          'seed': 12345}\n",
    "final_xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = optimal_num_boost_round)\n",
    "# make prediction for observations in the test set\n",
    "y_test_pred = final_xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "AUC = 0.8162\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(dtest.get_label(), y_test_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model object and predicted scores on the validation sample to local disk\n",
    "# pickle.dump(final_xgb_model, open(results_dir + \"/xgb.p\", \"wb\"))\n",
    "pickle.dump(list(y_test_pred), open(results_dir + \"/y_test_pred_xgb.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(list(final_xgb_model.get_fscore().items()), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "feature_importance.loc[:, 'importance'] = feature_importance.loc[:, 'importance'] / sum(feature_importance.loc[:, 'importance'])\n",
    "yy = feature_importance.loc[:, 'importance'].iloc[:20]\n",
    "xx = feature_importance.loc[:, 'feature'].iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_summary = feature_importance.rename(columns = {'feature':'predictor_name',\n",
    "                                                   'importance':'feature_importance'})\\\n",
    ".loc[:,['predictor_name', 'feature_importance']]\n",
    "xgb_summary = xgb_summary.merge(pd.DataFrame({'predictor_name': predictors}), on=['predictor_name'], how='right')\\\n",
    ".sort_values(['feature_importance', 'predictor_name'], ascending=[False, True]).fillna(0)\n",
    "xgb_summary.to_csv(results_dir + \"xgb_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAJvCAYAAAAp7yTwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIlIhmqCLiIiIiFSIJugiIiIiIhXydw0tK6SDoLGjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.bar(list(range(13)), yy, width=0.75, color = \"orange\")\n",
    "plt.xticks(list(range(13)), xx, rotation = 'vertical', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Predictor\", fontsize=16, color=\"gray\")\n",
    "plt.ylabel(\"Feature Importance\", fontsize=16, color=\"gray\")\n",
    "plt.savefig(results_dir + \"XGBoost_variable_importance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t\n",
    "\n",
    "def cross_validation(train, xgb_params, nbr):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.grad_6years):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        X_1 = train_part_new.loc[:,predictors]\n",
    "        y_1 = train_part_new.grad_6years\n",
    "        X_2 = test_part_new.loc[:,predictors]\n",
    "        y_2 = test_part_new.grad_6years\n",
    "        dtrain_cv = xgb.DMatrix(X_1,y_1)\n",
    "        dtest_cv = xgb.DMatrix(X_2,y_2)\n",
    "        xgb_cv_model = xgb.train(params=xgb_params, dtrain=dtrain_cv, num_boost_round = nbr)\n",
    "        y_2_pred = xgb_cv_model.predict(dtest_cv)\n",
    "        p,r,t = precision_recall_curve(y_2, y_2_pred)\n",
    "        auc = roc_auc_score(y_2, y_2_pred)\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8731628054800705 0.0013896373265129506\n"
     ]
    }
   ],
   "source": [
    "final_params = {'max_depth': 7, 'eta': 0.05, 'min_child_weight': 5, 'colsample_bytree': 0.7, \n",
    "                'subsample': 0.8, \n",
    "                'objective': 'binary:logistic', 'eval_metric': ['auc'],\n",
    "                'seed': 12345}\n",
    "best_threshold = cross_validation(train_df, final_params, optimal_num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3622659"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.362:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  11718.0  10090.0  21808.0\n",
      "Real_1   1159.0  10148.0  11307.0\n",
      "        12877.0  20238.0  33115.0\n",
      "\n",
      "F1 score = 0.6434\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "pr_xgb = create_confusion_matrix(y_test_pred, best_threshold, \"XGBoost_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.78:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  17762.0   4046.0  21808.0\n",
      "Real_1   3881.0   7426.0  11307.0\n",
      "        21643.0  11472.0  33115.0\n",
      "\n",
      "F1 score = 0.652\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.grad_6years))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "pr2_xgb = create_confusion_matrix(y_test_pred_binary, best_threshold, \"XGBoost_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df = pd.DataFrame([(best_threshold,)+pr_xgb,(alternative_threshold,)+pr2_xgb]).round(4)\n",
    "precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df.to_csv(results_dir + \"XGBoost_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorganize files of key evaluation metrics for the four non-truncated models: OLS, Logit, RF, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract all of the key evaluation metrics of the four non-truncated models that only include simple non-term-specific predictors,\n",
    "# which will be used to populate column (2) within the Appendix Table A1 and Figure 1 of the paper\n",
    "cstat = [0.8467,0.8441,0.8780,0.8885]\n",
    "m_dict = {'Logit': 'LR1', 'OLS': 'OLS',\n",
    "          'RF': 'RF', 'XGBoost': 'XGBoost'}\n",
    "m_list = ['Logit', 'OLS', 'RF', 'XGBoost']\n",
    "summary = []\n",
    "for c,m in zip(cstat,m_list):\n",
    "    summary.append((m,c)+tuple(pd.read_csv(results_dir + \"\\\\{}_precision_recall.csv\".format(m_dict[m])).iloc[0,1:]))\n",
    "summary_df = pd.DataFrame(summary, columns=['model','c-statistic','threshold','precision_1','recall_1',\n",
    "                                            'precision_0','recall_0','f1_score_1'])\n",
    "summary_df.loc[:,'f1_score_0'] = 2*summary_df.precision_0*summary_df.recall_0/(summary_df.precision_0+summary_df.recall_0)\n",
    "summary_df.to_csv(results_dir + \"cleaned_results\\\\main_eval_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
