{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "fpath = \"/Users/ys8mz/Box Sync/Predictive Models of College Completion (VCCS)/intermediate_files\"\n",
    "results_dir = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\evaluation_results\\\\truncated_simple_predictors\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(fpath + \"/full_data_truncated_survival.dta\")\n",
    "df = df.iloc[:,[-3,-2,-1] + list(range(df.shape[1]-3))]\n",
    "for p in ['num_terms', 'times', 'event']:\n",
    "    df.loc[:,p] = df[p].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'enrolled_sum'] = 0\n",
    "for v1 in ['fa','sp','su']:\n",
    "    for i in range(1,7):\n",
    "        df.loc[:,'enrolled_sum'] += df[\"enrolled_\"+v1+str(i)]\n",
    "for p in [\"grants\", \"sub_loans\", 'unsub_loans', 'others']:\n",
    "    df.loc[:,p] = 0\n",
    "    for s in ['yr1','yr2','yr3','yr4','yr5','yr6']:\n",
    "        df.loc[:,p] += df.loc[:,p+\"_\"+s]\n",
    "    df.loc[:,p] = df[p]/(df.enrolled_sum)\n",
    "df = df.drop(['enrolled_sum'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Note: The predictors included in this model variant are all non-term-specific predictors plus the simple term-specific predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n"
     ]
    }
   ],
   "source": [
    "predictors = [p for p in list(df.columns)[4:] if p[-3:] not in ['yr1','yr2','yr3','yr4','yr5','yr6'] + [t2+str(t3) for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)]]\n",
    "predictors += [t1+\"_\"+t2+str(t3) for t1 in [\"available\", \"enrolled\", \"term_gpa\", \"prop_comp\", \"term_cred_att\", 'pell_0', 'pell_1'] for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)]\n",
    "print(len(predictors))\n",
    "impute_list_1 = set([\"prop_comp_pre\",\"cum_gpa_pre\"])\n",
    "impute_list_2 = set([t1+\"_\"+t2+str(t3) for t1 in [\"term_gpa\", \"prop_comp\", \"term_cred_att\"] for t2 in [\"fa\", \"sp\", \"su\"] for t3 in range(1,7,1)])\n",
    "impute_list_3 = set([\"cum_gpa\", \"lvl2_prop_comp\", \"dev_prop_comp\", \"prop_comp\", \"prop_comp_sd\", \"withdrawn_prop_comp_sd\"])\n",
    "impute_list_4 = set([\"admrate\", \"gradrate\", \"satvr25\", \"satvr75\", \"satmt25\", \"satmt75\", \"satwr25\", \"satwr75\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298139, 188) (33115, 188)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.valid == 0].drop(['valid'], axis=1).loc[:,predictors+['num_terms', 'times', 'event']]\n",
    "test_df = df[df.valid == 1].drop(['valid'], axis=1).loc[:,predictors+['num_terms', 'times', 'event']]\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.342028382734228\n",
      "0.34144647440736825\n"
     ]
    }
   ],
   "source": [
    "# degree completion rate of training sample\n",
    "print(sum(train_df.event)/train_df.shape[0])\n",
    "# degree completion rate of validation sample\n",
    "print(sum(test_df.event)/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute(train, test):\n",
    "    for p in impute_list_1:\n",
    "        avg_p = np.nanmean(train[train.enrolled_pre == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_2:\n",
    "        suffix = p[-3:]\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_\" + suffix] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_3:\n",
    "        avg_p = np.nanmean(train[p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    for p in impute_list_4:\n",
    "        avg_p = np.nanmean(train[train[\"enrolled_nsc\"] == 1][p])\n",
    "        train.loc[:,p] = train.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "        test.loc[:,p] = test.loc[:,p].apply(lambda x: avg_p if pd.isnull(x) else x)\n",
    "    return train, test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%time train_df_new, test_df_new = impute(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = test_df_new.event.copy()\n",
    "test_df_new.loc[:,'event'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 298139 total observations, 196167 right-censored observations>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the CoxPH model\n",
    "cph = CoxPHFitter(penalizer=0.01) # No penalizer will result in LinAlgError (probably due to multicollinearity)\n",
    "%time cph.fit(train_df_new, duration_col='times', event_col='event', strata='num_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33115, 17)\n"
     ]
    }
   ],
   "source": [
    "# Predict graduation probability (derived from survival probability by the end of Year 6)\n",
    "test_pred_raw = cph.predict_survival_function(test_df_new).T.sort_index()\n",
    "print(test_pred_raw.shape)\n",
    "y_test_pred = [1 - test_pred_raw.iloc[i,:].loc[18-e] for i,e in enumerate(test_df_new.num_terms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(y_test_pred, open(results_dir + \"y_test_pred_cox.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cox Proportional Hazard Model:\n",
      "AUC = 0.8794\n"
     ]
    }
   ],
   "source": [
    "# C-statistics\n",
    "print(\"Cox Proportional Hazard Model:\")\n",
    "print(\"AUC = {}\".format(round(roc_auc_score(y_test, y_test_pred),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(p,r,t):\n",
    "    to_drop = np.union1d(np.where(pd.isnull(p[:-1]) == True)[0], np.where(pd.isnull(r[:-1]) == True)[0])\n",
    "    to_drop = np.union1d(to_drop, np.where(pd.isnull(t) == True)[0])\n",
    "    to_keep = np.setdiff1d(np.array(list(range(len(p)-1))), to_drop)\n",
    "    p,r,t = p[to_keep],r[to_keep],t[to_keep]\n",
    "    f1 = 2*p*r/(p+r)\n",
    "    best_t = t[np.argmax(f1)]\n",
    "    best_t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_cox(train):\n",
    "    threshold_list = []\n",
    "    auc_list = []\n",
    "    k_fold =  StratifiedKFold(n_splits = 10, random_state = 12345, shuffle=True)\n",
    "    for train_indices, test_indices in k_fold.split(train, train.event):\n",
    "        train_part = train.iloc[train_indices,:]\n",
    "        test_part = train.iloc[test_indices,:]\n",
    "        train_part_new, test_part_new = impute(train_part, test_part)\n",
    "        test_part_new = test_part_new.sort_index()\n",
    "        y_2 = test_part_new.event.copy()\n",
    "        test_part_new.loc[:,'event'] = 0\n",
    "        model = CoxPHFitter(penalizer=0.01)\n",
    "        model.fit(train_part_new, duration_col='times', event_col='event', strata='num_terms')\n",
    "        y_2_pred_raw = model.predict_survival_function(test_part_new).T.sort_index()\n",
    "        y_2_pred = [1 - y_2_pred_raw.iloc[i,:].loc[18-e] for i,e in enumerate(test_part_new.num_terms)]\n",
    "        p,r,t = precision_recall_curve(y_2, y_2_pred)\n",
    "        auc = roc_auc_score(y_2, y_2_pred)\n",
    "        threshold_list.append(find_optimal_threshold(p,r,t))\n",
    "        auc_list.append(auc)\n",
    "    print(threshold_list)\n",
    "    print(np.mean(auc_list), np.std(auc_list, ddof=1))\n",
    "    return gmean(threshold_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\ys8mz\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3632226399537899, 0.9999999940638181, 0.3846688865912019, 0.37411332165527567, 0.3847162908327266, 0.3401371461249163, 0.36305167349928025, 0.3670490908806866, 0.3730404606659308, 0.999999222047505]\n",
      "0.876920656403698 0.002125046152791198\n"
     ]
    }
   ],
   "source": [
    "best_threshold = cross_validation_cox(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44993584957347593"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test_pred, threshold, fname):\n",
    "    cm_arr = confusion_matrix(y_test, np.where(y_test_pred > threshold, 1, 0))\n",
    "    cm_df = pd.DataFrame(cm_arr, columns=['Pred_0','Pred_1'], index=['Real_0', 'Real_1'])\n",
    "    cm_df.loc[:,''] = cm_df.sum(axis=1)\n",
    "    cm_df.loc['',:] = cm_df.sum(axis=0)\n",
    "    print(cm_df)\n",
    "    print(\"\")\n",
    "    p1 = cm_df.iloc[1,1]/cm_df.iloc[2,1]\n",
    "    r1 = cm_df.iloc[1,1]/cm_df.iloc[1,2]\n",
    "    p0 = cm_df.iloc[0,0]/cm_df.iloc[2,0]\n",
    "    r0 = cm_df.iloc[0,0]/cm_df.iloc[0,2]    \n",
    "    print(\"F1 score = {}\".format(round(2*p1*r1/(p1+r1),4)))    \n",
    "    cm_df.to_csv(results_dir + fname + \".csv\")\n",
    "    return p1,r1,p0,r0,round(2*p1*r1/(p1+r1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 threshold = 0.45:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  19434.0   2374.0  21808.0\n",
      "Real_1   3485.0   7822.0  11307.0\n",
      "        22919.0  10196.0  33115.0\n",
      "\n",
      "F1 score = 0.7275\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 threshold = {}:\\n\".format(str(round(best_threshold,3))))\n",
    "pr_cox = create_confusion_matrix(y_test_pred, best_threshold, \"Cox_cm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative threshold = 0.403:\n",
      "\n",
      "         Pred_0   Pred_1         \n",
      "Real_0  18794.0   3014.0  21808.0\n",
      "Real_1   2995.0   8312.0  11307.0\n",
      "        21789.0  11326.0  33115.0\n",
      "\n",
      "F1 score = 0.7345\n"
     ]
    }
   ],
   "source": [
    "num_of_0 = int(round((1-np.mean(train_df.event))*len(y_test)))\n",
    "y_test_pred_binary = np.ones(len(y_test))\n",
    "y_test_pred_binary[np.argsort(y_test_pred)[:num_of_0]] = 0\n",
    "alternative_threshold = y_test_pred[np.argsort(y_test_pred)[num_of_0]]\n",
    "print(\"Alternative threshold = {}:\\n\".format(str(round(alternative_threshold,3))))\n",
    "pr2_cox = create_confusion_matrix(y_test_pred_binary, best_threshold, \"Cox_cm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_df = pd.DataFrame([(best_threshold,)+pr_cox,(alternative_threshold,)+pr2_cox]).round(4)\n",
    "precision_recall_df.index = ['F1','Same_Graduation_Rate']\n",
    "precision_recall_df.columns = ['threshold','precision_1','recall_1','precision_0','recall_0','f1_score']\n",
    "precision_recall_df.to_csv(results_dir + \"Cox_precision_recall.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
