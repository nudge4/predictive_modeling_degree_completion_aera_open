{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "fpath = \"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\intermediate_files\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_nth = pd.read_stata(fpath+\"enrolled_nth_alternative.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_ind = pd.read_stata(fpath+\"full_data_enrolled_terms.dta\").loc[:,['vccsid','valid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 300144, 1.0: 33350})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(valid_ind.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 298624\n",
      "Validation sample size: 33161\n"
     ]
    }
   ],
   "source": [
    "enrolled_nth_1 = valid_ind[valid_ind.valid == 0].merge(enrolled_nth, on=['vccsid'], how='inner')\n",
    "print(\"Training sample size:\", len(np.unique(enrolled_nth_1.vccsid)))\n",
    "enrolled_nth_2 = valid_ind[valid_ind.valid == 1].merge(enrolled_nth, on=['vccsid'], how='inner')\n",
    "print(\"Validation sample size:\", len(np.unique(enrolled_nth_2.vccsid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random truncation procedure for the training/validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Use the above number to calculate training/validation sample sizes corresponding to each nth_term (in \"identify_truncated_sample_sizes.do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_dict = {}\n",
    "df1 = enrolled_nth.loc[:,['vccsid','first_nonde_strm']].drop_duplicates()\n",
    "for i in range(df1.shape[0]):\n",
    "    vccsid = df1.vccsid.iloc[i]\n",
    "    fns = df1.first_nonde_strm.iloc[i]\n",
    "    initial_dict[vccsid] = fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nth_dict_1 = {i:set() for i in range(1,18)}\n",
    "for i in range(enrolled_nth_1.shape[0]):\n",
    "    vccsid = enrolled_nth_1.vccsid.iloc[i]\n",
    "    nth = enrolled_nth_1.nth.iloc[i]\n",
    "    nth_dict_1[nth].add(vccsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nth_dict_2 = {i:set() for i in range(1,18)}\n",
    "for i in range(enrolled_nth_2.shape[0]):\n",
    "    vccsid = enrolled_nth_2.vccsid.iloc[i]\n",
    "    nth = enrolled_nth_2.nth.iloc[i]\n",
    "    nth_dict_2[nth].add(vccsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nth_dict_1_cp = nth_dict_1.copy()\n",
    "nth_dict_2_cp = nth_dict_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truncation_ss = pd.read_stata(fpath+\"truncation_sample_sizes_alternative.dta\")\n",
    "train_ss = {}\n",
    "valid_ss = {}\n",
    "for i in range(truncation_ss.shape[0]):\n",
    "    nth_term = truncation_ss.nth_term.iloc[i]\n",
    "    tss = truncation_ss.train_sample_size.iloc[i]\n",
    "    vss = truncation_ss.valid_sample_size.iloc[i]\n",
    "    train_ss[nth_term] = tss\n",
    "    valid_ss[nth_term] = vss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nth == 17 is sampled: 1486 out of 14190\n",
      "nth == 16 is sampled: 6886 out of 17036\n",
      "nth == 15 is sampled: 3265 out of 11318\n",
      "nth == 14 is sampled: 2010 out of 15053\n",
      "nth == 13 is sampled: 10241 out of 20065\n",
      "nth == 12 is sampled: 5360 out of 14088\n",
      "nth == 11 is sampled: 3167 out of 19540\n",
      "nth == 10 is sampled: 17701 out of 27793\n",
      "nth == 9 is sampled: 8909 out of 18058\n",
      "nth == 8 is sampled: 4601 out of 26692\n",
      "nth == 7 is sampled: 28924 out of 40802\n",
      "nth == 6 is sampled: 13596 out of 24315\n",
      "nth == 5 is sampled: 7889 out of 38326\n",
      "nth == 4 is sampled: 50346 out of 57328\n",
      "nth == 3 is sampled: 22492 out of 24211\n",
      "nth == 2 is sampled: 12868 out of 42141\n",
      "nth == 1 is sampled: 98883 out of 98883\n"
     ]
    }
   ],
   "source": [
    "### Random truncation (sampling) for training sample\n",
    "random.seed(12345)\n",
    "sample_1 = {}\n",
    "diff = 0\n",
    "for nth in range(17,0,-1):\n",
    "    tss = int(train_ss[nth]) + diff\n",
    "    pool_size = len(nth_dict_1_cp[nth])\n",
    "    if pool_size < tss:\n",
    "        sample_1[nth] = nth_dict_1_cp[nth]\n",
    "        diff = tss - pool_size\n",
    "    else:\n",
    "        sample_1[nth] = set(random.sample(nth_dict_1_cp[nth], tss))    \n",
    "    for i in range(nth,0,-1):\n",
    "        nth_dict_1_cp[i] = nth_dict_1_cp[i].difference(sample_1[nth])\n",
    "    print(\"nth == {0} is sampled: {1} out of {2}\".format(nth,min(tss, pool_size),pool_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_1 = np.array([len(sample_1[i+1]) for i in range(len(sample_1))])\n",
    "prop_1 = prop_1/np.sum(prop_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nth == 17 is sampled: 165 out of 1560\n",
      "nth == 16 is sampled: 765 out of 1898\n",
      "nth == 15 is sampled: 363 out of 1237\n",
      "nth == 14 is sampled: 223 out of 1642\n",
      "nth == 13 is sampled: 1137 out of 2252\n",
      "nth == 12 is sampled: 595 out of 1450\n",
      "nth == 11 is sampled: 352 out of 2174\n",
      "nth == 10 is sampled: 1966 out of 3080\n",
      "nth == 9 is sampled: 989 out of 2011\n",
      "nth == 8 is sampled: 511 out of 2941\n",
      "nth == 7 is sampled: 3212 out of 4566\n",
      "nth == 6 is sampled: 1510 out of 2724\n",
      "nth == 5 is sampled: 876 out of 4339\n",
      "nth == 4 is sampled: 5591 out of 6366\n",
      "nth == 3 is sampled: 2498 out of 2788\n",
      "nth == 2 is sampled: 1429 out of 4653\n",
      "nth == 1 is sampled: 10979 out of 10979\n"
     ]
    }
   ],
   "source": [
    "### Random truncation (sampling) for validation sample\n",
    "random.seed(12345)\n",
    "sample_2 = {}\n",
    "diff = 0\n",
    "for nth in range(17,0,-1):\n",
    "    vss = int(valid_ss[nth]) + diff\n",
    "    pool_size = len(nth_dict_2_cp[nth])\n",
    "    if pool_size < vss:\n",
    "        sample_2[nth] = nth_dict_2_cp[nth]\n",
    "        diff = vss - pool_size\n",
    "    else:\n",
    "        sample_2[nth] = set(random.sample(nth_dict_2_cp[nth], vss))    \n",
    "    for i in range(nth,0,-1):\n",
    "        nth_dict_2_cp[i] = nth_dict_2_cp[i].difference(sample_2[nth])\n",
    "    print(\"nth == {0} is sampled: {1} out of {2}\".format(nth,min(vss, pool_size),pool_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_2 = np.array([len(sample_2[i+1]) for i in range(len(sample_2))])\n",
    "prop_2 = prop_2/np.sum(prop_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nth_term  crnt_cohort  truncated_train  truncated_validation\n",
      "0          1       0.3311           0.3311                0.3311\n",
      "1          2       0.0431           0.0431                0.0431\n",
      "2          3       0.0753           0.0753                0.0753\n",
      "3          4       0.1686           0.1686                0.1686\n",
      "4          5       0.0264           0.0264                0.0264\n",
      "5          6       0.0455           0.0455                0.0455\n",
      "6          7       0.0969           0.0969                0.0969\n",
      "7          8       0.0154           0.0154                0.0154\n",
      "8          9       0.0298           0.0298                0.0298\n",
      "9         10       0.0593           0.0593                0.0593\n",
      "10        11       0.0106           0.0106                0.0106\n",
      "11        12       0.0179           0.0179                0.0179\n",
      "12        13       0.0343           0.0343                0.0343\n",
      "13        14       0.0067           0.0067                0.0067\n",
      "14        15       0.0109           0.0109                0.0109\n",
      "15        16       0.0231           0.0231                0.0231\n",
      "16        17       0.0050           0.0050                0.0050\n"
     ]
    }
   ],
   "source": [
    "prop_df = pd.DataFrame({\"nth_term\": range(1,18),\n",
    "                        \"crnt_cohort\": np.round(truncation_ss.prop,4), \n",
    "                        \"truncated_train\": np.round(prop_1,4),\n",
    "                        \"truncated_validation\": np.round(prop_2,4)})\\\n",
    ".loc[:,['nth_term', 'crnt_cohort', 'truncated_train', 'truncated_validation']]\n",
    "print(prop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_df.to_csv(fpath + \"proportion_after_truncation_alternative.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the end term of each observation after truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298624 33161\n"
     ]
    }
   ],
   "source": [
    "new_nth_dict = {}\n",
    "s1 = 0\n",
    "for k,v in sample_1.items():\n",
    "    s1 += len(v)\n",
    "    for vccsid in v:\n",
    "        new_nth_dict[vccsid] = k\n",
    "s2 = 0\n",
    "for k,v in sample_2.items():\n",
    "    s2 += len(v)\n",
    "    for vccsid in v:\n",
    "        new_nth_dict[vccsid] = k\n",
    "print(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_nth_df = enrolled_nth.groupby(['vccsid', 'first_nonde_strm']).agg({'nth':'max'}).reset_index()\n",
    "new_nth_df = pd.DataFrame.from_dict(new_nth_dict, orient=\"index\").reset_index().rename(columns={0:\"new_nth\", 'index':'vccsid'})\n",
    "final_nth_df = old_nth_df.merge(new_nth_df, on=['vccsid'], how='inner').merge(valid_ind, on=['vccsid'], how='inner').sort_values(['vccsid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'truncated'] = final_nth_df.apply(lambda r: int(r.loc['nth'] > r.loc['new_nth']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truncated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.428174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.429028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       truncated\n",
       "valid           \n",
       "0.0     0.428174\n",
       "1.0     0.429028"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_nth_df.groupby(['valid']).agg({'truncated':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.88 4.88\n"
     ]
    }
   ],
   "source": [
    "print(np.round(final_nth_df[final_nth_df.valid==0].new_nth.mean(), 2),\n",
    "      np.round(final_nth_df[final_nth_df.valid==1].new_nth.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df = final_nth_df.drop(['nth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'yr'] = (final_nth_df.new_nth-1) // 3\n",
    "final_nth_df.loc[:,'t'] = (final_nth_df.new_nth-1) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'last_term'] = final_nth_df.first_nonde_strm + 10*final_nth_df.yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'last_term'] = final_nth_df.last_term + final_nth_df.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.loc[:,'last_term'] = final_nth_df.last_term.apply(lambda x: x+7 if x % 10 == 5 or x % 10 == 6 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df = final_nth_df.loc[:,['vccsid', 'first_nonde_strm', 'last_term', 'truncated','new_nth']]\\\n",
    ".rename(columns={'new_nth':'nth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_nth_df.sort_values(['vccsid']).to_stata(fpath + \"truncation_nth_df_alternative.dta\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 109862,\n",
       "         2: 14297,\n",
       "         3: 24990,\n",
       "         4: 55937,\n",
       "         5: 8765,\n",
       "         6: 15106,\n",
       "         7: 32136,\n",
       "         8: 5112,\n",
       "         9: 9898,\n",
       "         10: 19667,\n",
       "         11: 3519,\n",
       "         12: 5955,\n",
       "         13: 11378,\n",
       "         14: 2233,\n",
       "         15: 3628,\n",
       "         16: 7651,\n",
       "         17: 1651})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(final_nth_df.nth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check: dropped students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_terms = pd.read_stata(\"C:\\\\Users\\\\ys8mz\\\\Box Sync\\\\Predictive Models of College Completion (VCCS)\\\\dta\\\\student_level_sample_and_outcomes.dta\")\\\n",
    ".loc[:,['vccsid', 'first_nonde_strm', 'deg_vccs_associate_strm', 'deg_vccs_certificate_strm', 'deg_vccs_diploma_strm']]\n",
    "enrolled_terms.loc[:,'first_degree_strm'] =\\\n",
    "enrolled_terms.loc[:,['deg_vccs_associate_strm', 'deg_vccs_certificate_strm', 'deg_vccs_diploma_strm']].min(axis=1)\n",
    "enrolled_terms.drop(['deg_vccs_associate_strm', 'deg_vccs_certificate_strm', 'deg_vccs_diploma_strm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_nth_1_new = valid_ind[valid_ind.valid == 0].merge(enrolled_nth, on=['vccsid'], how='left')\n",
    "enrolled_nth_1_new = enrolled_nth_1_new[pd.isnull(enrolled_nth_1_new.nth)].loc[:,['vccsid']]\n",
    "enrolled_nth_1_new = enrolled_nth_1_new.merge(enrolled_terms, on=['vccsid'], how='left')\n",
    "assert (enrolled_nth_1_new.first_nonde_strm == enrolled_nth_1_new.first_degree_strm).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enrolled_nth_2_new = valid_ind[valid_ind.valid == 1].merge(enrolled_nth, on=['vccsid'], how='left')\n",
    "enrolled_nth_2_new = enrolled_nth_2_new[pd.isnull(enrolled_nth_2_new.nth)].loc[:,['vccsid']]\n",
    "enrolled_nth_2_new = enrolled_nth_2_new.merge(enrolled_terms, on=['vccsid'], how='left')\n",
    "assert (enrolled_nth_2_new.first_nonde_strm == enrolled_nth_2_new.first_degree_strm).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
